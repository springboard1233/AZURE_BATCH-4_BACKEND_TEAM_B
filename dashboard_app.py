import streamlit as st
import requests
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')
import time  # <-- ADD THIS LINE TO FIX THE ERROR
import os





# Page Configuration
st.set_page_config(
    page_title="Azure Demand Forecasting Dashboard",
    page_icon="‚òÅÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API Configuration
BASE_URL = "http://localhost:5000/api"

# Custom CSS for Azure theme
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #0078d4 0%, #106ebe 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-left: 4px solid #0078d4;
        margin-bottom: 1rem;
    }
    
    .tab-container {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    .kpi-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        margin-bottom: 1rem;
    }
    
    .success-alert {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
        margin-bottom: 1rem;
    }
    
    .warning-alert {
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
        margin-bottom: 1rem;Multi-dimensional Analysis - External Factors Impact


    }
    
    .plotly-chart {
        border-radius: 8px;
        box-shadow: 0 1px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# Utility Functions
@st.cache_data(ttl=300)  # Cache for 5 minutes
def fetch_api(endpoint, params=None):
    """Fetch data from API with error handling"""
    try:
        response = requests.get(f"{BASE_URL}/{endpoint}", params=params, timeout=60)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"API Error: {str(e)}")
        return None
    except Exception as e:
        st.error(f"Unexpected error: {str(e)}")
        return None

def create_metric_card(title, value, delta=None, delta_color="normal"):
    """Create custom metric card"""
    delta_html = ""
    if delta:
        color = "#28a745" if delta_color == "normal" else "#dc3545"
        delta_html = f'<small style="color: {color};">{delta}</small>'
    
    return f"""
    <div class="metric-card">
        <h4 style="margin: 0; color: #0078d4;">{title}</h4>
        <h2 style="margin: 0.5rem 0; color: #333;">{value}</h2>
        {delta_html}
    </div>
    """

# Main Header
st.markdown("""
<div class="main-header">
    <h1>‚òÅÔ∏è Azure Demand Forecasting Dashboard</h1>
    <p>Real-time analytics and insights for Azure resource demand patterns</p>
</div>
""", unsafe_allow_html=True)

# Load filter options
@st.cache_data(ttl=3600)  # Cache for 1 hour
def load_filter_options():
    return fetch_api("filters/options")

filter_options = load_filter_options()

# Sidebar Filters
with st.sidebar:
    st.header("üéõÔ∏è Global Filters")
    
    if filter_options:
        # Region filter
        regions = filter_options.get('regions', [])
        selected_regions = st.multiselect(
            "üåç Select Regions",
            options=regions,
            default=regions,
            help="Choose one or more regions to analyze"
        )
        
        # Resource type filter
        resources = filter_options.get('resource_types', [])
        selected_resources = st.multiselect(
            "‚öôÔ∏è Select Resource Types",
            options=resources,
            default=resources,
            help="Choose resource types to include in analysis"
        )
        
        # Date range filter
        date_range = filter_options.get('date_range', {})
        if date_range:
            start_date = st.date_input(
                "üìÖ Start Date",
                value=pd.to_datetime(date_range['min_date']).date(),
                min_value=pd.to_datetime(date_range['min_date']).date(),
                max_value=pd.to_datetime(date_range['max_date']).date()
            )
            
            end_date = st.date_input(
                "üìÖ End Date", 
                value=pd.to_datetime(date_range['max_date']).date(),
                min_value=pd.to_datetime(date_range['min_date']).date(),
                max_value=pd.to_datetime(date_range['max_date']).date()
            )
    else:
        st.error("Unable to load filter options")
        selected_regions = []
        selected_resources = []
        start_date = None
        end_date = None

# Tab Navigation
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10 = st.tabs([
    "üìä Overview", "üìà Trends", "üåç Regional", "‚ö° Resources", 
    "üîó Correlations", "üë• User Engagement", "ü§ñ Forecasting", 
    "üèóÔ∏è Model Training", "üèóÔ∏è Capacity Planning", "üîç Monitoring"
])


# ===== TAB 1: OVERVIEW & KPIs =====
with tab1:
    st.subheader("üìä Key Performance Indicators")
    
    # Load KPI data
    kpi_data = fetch_api("kpis")
    
    if kpi_data:
        # Top row - Main KPIs
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="üî• Peak CPU Usage",
                value=f"{kpi_data['peak_cpu']:.1f}%",
                delta=f"+{kpi_data['peak_cpu'] - kpi_data['avg_cpu']:.1f}% above avg"
            )
            with st.expander("Details"):
                details = kpi_data['peak_cpu_details']
                st.write(f"**Date:** {details['date']}")
                st.write(f"**Region:** {details['region']}")
                st.write(f"**Resource:** {details['resource_type']}")
        
        with col2:
            st.metric(
                label="üíæ Max Storage",
                value=f"{kpi_data['max_storage']:,.0f} GB",
                delta=f"+{kpi_data['max_storage'] - kpi_data['avg_storage']:.0f}GB above avg"
            )
            with st.expander("Details"):
                details = kpi_data['max_storage_details']
                st.write(f"**Date:** {details['date']}")
                st.write(f"**Region:** {details['region']}")
                st.write(f"**Resource:** {details['resource_type']}")
        
        with col3:
            st.metric(
                label="üë• Peak Users",
                value=f"{kpi_data['peak_users']:,}",
                delta=f"+{kpi_data['peak_users'] - kpi_data['avg_users']:.0f} above avg"
            )
            with st.expander("Details"):
                details = kpi_data['peak_users_details']
                st.write(f"**Date:** {details['date']}")
                st.write(f"**Region:** {details['region']}")
                st.write(f"**Resource:** {details['resource_type']}")
        
        with col4:
            holiday_impact = kpi_data['holiday_impact']['percentage']
            st.metric(
                label="üéâ Holiday Impact",
                value=f"{holiday_impact:+.1f}%",
                delta="CPU usage change on holidays",
                delta_color="inverse" if holiday_impact < 0 else "normal"
            )
        
        # Second row - System Overview
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            st.metric("üåç Total Regions", kpi_data['total_regions'])
        
        with col6:
            st.metric("‚öôÔ∏è Resource Types", kpi_data['total_resource_types'])
        
        with col7:
            st.metric("üìÖ Data Points", f"{kpi_data['data_points']:,}")
        
        with col8:
            st.metric("‚è±Ô∏è Time Span", f"{kpi_data['date_range']['days']} days")
        
        st.divider()
        
        # Sparklines section
        st.subheader("üìà Recent Trends (Last 30 Days)")
        sparklines = fetch_api("sparklines")
        
        if sparklines:
            spark_col1, spark_col2, spark_col3 = st.columns(3)
            
            with spark_col1:
                cpu_data = pd.DataFrame(sparklines['cpu_trend'])
                if not cpu_data.empty:
                    fig = px.line(cpu_data, x='date', y='usage_cpu',
                                title="CPU Usage Trend")
                    fig.update_layout(height=400, showlegend=False)
                    fig.update_xaxes(showticklabels=False)
                    st.plotly_chart(fig, use_container_width=True)
            
            with spark_col2:
                storage_data = pd.DataFrame(sparklines['storage_trend'])
                if not storage_data.empty:
                    fig = px.line(storage_data, x='date', y='usage_storage',
                                title="Storage Usage Trend", color_discrete_sequence=['#ff6b6b'])
                    fig.update_layout(height=400, showlegend=False)
                    fig.update_xaxes(showticklabels=False)
                    st.plotly_chart(fig, use_container_width=True)
            
            with spark_col3:
                users_data = pd.DataFrame(sparklines['users_trend'])
                if not users_data.empty:
                    fig = px.line(users_data, x='date', y='users_active',
                                title="User Activity Trend", color_discrete_sequence=['#4ecdc4'])
                    fig.update_layout(height=400, showlegend=False)
                    fig.update_xaxes(showticklabels=False)
                    st.plotly_chart(fig, use_container_width=True)
        st.divider()
        # ===== Data Explorer =====
        st.subheader("üóÉÔ∏è Data Explorer")

        # Fetch raw data
        raw_data = fetch_api("data/raw")
        if not raw_data:
           st.info("No data available for exploration.")
        else:
           df_explore = pd.DataFrame(raw_data)
           df_explore['date'] = pd.to_datetime(df_explore['date']).dt.date

           # --- Inline filter controls ---
           st.markdown("**Filters:**")
           fcol1, fcol2, fcol3, fcol4 = st.columns([1, 1, 1, 1])
           # Separate start and end date pickers
           default_start = df_explore['date'].min()
           default_end   = df_explore['date'].max()
           with fcol1:
                start = st.date_input("Start Date", default_start)
   
           with fcol2:
                end = st.date_input("End Date", default_end)

            # Region dropdown
           regions = ['All'] + sorted(df_explore['region'].unique().tolist())
           with fcol3:
                sel_region = st.selectbox("Region", regions)

            # Resource type dropdown
           resources = ['All'] + sorted(df_explore['resource_type'].unique().tolist())
           with fcol4:
                sel_resource = st.selectbox("Resource Type", resources)

           # --- Apply filters ---
           mask = df_explore['date'].between(start, end)
           if sel_region != 'All':
              mask &= df_explore['region'] == sel_region
           if sel_resource != 'All':
              mask &= df_explore['resource_type'] == sel_resource
           df_filtered = df_explore.loc[mask].copy()



           # --- COLUMN ORDERING & LABELING ---
           # Define meaningful column order and labels
           column_config = {
                             'date': 'Date',
        'region': 'Azure Region',
        'resource_type': 'Resource Type',
        'usage_cpu': 'CPU Usage (%)',
        'usage_storage': 'Storage (GB)',
        'users_active': 'Active Users',
        'economic_index': 'Economic Index',
        'cloud_market_demand': 'Market Demand',
        'holiday': 'Holiday'
    }
    
           # Reorder columns in meaningful sequence
           ordered_columns = ['date', 'region', 'resource_type', 'usage_cpu', 'usage_storage', 
                      'users_active', 'economic_index', 'cloud_market_demand', 'holiday']
    
           # Select and reorder columns
           df_display = df_filtered[ordered_columns].copy()
    
           # Format specific columns for better readability
           df_display['usage_cpu'] = df_display['usage_cpu'].round(1)
           df_display['usage_storage'] = df_display['usage_storage'].astype(int)
           df_display['economic_index'] = df_display['economic_index'].round(2)
           df_display['cloud_market_demand'] = df_display['cloud_market_demand'].round(3)
           df_display['holiday'] = df_display['holiday'].map({0: 'No', 1: 'Yes'})
    
           # Display count and table with custom column configuration
           st.markdown(f"**Showing {len(df_display):,} records**")
    
           st.dataframe(
                 df_display.sort_values('date', ascending=False),
                 use_container_width=True,
                 height=400,
                 column_config={
            'date': st.column_config.DateColumn('üìÖ Date'),
            'region': st.column_config.TextColumn('üåç Azure Region'),
            'resource_type': st.column_config.TextColumn('‚öôÔ∏è Resource Type'),
            'usage_cpu': st.column_config.NumberColumn('üî• CPU Usage (%)', format="%.1f%%"),
            'usage_storage': st.column_config.NumberColumn('üíæ Storage (GB)', format="%d GB"),
            'users_active': st.column_config.NumberColumn('üë• Active Users', format="%d"),
            'economic_index': st.column_config.NumberColumn('üìà Economic Index', format="%.2f"),
            'cloud_market_demand': st.column_config.NumberColumn('üìä Market Demand', format="%.3f"),
            'holiday': st.column_config.TextColumn('üéâ Holiday')
        }
    )
    
          # Additional insights section
           with st.expander("üìä Quick Insights from Filtered Data"):
              insights_col1, insights_col2, insights_col3 = st.columns(3)
        
           with insights_col1:
                st.metric("Avg CPU Usage", f"{df_display['usage_cpu'].mean():.1f}%")
                st.metric("Peak CPU Usage", f"{df_display['usage_cpu'].max():.1f}%")
        
           with insights_col2:
                st.metric("Avg Storage", f"{df_display['usage_storage'].mean():.0f} GB")
                st.metric("Total Users", f"{df_display['users_active'].sum():,}")
        
           with insights_col3:
               holiday_pct = (df_display['holiday'] == 'Yes').mean() * 100
               st.metric("Holiday Records", f"{holiday_pct:.1f}%")
               st.metric("Unique Regions", f"{df_display['region'].nunique()}")







# SPACE-OPTIMIZED TAB 2 - COMPACT LAYOUT

# ===== TAB 2: ENHANCED TRENDS ANALYSIS WITH COMPACT LAYOUT =====
with tab2:
    st.subheader("üìà Advanced Trends Analysis & Pattern Detection")

    # Load filter options and check filtering capability
    filter_options = fetch_api("filters/options")

    if not filter_options:
        st.error("‚ùå Unable to load filter options")
        st.stop()

    # === ENHANCED FILTER CONTROLS ===
    st.markdown("**üéõÔ∏è Advanced Trend Controls:**")

    # Row 1: Primary filters
    filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)

    with filter_col1:
        metric_choice = st.selectbox(
            "üìä Primary Metric", 
            ["usage_cpu", "usage_storage", "users_active"], 
            format_func=lambda x: {
                "usage_cpu": "üî• CPU Usage (%)",
                "usage_storage": "üíæ Storage Usage (GB)", 
                "users_active": "üë• Active Users"
            }[x]
        )

    with filter_col2:
        # Get regions from filter options API
        available_regions = ['All Regions'] + filter_options.get('regions', [])
        region_filter = st.selectbox("üåç Region Focus", available_regions)

    with filter_col3:
        # Get resource types from filter options API
        available_resources = ['All Resources'] + filter_options.get('resource_types', [])
        resource_filter = st.selectbox("‚öôÔ∏è Resource Type", available_resources)

    with filter_col4:
        trend_period = st.selectbox("‚è∞ Time Period", ["7D", "30D", "90D", "All"])

    # Row 2: Analysis options
    analysis_col1, analysis_col2, analysis_col3, analysis_col4 = st.columns(4)

    with analysis_col1:
        smoothing = st.checkbox("üìà Apply Smoothing", value=True)

    with analysis_col2:
        show_patterns = st.checkbox("üîç Highlight Patterns", value=True)

    with analysis_col3:
        compare_mode = st.checkbox("‚öñÔ∏è Comparison View", value=False)

    with analysis_col4:
        show_anomalies = st.checkbox("üö® Detect Anomalies", value=False)

    # === DATA LOADING (COMPACT) ===
    # Try to use raw data for proper filtering
    raw_data = fetch_api("data/raw")

    if raw_data:
        # CLIENT-SIDE FILTERING (Most reliable approach)
        df_raw = pd.DataFrame(raw_data)
        df_raw['date'] = pd.to_datetime(df_raw['date'])

        # Apply region filter
        if region_filter != 'All Regions':
            df_filtered_raw = df_raw[df_raw['region'] == region_filter]
        else:
            df_filtered_raw = df_raw

        # Apply resource type filter
        if resource_filter != 'All Resources':
            df_filtered_raw = df_filtered_raw[df_filtered_raw['resource_type'] == resource_filter]

        # Apply time period filter
        if trend_period != "All":
            days = int(trend_period[:-1])
            latest_date = df_filtered_raw['date'].max()
            cutoff = latest_date - timedelta(days=days)
            df_filtered_raw = df_filtered_raw[df_filtered_raw['date'] >= cutoff]

        # Aggregate filtered data by date
        df_agg = df_filtered_raw.groupby('date').agg({
            'usage_cpu': 'mean',
            'usage_storage': 'mean', 
            'users_active': 'mean',
            'economic_index': 'mean',
            'cloud_market_demand': 'mean'
        }).reset_index().sort_values('date')

    else:
        # FALLBACK: Try time-series API with query parameters
        params = {}
        if region_filter != 'All Regions':
            params['region'] = region_filter
        if resource_filter != 'All Resources':
            params['resource_type'] = resource_filter

        if params:
            query_params = '&'.join([f"{k}={v}" for k, v in params.items()])
            filtered_time_series = fetch_api(f"time-series?{query_params}")

            if filtered_time_series:
                df_agg = pd.DataFrame(filtered_time_series)
                df_agg['date'] = pd.to_datetime(df_agg['date'])
            else:
                time_series_data = fetch_api("time-series")
                df_agg = pd.DataFrame(time_series_data)
                df_agg['date'] = pd.to_datetime(df_agg['date'])
        else:
            # No filters, use regular time-series
            time_series_data = fetch_api("time-series")
            df_agg = pd.DataFrame(time_series_data)
            df_agg['date'] = pd.to_datetime(df_agg['date'])

        # Apply time period filter
        if trend_period != "All":
            days = int(trend_period[:-1])
            latest_date = df_agg['date'].max()
            cutoff = latest_date - timedelta(days=days)
            df_agg = df_agg[df_agg['date'] >= cutoff]

    if df_agg.empty:
        st.error("‚ùå No data available for selected filters")
        st.error(f"Filters: Region={region_filter}, Resource={resource_filter}, Period={trend_period}")
        st.stop()

    # === COMPACT DATA STATUS (HIDDEN IN EXPANDER) ===
    with st.expander("üìä Data Status & Debug Information", expanded=False):
        # Data loading status
        status_col1, status_col2, status_col3 = st.columns(3)

        if raw_data:
            status_col1.success("üîß Using raw data for accurate filtering")
        else:
            status_col1.warning("‚ö†Ô∏è Using time-series API")

        # Filter status
        if region_filter != 'All Regions':
            status_col2.info(f"üåç {region_filter}: {len(df_agg):,} records")
        else:
            status_col2.info("üìä All regions")

        if resource_filter != 'All Resources':
            status_col3.info(f"‚öôÔ∏è {resource_filter}")
        else:
            status_col3.info("üìä All resources")

        st.divider()

        # Debug information (moved from main area)
        debug_col1, debug_col2 = st.columns(2)

        with debug_col1:
            st.markdown("**Filter Selection:**")
            st.write(f"üìç Region: {region_filter}")
            st.write(f"‚öôÔ∏è Resource: {resource_filter}")
            st.write(f"‚è∞ Period: {trend_period}")
            st.write(f"üìä Metric: {metric_choice}")

        with debug_col2:
            st.markdown("**Data Summary:**")
            st.write(f"üìà Records: {len(df_agg):,}")
            st.write(f"üìÖ Date Range: {df_agg['date'].min().date()} to {df_agg['date'].max().date()}")
            st.write(f"üî¢ {metric_choice} Range: {df_agg[metric_choice].min():.1f} - {df_agg[metric_choice].max():.1f}")

            # Show actual data preview
            st.markdown("**Sample Data:**")
            st.dataframe(df_agg.head(3), width="stretch")

        # Summary metrics (moved from main area) 
        st.markdown("**üìä Quick Summary Metrics:**")
        summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)

        with summary_col1:
            st.metric("üìä Data Points", f"{len(df_agg):,}")

        with summary_col2:
            date_range = (df_agg['date'].max() - df_agg['date'].min()).days
            st.metric("üìÖ Date Range", f"{date_range} days")

        with summary_col3:
            current_value = df_agg[metric_choice].iloc[-1] if len(df_agg) > 0 else 0
            st.metric("üìà Current Value", f"{current_value:.1f}")

        with summary_col4:
            if len(df_agg) > 1:
                trend_change = ((df_agg[metric_choice].iloc[-1] - df_agg[metric_choice].iloc[0]) / df_agg[metric_choice].iloc[0]) * 100
                st.metric("üîÑ Period Change", f"{trend_change:+.1f}%")
            else:
                st.metric("üîÑ Period Change", "N/A")

    # === 1. PRIMARY TREND ANALYSIS (NOW MUCH CLOSER TO CONTROLS) ===
    st.markdown("### üìà Primary Trend Analysis")

    # Create primary trend chart
    fig_primary = go.Figure()

    # Base trend line
    base_color = '#0078d4'
    if smoothing and len(df_agg) >= 7:
        # Apply smoothing
        df_agg[f'{metric_choice}_smooth'] = df_agg[metric_choice].rolling(window=min(7, len(df_agg)), center=True).mean()

        # Original data (lighter)
        fig_primary.add_trace(go.Scatter(
            x=df_agg['date'],
            y=df_agg[metric_choice],
            mode='lines+markers',
            name=f'Daily {metric_choice.replace("_", " ").title()}',
            line=dict(color='lightgray', width=1),
            marker=dict(size=3, color='lightgray'),
            opacity=0.5
        ))

        # Smoothed trend (bold)
        fig_primary.add_trace(go.Scatter(
            x=df_agg['date'],
            y=df_agg[f'{metric_choice}_smooth'],
            mode='lines',
            name=f'Smoothed Trend',
            line=dict(color=base_color, width=3)
        ))

        trend_values = df_agg[f'{metric_choice}_smooth'].dropna()
    else:
        fig_primary.add_trace(go.Scatter(
            x=df_agg['date'],
            y=df_agg[metric_choice],
            mode='lines+markers',
            name=f'{metric_choice.replace("_", " ").title()}',
            line=dict(color=base_color, width=2),
            marker=dict(size=4)
        ))
        trend_values = df_agg[metric_choice]

    # Anomaly detection
    if show_anomalies and len(trend_values) > 10:
        # Simple anomaly detection using IQR
        Q1 = trend_values.quantile(0.25)
        Q3 = trend_values.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        anomalies = df_agg[(df_agg[metric_choice] < lower_bound) | (df_agg[metric_choice] > upper_bound)]

        if not anomalies.empty:
            fig_primary.add_trace(go.Scatter(
                x=anomalies['date'],
                y=anomalies[metric_choice],
                mode='markers',
                name='üö® Anomalies',
                marker=dict(size=8, color='red', symbol='diamond'),
                hovertemplate='<b>Anomaly Detected</b><br>Date: %{x}<br>Value: %{y:.2f}<extra></extra>'
            ))

    # Pattern highlighting
    if show_patterns and len(trend_values) > 5:
        try:
            from scipy.signal import find_peaks

            values = trend_values.values
            peaks, _ = find_peaks(values, height=np.percentile(values, 75))
            valleys, _ = find_peaks(-values, height=-np.percentile(values, 25))

            if len(peaks) > 0:
                peak_dates = df_agg.iloc[peaks]['date']
                peak_values = df_agg.iloc[peaks][metric_choice]

                fig_primary.add_trace(go.Scatter(
                    x=peak_dates,
                    y=peak_values,
                    mode='markers',
                    name='‚õ∞Ô∏è Peaks',
                    marker=dict(size=10, color='green', symbol='triangle-up'),
                    hovertemplate='<b>Peak</b><br>Date: %{x}<br>Value: %{y:.2f}<extra></extra>'
                ))

            if len(valleys) > 0:
                valley_dates = df_agg.iloc[valleys]['date']
                valley_values = df_agg.iloc[valleys][metric_choice]

                fig_primary.add_trace(go.Scatter(
                    x=valley_dates,
                    y=valley_values,
                    mode='markers',
                    name='üèîÔ∏è Valleys',
                    marker=dict(size=10, color='orange', symbol='triangle-down'),
                    hovertemplate='<b>Valley</b><br>Date: %{x}<br>Value: %{y:.2f}<extra></extra>'
                ))
        except ImportError:
            pass  # Skip pattern detection if scipy not available

    # Add trend annotation
    if len(trend_values) > 1:
        trend_change = ((trend_values.iloc[-1] - trend_values.iloc[0]) / trend_values.iloc[0]) * 100
        trend_color = 'green' if trend_change > 0 else 'red'
        trend_arrow = 'üìà' if trend_change > 0 else 'üìâ'

        fig_primary.add_annotation(
            x=df_agg['date'].iloc[-1],
            y=trend_values.iloc[-1],
            text=f"{trend_arrow} {trend_change:+.1f}%",
            showarrow=True,
            arrowhead=2,
            arrowcolor=trend_color,
            bgcolor=trend_color,
            font=dict(color='white', size=12),
            bordercolor=trend_color,
            borderwidth=2
        )

    filter_text = ""
    if region_filter != 'All Regions':
        filter_text += f" | {region_filter}"
    if resource_filter != 'All Resources':
        filter_text += f" | {resource_filter}"

    fig_primary.update_layout(
        title=f"{metric_choice.replace('_', ' ').title()} Trends{filter_text}",
        xaxis_title="Date",
        yaxis_title=metric_choice.replace('_', ' ').title(),
        height=500,
        hovermode='x unified',
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )

    st.plotly_chart(fig_primary, width="stretch")

    # === 2. COMPARISON VIEW ===
    if compare_mode:
        st.markdown("### ‚öñÔ∏è Regional & Resource Comparison")

        comp_col1, comp_col2 = st.columns(2)

        with comp_col1:
            # Regional comparison using raw data
            if raw_data:
                df_raw_regional = pd.DataFrame(raw_data)
                df_raw_regional['date'] = pd.to_datetime(df_raw_regional['date'])

                # Filter by time period
                if trend_period != "All":
                    days = int(trend_period[:-1])
                    latest_date = df_raw_regional['date'].max()
                    cutoff = latest_date - timedelta(days=days)
                    df_raw_regional = df_raw_regional[df_raw_regional['date'] >= cutoff]

                # Apply resource filter if selected
                if resource_filter != 'All Resources':
                    df_raw_regional = df_raw_regional[df_raw_regional['resource_type'] == resource_filter]

                # Aggregate by date and region
                regional_comparison = df_raw_regional.groupby(['date', 'region']).agg({
                    metric_choice: 'mean'
                }).reset_index()

                fig_regional = px.line(
                    regional_comparison,
                    x='date',
                    y=metric_choice,
                    color='region',
                    title=f"Regional Comparison - {metric_choice.replace('_', ' ').title()}",
                    color_discrete_map={
                        'East US': '#0078d4',
                        'West US': '#ff6b6b', 
                        'North Europe': '#4ecdc4',
                        'Southeast Asia': '#95e1d3'
                    }
                )
                fig_regional.update_layout(height=400)
                st.plotly_chart(fig_regional, width="stretch")
            else:
                st.info("üìä Raw data not available for regional comparison")

        with comp_col2:
            # Resource comparison using raw data
            if raw_data:
                df_raw_resource = pd.DataFrame(raw_data)
                df_raw_resource['date'] = pd.to_datetime(df_raw_resource['date'])

                # Filter by time period
                if trend_period != "All":
                    days = int(trend_period[:-1])
                    latest_date = df_raw_resource['date'].max()
                    cutoff = latest_date - timedelta(days=days)
                    df_raw_resource = df_raw_resource[df_raw_resource['date'] >= cutoff]

                # Apply region filter if selected
                if region_filter != 'All Regions':
                    df_raw_resource = df_raw_resource[df_raw_resource['region'] == region_filter]

                # Aggregate by date and resource type
                resource_comparison = df_raw_resource.groupby(['date', 'resource_type']).agg({
                    metric_choice: 'mean'
                }).reset_index()

                fig_resource = px.line(
                    resource_comparison,
                    x='date',
                    y=metric_choice,
                    color='resource_type',
                    title=f"Resource Type Comparison - {metric_choice.replace('_', ' ').title()}",
                    color_discrete_map={
                        'VM': '#8e44ad',
                        'Storage': '#e67e22',
                        'Container': '#27ae60'
                    }
                )
                fig_resource.update_layout(height=400)
                st.plotly_chart(fig_resource, width="stretch")
            else:
                st.info("üìä Raw data not available for resource comparison")

    # === 3. PATTERN ANALYSIS ===
    st.markdown("### üîç Pattern Analysis")

    pattern_col1, pattern_col2 = st.columns(2)

    with pattern_col1:
        # Weekly pattern
        df_agg['day_of_week'] = df_agg['date'].dt.day_name()
        weekly_pattern = df_agg.groupby('day_of_week')[metric_choice].mean().reset_index()

        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        weekly_pattern['day_of_week'] = pd.Categorical(weekly_pattern['day_of_week'], categories=day_order, ordered=True)
        weekly_pattern = weekly_pattern.sort_values('day_of_week')

        fig_weekly = px.bar(
            weekly_pattern,
            x='day_of_week',
            y=metric_choice,
            title=f"Weekly Pattern{filter_text}",
            color=metric_choice,
            color_continuous_scale='Blues'
        )
        fig_weekly.update_layout(height=350)
        st.plotly_chart(fig_weekly, width="stretch")

    with pattern_col2:
        # Monthly pattern (if enough data)
        if len(df_agg) > 30:
            df_agg['month'] = df_agg['date'].dt.month_name()
            monthly_pattern = df_agg.groupby('month')[metric_choice].mean().reset_index()

            month_order = ['January', 'February', 'March', 'April', 'May', 'June',
                          'July', 'August', 'September', 'October', 'November', 'December']
            monthly_pattern['month'] = pd.Categorical(monthly_pattern['month'], categories=month_order, ordered=True)
            monthly_pattern = monthly_pattern.sort_values('month')

            fig_monthly = px.bar(
                monthly_pattern,
                x='month',
                y=metric_choice,
                title=f"Monthly Pattern{filter_text}",
                color=metric_choice,
                color_continuous_scale='Oranges'
            )
            fig_monthly.update_layout(height=350)
            fig_monthly.update_xaxes(tickangle=45)
            st.plotly_chart(fig_monthly, width="stretch")
        else:
            st.info("üìä Need more data points for monthly pattern analysis")

    # === 4. ADVANCED STATISTICS (MOVED TO EXPANDER) ===
    with st.expander("üìä Advanced Statistics & Insights", expanded=False):
        st.markdown("### üìä Detailed Statistics")

        stats_col1, stats_col2, stats_col3, stats_col4, stats_col5 = st.columns(5)

        with stats_col1:
            volatility = df_agg[metric_choice].std()
            st.metric("üìä Volatility", f"{volatility:.2f}")

        with stats_col2:
            avg_value = df_agg[metric_choice].mean()
            st.metric("üìà Average", f"{avg_value:.1f}")

        with stats_col3:
            max_value = df_agg[metric_choice].max()
            min_value = df_agg[metric_choice].min()
            range_val = max_value - min_value
            st.metric("üìè Range", f"{range_val:.1f}")

        with stats_col4:
            median_value = df_agg[metric_choice].median()
            st.metric("üéØ Median", f"{median_value:.1f}")

        with stats_col5:
            if len(df_agg) > 1:
                correlation = np.corrcoef(range(len(df_agg)), df_agg[metric_choice])[0, 1]
                st.metric("üìê Trend Strength", f"{correlation:.3f}")
            else:
                st.metric("üìê Trend Strength", "N/A")

    # === 5. AI-POWERED INSIGHTS ===
    with st.expander("ü§ñ AI-Powered Insights & Recommendations", expanded=False):
        insights_col1, insights_col2 = st.columns(2)

        with insights_col1:
            st.markdown("**üîç Pattern Detection:**")

            # Analyze trends
            if len(trend_values) > 7:
                recent_trend = trend_values.tail(7).mean()
                overall_trend = trend_values.mean()
                trend_momentum = ((recent_trend - overall_trend) / overall_trend) * 100

                if trend_momentum > 10:
                    st.success("üìà **Strong Upward Momentum** detected in recent data")
                elif trend_momentum < -10:
                    st.error("üìâ **Strong Downward Momentum** detected in recent data")
                else:
                    st.info("‚û°Ô∏è **Stable Trend** - minimal momentum change")

                # Seasonality detection
                if show_patterns:
                    weekly_var = weekly_pattern[metric_choice].var()
                    if len(df_agg) > 0:
                        volatility = df_agg[metric_choice].std()
                        if weekly_var > volatility * 0.5:
                            st.warning("üóìÔ∏è **Strong Weekly Seasonality** detected")
                        else:
                            st.info("üìÖ **Minimal Weekly Seasonality** observed")
            else:
                st.info("Need more data points for advanced pattern detection")

        with insights_col2:
            st.markdown("**üí° Smart Recommendations:**")

            if len(df_agg) > 0:
                current_val = df_agg[metric_choice].iloc[-1]
                avg_val = df_agg[metric_choice].mean()

                if metric_choice == 'usage_cpu':
                    if current_val > avg_val * 1.2:
                        st.warning("‚ö†Ô∏è **High CPU Alert**: Consider scaling resources")
                    elif current_val < avg_val * 0.8:
                        st.success("‚úÖ **CPU Optimized**: Resources efficiently utilized")
                    else:
                        st.info("üìä **CPU Normal**: Operating within expected range")

                elif metric_choice == 'usage_storage':
                    if current_val > avg_val * 1.15:
                        st.warning("üíæ **Storage Growth**: Monitor capacity planning")
                    else:
                        st.success("üíΩ **Storage Stable**: Growth within normal range")

                elif metric_choice == 'users_active':
                    if current_val > avg_val * 1.1:
                        st.success("üöÄ **User Growth**: Positive engagement trend")
                    elif current_val < avg_val * 0.9:
                        st.warning("üë• **User Decline**: Review engagement strategies")
                    else:
                        st.info("üë§ **User Stable**: Consistent engagement levels")




# ===== TAB 3: ENHANCED REGIONAL PERFORMANCE ANALYSIS =====
with tab3:
    st.subheader("üåç Regional Performance Analysis & Geographic Insights")

    # Load raw data for comprehensive regional analysis
    raw_data = fetch_api("data/raw")

    if not raw_data:
        st.error("‚ùå Unable to load regional data")
        st.stop()

    df_raw = pd.DataFrame(raw_data)
    df_raw['date'] = pd.to_datetime(df_raw['date'])

    # === REGIONAL ANALYSIS CONTROLS ===
    st.markdown("**üéõÔ∏è Regional Analysis Settings:**")

    # Single row of controls - different from Tab 2's multi-row approach
    ctrl_col1, ctrl_col2, ctrl_col3, ctrl_col4, ctrl_col5 = st.columns(5)

    with ctrl_col1:
        analysis_metric = st.selectbox(
            "üìä Analysis Metric",
            ["usage_cpu", "usage_storage", "users_active"],
            format_func=lambda x: {
                "usage_cpu": "üî• CPU Usage",
                "usage_storage": "üíæ Storage Usage", 
                "users_active": "üë• Active Users"
            }[x]
        )

    with ctrl_col2:
        view_type = st.selectbox(
            "üìà View Type",
            ["Performance", "Distribution", "Comparison", "Rankings"]
        )

    with ctrl_col3:
        time_window = st.selectbox(
            "‚è∞ Time Window", 
            ["Last 7 Days", "Last 30 Days", "Last 90 Days", "All Time"]
        )

    with ctrl_col4:
        resource_focus = st.selectbox(
            "‚öôÔ∏è Resource Focus",
            ["All Resources", "VM", "Storage", "Container"]
        )

    with ctrl_col5:
        show_insights = st.checkbox("üß† Show Insights", value=True)

    # Apply filters
    df_filtered = df_raw.copy()

    # Time filter
    if time_window != "All Time":
        days_map = {"Last 7 Days": 7, "Last 30 Days": 30, "Last 90 Days": 90}
        days = days_map[time_window]
        cutoff = df_filtered['date'].max() - timedelta(days=days)
        df_filtered = df_filtered[df_filtered['date'] >= cutoff]

    # Resource filter
    if resource_focus != "All Resources":
        df_filtered = df_filtered[df_filtered['resource_type'] == resource_focus]

    st.divider()

    # === REGIONAL PERFORMANCE OVERVIEW ===
    st.markdown("### üéØ Regional Performance Overview")

    # Calculate regional statistics
    regional_stats = df_filtered.groupby('region').agg({
        analysis_metric: ['mean', 'max', 'min', 'std'],
        'date': 'count'
    }).round(2)

    # Flatten column names
    regional_stats.columns = ['avg', 'peak', 'min', 'volatility', 'data_points']
    regional_stats = regional_stats.reset_index()

    # Regional performance cards
    regions = regional_stats['region'].tolist()
    perf_col1, perf_col2, perf_col3, perf_col4 = st.columns(4)

    colors = ['#0078d4', '#ff6b6b', '#4ecdc4', '#95e1d3']

    for idx, (col, region) in enumerate(zip([perf_col1, perf_col2, perf_col3, perf_col4], regions)):
        if idx < len(regions):
            stats = regional_stats[regional_stats['region'] == region].iloc[0]

            with col:
                # Create a colored container
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, {colors[idx % len(colors)]}22, {colors[idx % len(colors)]}44); 
                           padding: 1rem; border-radius: 8px; border-left: 4px solid {colors[idx % len(colors)]};">
                    <h4 style="color: {colors[idx % len(colors)]}; margin: 0;">{region}</h4>
                    <h2 style="margin: 0.5rem 0;">{stats['avg']:.1f}</h2>
                    <p style="margin: 0; font-size: 0.9rem;">Average {analysis_metric.replace('_', ' ').title()}</p>
                    <hr style="margin: 0.5rem 0; border: 1px solid {colors[idx % len(colors)]}33;">
                    <div style="display: flex; justify-content: space-between; font-size: 0.8rem;">
                        <span>Peak: {stats['peak']:.1f}</span>
                        <span>Min: {stats['min']:.1f}</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)

    st.divider()

    # === MAIN VISUALIZATION BASED ON VIEW TYPE ===
    if view_type == "Performance":
        st.markdown("### üìä Regional Performance Analysis")

        viz_col1, viz_col2 = st.columns([2, 1])

        with viz_col1:
            # Multi-metric regional comparison
            fig_performance = go.Figure()

            # Add bars for each metric component
            fig_performance.add_trace(go.Bar(
                name='Average Performance',
                x=regional_stats['region'],
                y=regional_stats['avg'],
                marker_color=colors,
                text=regional_stats['avg'].round(1),
                textposition='outside',
                hovertemplate='<b>%{x}</b><br>Average: %{y:.1f}<extra></extra>'
            ))

            # Add line for volatility (on secondary y-axis)
            fig_performance.add_trace(go.Scatter(
                x=regional_stats['region'],
                y=regional_stats['volatility'],
                mode='lines+markers',
                name='Volatility',
                yaxis='y2',
                line=dict(color='orange', width=3),
                marker=dict(size=8, color='orange'),
                hovertemplate='<b>%{x}</b><br>Volatility: %{y:.1f}<extra></extra>'
            ))

            fig_performance.update_layout(
                title=f"Regional {analysis_metric.replace('_', ' ').title()} Performance",
                xaxis_title="Region",
                yaxis=dict(title=f"{analysis_metric.replace('_', ' ').title()}", side='left'),
                yaxis2=dict(title="Volatility", overlaying='y', side='right', showgrid=False),
                height=450,
                showlegend=True,
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )

            st.plotly_chart(fig_performance, width="stretch")

        with viz_col2:
            # Regional efficiency ranking
            st.markdown("**üèÜ Regional Efficiency Ranking**")

            # Calculate efficiency (lower volatility + higher performance is better)
            regional_stats['efficiency_score'] = (
                (regional_stats['avg'] / regional_stats['avg'].max()) * 0.7 +
                (1 - regional_stats['volatility'] / regional_stats['volatility'].max()) * 0.3
            ) * 100

            ranked_regions = regional_stats.sort_values('efficiency_score', ascending=False)

            for idx, row in ranked_regions.iterrows():
                rank_emoji = ['ü•á', 'ü•à', 'ü•â', 'üèÖ'][min(idx, 3)]

                st.markdown(f"""
                <div style="background: #f8f9fa; padding: 0.8rem; margin: 0.3rem 0; 
                           border-radius: 6px; border-left: 3px solid {colors[idx % len(colors)]};">
                    <div style="display: flex; align-items: center; justify-content: space-between;">
                        <div style="display: flex; align-items: center;">
                            <span style="font-size: 1.2rem; margin-right: 0.5rem;">{rank_emoji}</span>
                            <strong>{row['region']}</strong>
                        </div>
                        <span style="font-weight: bold; color: {colors[idx % len(colors)]};">
                            {row['efficiency_score']:.0f}%
                        </span>
                    </div>
                    <div style="font-size: 0.8rem; color: #666; margin-top: 0.2rem;">
                        Avg: {row['avg']:.1f} | Volatility: {row['volatility']:.1f}
                    </div>
                </div>
                """, unsafe_allow_html=True)

    elif view_type == "Distribution":
        st.markdown("### ü•ß Regional Resource Distribution")

        dist_col1, dist_col2 = st.columns(2)

        with dist_col1:
            # Resource distribution pie chart
            regional_totals = df_filtered.groupby('region')[analysis_metric].sum().reset_index()

            fig_pie = go.Figure(data=[go.Pie(
                labels=regional_totals['region'],
                values=regional_totals[analysis_metric],
                hole=0.4,
                marker_colors=colors,
                textinfo='label+percent+value',
                texttemplate='%{label}<br>%{percent}<br>%{value:.1f}'
            )])

            fig_pie.update_layout(
                title=f"Total {analysis_metric.replace('_', ' ').title()} Distribution",
                height=400,
                annotations=[dict(
                    text=f'Regional<br>Distribution', 
                    x=0.5, y=0.5, 
                    font_size=14, 
                    showarrow=False
                )]
            )

            st.plotly_chart(fig_pie, width="stretch")

        with dist_col2:
            # Resource type breakdown by region
            resource_breakdown = df_filtered.groupby(['region', 'resource_type'])[analysis_metric].mean().reset_index()

            fig_breakdown = px.bar(
                resource_breakdown,
                x='region',
                y=analysis_metric,
                color='resource_type',
                title=f"Average {analysis_metric.replace('_', ' ').title()} by Resource Type",
                color_discrete_map={'VM': '#8e44ad', 'Storage': '#e67e22', 'Container': '#27ae60'},
                height=400
            )

            fig_breakdown.update_layout(
                xaxis_title="Region",
                yaxis_title=analysis_metric.replace('_', ' ').title(),
                legend=dict(title="Resource Type")
            )

            st.plotly_chart(fig_breakdown, width="stretch")

    elif view_type == "Comparison":
        st.markdown("### ‚öñÔ∏è Head-to-Head Regional Comparison")

        # Regional comparison matrix
        comparison_metrics = ['usage_cpu', 'usage_storage', 'users_active']

        # Create comparison data
        comparison_data = df_filtered.groupby('region')[comparison_metrics].mean().round(1)

        # Normalize for radar chart (0-100 scale)
        comparison_normalized = comparison_data.copy()
        for col in comparison_metrics:
            max_val = comparison_data[col].max()
            min_val = comparison_data[col].min()
            if max_val > min_val:
                comparison_normalized[col] = ((comparison_data[col] - min_val) / (max_val - min_val)) * 100
            else:
                comparison_normalized[col] = 50  # If all values are the same

        # Radar chart comparing regions
        fig_radar = go.Figure()

        for idx, region in enumerate(comparison_normalized.index):
            values = comparison_normalized.loc[region].tolist()
            values.append(values[0])  # Close the radar

            labels = ['CPU Usage', 'Storage Usage', 'User Activity']
            labels.append(labels[0])  # Close the radar

            fig_radar.add_trace(go.Scatterpolar(
                r=values,
                theta=labels,
                fill='toself',
                name=region,
                line_color=colors[idx % len(colors)],
                fillcolor=f'rgba({",".join([str(int(colors[idx % len(colors)][i:i+2], 16)) for i in (1, 3, 5)])}, 0.1)'
            ))

        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 100],
                    tickmode='linear',
                    tick0=0,
                    dtick=25
                )
            ),
            title="Regional Performance Radar Comparison (Normalized)",
            height=500,
            showlegend=True
        )

        st.plotly_chart(fig_radar, width="stretch")

        # Detailed comparison table
        st.markdown("**üìã Detailed Regional Comparison**")

        # Add ranking for each metric
        for col in comparison_metrics:
            comparison_data[f'{col}_rank'] = comparison_data[col].rank(ascending=False).astype(int)

        # Display formatted table
        display_data = comparison_data.copy()

        # Format the display
        st.dataframe(
            display_data.style.format({
                'usage_cpu': '{:.1f}%',
                'usage_storage': '{:.1f} GB',
                'users_active': '{:.0f}',
                'usage_cpu_rank': '#{:.0f}',
                'usage_storage_rank': '#{:.0f}',
                'users_active_rank': '#{:.0f}'
            }).background_gradient(subset=['usage_cpu', 'usage_storage', 'users_active'], cmap='RdYlBu_r'),
            width="stretch"
        )

    elif view_type == "Rankings":
        st.markdown("### üèÜ Regional Performance Rankings")

        # Create comprehensive ranking system
        ranking_metrics = ['avg', 'peak', 'volatility']
        regional_stats_rank = regional_stats.copy()

        # Calculate ranks (lower volatility is better, so we reverse it)
        regional_stats_rank['avg_rank'] = regional_stats_rank['avg'].rank(ascending=False)
        regional_stats_rank['peak_rank'] = regional_stats_rank['peak'].rank(ascending=False)
        regional_stats_rank['volatility_rank'] = regional_stats_rank['volatility'].rank(ascending=True)  # Lower is better

        # Calculate overall score
        regional_stats_rank['overall_score'] = (
            regional_stats_rank['avg_rank'] * 0.4 +
            regional_stats_rank['peak_rank'] * 0.3 +
            regional_stats_rank['volatility_rank'] * 0.3
        )

        regional_stats_rank['overall_rank'] = regional_stats_rank['overall_score'].rank()

        # Sort by overall rank
        ranked_data = regional_stats_rank.sort_values('overall_rank')

        rank_col1, rank_col2 = st.columns([2, 1])

        with rank_col1:
            # Ranking bar chart
            fig_rank = go.Figure()

            fig_rank.add_trace(go.Bar(
                x=ranked_data['region'],
                y=ranked_data['avg'],
                name='Average Performance',
                marker_color=[colors[i % len(colors)] for i in range(len(ranked_data))],
                text=[f"#{int(rank)}" for rank in ranked_data['overall_rank']],
                textposition='outside',
                hovertemplate='<b>%{x}</b><br>Avg: %{y:.1f}<br>Rank: #%{text}<extra></extra>'
            ))

            fig_rank.update_layout(
                title=f"Regional Rankings - {analysis_metric.replace('_', ' ').title()}",
                xaxis_title="Region (Ordered by Overall Rank)",
                yaxis_title=analysis_metric.replace('_', ' ').title(),
                height=400,
                showlegend=False
            )

            st.plotly_chart(fig_rank, width="stretch")

        with rank_col2:
            st.markdown("**üèÖ Overall Rankings**")

            for idx, (_, row) in enumerate(ranked_data.iterrows()):
                rank_icons = ['üëë', 'ü•á', 'ü•à', 'ü•â']
                icon = rank_icons[min(idx, 3)] if idx < 4 else f"#{idx+1}"

                st.markdown(f"""
                <div style="background: linear-gradient(135deg, {colors[idx % len(colors)]}22, {colors[idx % len(colors)]}44);
                           padding: 1rem; margin: 0.5rem 0; border-radius: 8px;
                           border-left: 4px solid {colors[idx % len(colors)]};">
                    <div style="display: flex; align-items: center; justify-content: space-between;">
                        <div style="display: flex; align-items: center;">
                            <span style="font-size: 1.5rem; margin-right: 0.5rem;">{icon}</span>
                            <div>
                                <strong style="color: {colors[idx % len(colors)]};">{row['region']}</strong>
                                <br><small>Overall Score: {row['overall_score']:.1f}</small>
                            </div>
                        </div>
                        <div style="text-align: right; font-size: 0.8rem;">
                            <div>Avg: #{int(row['avg_rank'])}</div>
                            <div>Peak: #{int(row['peak_rank'])}</div>
                            <div>Stability: #{int(row['volatility_rank'])}</div>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)

    # === REGIONAL HEATMAP (ALWAYS SHOWN) ===
    st.divider()
    st.markdown("### üî• Regional Performance Heatmap")

    # Create heatmap data
    heatmap_data = df_filtered.groupby(['region', 'resource_type'])[analysis_metric].mean().reset_index()
    heatmap_pivot = heatmap_data.pivot(index='region', columns='resource_type', values=analysis_metric)

    fig_heatmap = go.Figure(data=go.Heatmap(
        z=heatmap_pivot.values,
        x=heatmap_pivot.columns,
        y=heatmap_pivot.index,
        colorscale='RdYlBu_r',
        text=heatmap_pivot.values.round(1),
        texttemplate='%{text}',
        textfont={"size": 12},
        hoverongaps=False,
        colorbar=dict(title=analysis_metric.replace('_', ' ').title())
    ))

    fig_heatmap.update_layout(
        title=f"Regional-Resource {analysis_metric.replace('_', ' ').title()} Heatmap",
        xaxis_title="Resource Type",
        yaxis_title="Region",
        height=300
    )

    st.plotly_chart(fig_heatmap, width="stretch")

    # === REGIONAL INSIGHTS (OPTIONAL) ===
    if show_insights:
        st.divider()
        st.markdown("### üß† Regional Performance Insights")

        insights_col1, insights_col2, insights_col3 = st.columns(3)

        with insights_col1:
            st.markdown("**üèÜ Best Performers**")
            best_region = regional_stats.loc[regional_stats['avg'].idxmax()]
            most_stable = regional_stats.loc[regional_stats['volatility'].idxmin()]

            st.success(f"ü•á **Highest Average**: {best_region['region']} ({best_region['avg']:.1f})")
            st.info(f"üìä **Most Stable**: {most_stable['region']} (œÉ: {most_stable['volatility']:.1f})")

        with insights_col2:
            st.markdown("**üìä Key Statistics**")
            total_avg = regional_stats['avg'].mean()
            performance_gap = regional_stats['avg'].max() - regional_stats['avg'].min()

            st.metric("Global Average", f"{total_avg:.1f}")
            st.metric("Performance Gap", f"{performance_gap:.1f}")

        with insights_col3:
            st.markdown("**üí° Recommendations**")

            if performance_gap > total_avg * 0.2:  # 20% gap
                st.warning("‚ö†Ô∏è **High regional disparity** detected. Consider resource rebalancing.")
            else:
                st.success("‚úÖ **Balanced regional performance** across all regions.")

            high_volatility = regional_stats[regional_stats['volatility'] > regional_stats['volatility'].mean()]
            if len(high_volatility) > 0:
                volatile_regions = ", ".join(high_volatility['region'].tolist())
                st.info(f"üìà **Monitor volatility** in: {volatile_regions}")

    else:
        st.error("‚ùå Unable to load regional data")



# ===== TAB 4: FIXED RESOURCE TYPE ANALYSIS =====
with tab4:
    st.subheader("‚öôÔ∏è Resource Type Performance & Optimization Analysis")

    try:
        # Load raw data for comprehensive resource analysis
        raw_data = fetch_api("data/raw")

        if not raw_data:
            st.error("‚ùå Unable to load resource data")
            st.stop()

        df_raw = pd.DataFrame(raw_data)
        df_raw['date'] = pd.to_datetime(df_raw['date'])

        # Data validation
        required_columns = ['resource_type', 'usage_cpu', 'usage_storage', 'users_active']
        missing_columns = [col for col in required_columns if col not in df_raw.columns]

        if missing_columns:
            st.error(f"‚ùå Missing required columns: {missing_columns}")
            st.stop()

        # Clean data - handle NaN and negative values
        df_raw = df_raw.dropna(subset=required_columns)
        df_raw['usage_cpu'] = df_raw['usage_cpu'].clip(0, 100)
        df_raw['usage_storage'] = df_raw['usage_storage'].clip(0, None)
        df_raw['users_active'] = df_raw['users_active'].clip(0, None)

    except Exception as e:
        st.error(f"‚ùå Error loading data: {str(e)}")
        st.stop()

    # === RESOURCE-FOCUSED CONTROL PANEL ===
    st.markdown("**üîß Resource Analysis Dashboard:**")

    # Vertical control layout
    control_col1, control_col2 = st.columns([1, 3])

    with control_col1:
        st.markdown("**‚öôÔ∏è Resource Settings**")

        available_resources = df_raw['resource_type'].unique().tolist()
        selected_resources = st.multiselect(
            "Resource Types",
            options=available_resources,
            default=available_resources,
            help="Select which resource types to analyze"
        )

        analysis_dimension = st.radio(
            "Analysis Focus",
            options=["Utilization", "Efficiency", "Capacity", "Cost-Benefit"],
            help="Choose the primary analysis dimension"
        )

        benchmark_mode = st.toggle(
            "‚ö° Benchmark Mode",
            help="Compare resources against optimal performance thresholds"
        )

        show_optimization = st.toggle(
            "üéØ Show Optimization",
            value=True,
            help="Display optimization recommendations"
        )

    with control_col2:
        # Quick resource overview cards (horizontal layout)
        if selected_resources:
            st.markdown("**üìä Resource Overview**")

            try:
                overview_cols = st.columns(len(selected_resources))
                resource_colors = {'VM': '#8e44ad', 'Storage': '#e67e22', 'Container': '#27ae60'}

                for idx, resource in enumerate(selected_resources):
                    resource_data = df_raw[df_raw['resource_type'] == resource]

                    if not resource_data.empty:
                        # Safe calculations with error handling
                        avg_cpu = resource_data['usage_cpu'].mean() if len(resource_data) > 0 else 0
                        avg_storage = resource_data['usage_storage'].mean() if len(resource_data) > 0 else 0
                        avg_users = resource_data['users_active'].mean() if len(resource_data) > 0 else 0

                        color = resource_colors.get(resource, '#3498db')

                        with overview_cols[idx]:
                            st.markdown(f"""
                            <div style="background: linear-gradient(135deg, {color}22, {color}44);
                                       padding: 1rem; border-radius: 8px; text-align: center;
                                       border: 2px solid {color};">
                                <h3 style="color: {color}; margin: 0;">{resource}</h3>
                                <hr style="margin: 0.5rem 0; border-color: {color}66;">
                                <div style="font-size: 0.9rem;">
                                    <div>üî• CPU: {avg_cpu:.1f}%</div>
                                    <div>üíæ Storage: {avg_storage:.0f}GB</div>
                                    <div>üë• Users: {avg_users:.0f}</div>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"Error creating overview cards: {str(e)}")

    if not selected_resources:
        st.warning("‚ö†Ô∏è Please select at least one resource type to analyze")
        st.stop()

    # Filter data by selected resources
    df_filtered = df_raw[df_raw['resource_type'].isin(selected_resources)]

    if df_filtered.empty:
        st.warning("‚ö†Ô∏è No data available for selected resource types")
        st.stop()

    st.divider()

    try:
        # === MAIN ANALYSIS SECTION ===
        if analysis_dimension == "Utilization":
            st.markdown("### üìà Resource Utilization Analysis")

            util_col1, util_col2 = st.columns([2, 1])

            with util_col1:
                # FIXED: Import statement and error handling
                from plotly.subplots import make_subplots

                # Multi-resource utilization comparison
                fig_util = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=('CPU Utilization Pattern', 'Storage Usage Pattern', 
                                   'User Activity Pattern', 'Resource Efficiency Score'),
                    specs=[[{}, {}], [{}, {}]],
                    vertical_spacing=0.12,
                    horizontal_spacing=0.1
                )

                for idx, resource in enumerate(selected_resources):
                    color = resource_colors.get(resource, '#3498db')
                    resource_data = df_filtered[df_filtered['resource_type'] == resource]

                    if not resource_data.empty:
                        # FIXED: Safe groupby with error handling
                        try:
                            daily_data = resource_data.groupby('date').agg({
                                'usage_cpu': 'mean',
                                'usage_storage': 'mean',
                                'users_active': 'mean'
                            }).reset_index()

                            if not daily_data.empty:
                                # CPU utilization (subplot 1)
                                fig_util.add_trace(
                                    go.Scatter(x=daily_data['date'], y=daily_data['usage_cpu'], 
                                              name=f'{resource} CPU', line=dict(color=color, width=2)),
                                    row=1, col=1
                                )

                                # Storage utilization (subplot 2)  
                                fig_util.add_trace(
                                    go.Scatter(x=daily_data['date'], y=daily_data['usage_storage'],
                                              name=f'{resource} Storage', line=dict(color=color, width=2, dash='dot')),
                                    row=1, col=2
                                )

                                # User activity (subplot 3)
                                fig_util.add_trace(
                                    go.Scatter(x=daily_data['date'], y=daily_data['users_active'],
                                              name=f'{resource} Users', line=dict(color=color, width=2, dash='dash')),
                                    row=2, col=1
                                )

                                # FIXED: Safe efficiency calculation
                                efficiency = []
                                for _, row in daily_data.iterrows():
                                    if row['users_active'] > 0:
                                        eff = (row['usage_cpu'] / row['users_active']) * 10
                                    else:
                                        eff = row['usage_cpu']  # Fallback if no users
                                    efficiency.append(eff)

                                # Efficiency score (subplot 4)
                                fig_util.add_trace(
                                    go.Scatter(x=daily_data['date'], y=efficiency,
                                              name=f'{resource} Efficiency', line=dict(color=color, width=3)),
                                    row=2, col=2
                                )
                        except Exception as subplot_error:
                            st.warning(f"Error processing {resource} data: {str(subplot_error)}")

                fig_util.update_layout(height=600, showlegend=True, 
                                      title_text="Comprehensive Resource Utilization Dashboard")
                st.plotly_chart(fig_util, width="stretch")

            with util_col2:
                # Resource performance matrix
                st.markdown("**üéØ Performance Matrix**")

                try:
                    for resource in selected_resources:
                        resource_data = df_filtered[df_filtered['resource_type'] == resource]
                        color = resource_colors.get(resource, '#3498db')

                        if not resource_data.empty:
                            # FIXED: Safe calculations with bounds checking
                            cpu_avg = resource_data['usage_cpu'].mean()
                            cpu_peak = resource_data['usage_cpu'].max() 
                            utilization_rate = min(100, max(0, cpu_avg))  # Clamp between 0-100

                            # Performance scoring
                            if utilization_rate > 80:
                                performance_status = "üî¥ High Load"
                                performance_color = "#e74c3c"
                            elif utilization_rate > 60:
                                performance_status = "üü° Moderate Load"
                                performance_color = "#f39c12"
                            else:
                                performance_status = "üü¢ Optimal"
                                performance_color = "#27ae60"

                            st.markdown(f"""
                            <div style="background: white; padding: 1rem; margin: 0.5rem 0; 
                                       border-radius: 8px; border-left: 4px solid {color};
                                       box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                <div style="display: flex; justify-content: space-between; align-items: center;">
                                    <strong style="color: {color};">{resource}</strong>
                                    <span style="color: {performance_color}; font-weight: bold;">{performance_status}</span>
                                </div>
                                <hr style="margin: 0.5rem 0; border-color: #eee;">
                                <div style="font-size: 0.9rem;">
                                    <div>üìä Avg CPU: {cpu_avg:.1f}%</div>
                                    <div>‚ö° Peak CPU: {cpu_peak:.1f}%</div>
                                    <div>üéØ Utilization: {utilization_rate:.1f}%</div>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                except Exception as matrix_error:
                    st.error(f"Error creating performance matrix: {str(matrix_error)}")

        elif analysis_dimension == "Efficiency":
            st.markdown("### ‚ö° Resource Efficiency Analysis")

            eff_col1, eff_col2 = st.columns(2)

            with eff_col1:
                # Efficiency bubble chart
                st.markdown("**üéà Resource Efficiency Bubble Chart**")

                try:
                    efficiency_data = []
                    for resource in selected_resources:
                        resource_data = df_filtered[df_filtered['resource_type'] == resource]
                        color = resource_colors.get(resource, '#3498db')

                        if not resource_data.empty:
                            # FIXED: Safe efficiency calculations
                            total_users = resource_data['users_active'].sum()
                            avg_cpu = resource_data['usage_cpu'].mean()
                            avg_storage = resource_data['usage_storage'].mean()
                            avg_users = resource_data['users_active'].mean()

                            # Avoid division by zero
                            if avg_users > 0:
                                cpu_efficiency = avg_cpu / avg_users
                                storage_efficiency = avg_storage / avg_users
                            else:
                                cpu_efficiency = avg_cpu
                                storage_efficiency = avg_storage

                            efficiency_data.append({
                                'resource_type': resource,
                                'cpu_efficiency': cpu_efficiency,
                                'storage_efficiency': storage_efficiency,
                                'total_users': total_users,
                                'color': color
                            })

                    if efficiency_data:
                        eff_df = pd.DataFrame(efficiency_data)

                        fig_bubble = go.Figure()

                        for _, row in eff_df.iterrows():
                            # FIXED: Safe bubble size calculation
                            bubble_size = max(20, min(80, row['total_users'] / 10 if row['total_users'] > 0 else 20))

                            fig_bubble.add_trace(go.Scatter(
                                x=[row['cpu_efficiency']],
                                y=[row['storage_efficiency']],
                                mode='markers',
                                marker=dict(
                                    size=bubble_size,
                                    color=row['color'],
                                    opacity=0.7,
                                    line=dict(width=2, color='white')
                                ),
                                name=row['resource_type'],
                                text=f"{row['resource_type']}<br>Users: {row['total_users']:.0f}",
                                hovertemplate='<b>%{text}</b><br>CPU/User: %{x:.2f}<br>Storage/User: %{y:.1f}<extra></extra>'
                            ))

                        fig_bubble.update_layout(
                            title="Resource Efficiency: CPU vs Storage per User",
                            xaxis_title="CPU Usage per User (%)",
                            yaxis_title="Storage Usage per User (GB)",
                            height=400,
                            showlegend=True
                        )

                        st.plotly_chart(fig_bubble, width="stretch")
                    else:
                        st.warning("No efficiency data available")

                except Exception as bubble_error:
                    st.error(f"Error creating bubble chart: {str(bubble_error)}")

            with eff_col2:
                # Efficiency scoring
                st.markdown("**üèÜ Efficiency Scoring**")

                try:
                    efficiency_scores = []
                    for resource in selected_resources:
                        resource_data = df_filtered[df_filtered['resource_type'] == resource]
                        color = resource_colors.get(resource, '#3498db')

                        if not resource_data.empty:
                            # FIXED: Improved efficiency scoring logic
                            avg_cpu = resource_data['usage_cpu'].mean()
                            avg_users = resource_data['users_active'].mean()
                            avg_storage = resource_data['usage_storage'].mean()

                            # Efficiency metrics (higher is better)
                            cpu_efficiency = max(0, min(100, 100 - avg_cpu))  # Lower CPU usage is more efficient

                            if avg_cpu > 0:
                                user_efficiency = min(100, (avg_users / avg_cpu) * 50)  # Users per CPU unit
                            else:
                                user_efficiency = 50  # Neutral score

                            storage_efficiency = max(0, min(100, 100 - min(100, avg_storage / 20)))  # Normalized storage

                            # Overall score (weighted average)
                            overall_score = (cpu_efficiency * 0.4 + user_efficiency * 0.4 + storage_efficiency * 0.2)
                            overall_score = max(0, min(100, overall_score))

                            efficiency_scores.append({
                                'resource': resource,
                                'score': overall_score,
                                'cpu_eff': cpu_efficiency,
                                'user_eff': user_efficiency,
                                'storage_eff': storage_efficiency,
                                'color': color
                            })

                    # Sort by overall score
                    efficiency_scores.sort(key=lambda x: x['score'], reverse=True)

                    for idx, score_data in enumerate(efficiency_scores):
                        resource = score_data['resource']
                        score = score_data['score']
                        color = score_data['color']

                        # Determine grade
                        if score >= 80:
                            grade = "A+"
                            grade_color = "#27ae60"
                        elif score >= 70:
                            grade = "A"
                            grade_color = "#2ecc71"
                        elif score >= 60:
                            grade = "B+"
                            grade_color = "#f39c12"
                        elif score >= 50:
                            grade = "B"
                            grade_color = "#e67e22"
                        else:
                            grade = "C"
                            grade_color = "#e74c3c"

                        rank_emoji = ['ü•á', 'ü•à', 'ü•â'][min(idx, 2)] if len(efficiency_scores) > idx else f"#{idx+1}"

                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, {color}11, {color}22);
                                   padding: 1rem; margin: 0.5rem 0; border-radius: 8px;
                                   border: 2px solid {color};">
                            <div style="display: flex; justify-content: space-between; align-items: center;">
                                <div style="display: flex; align-items: center;">
                                    <span style="font-size: 1.5rem; margin-right: 0.5rem;">{rank_emoji}</span>
                                    <strong style="color: {color};">{resource}</strong>
                                </div>
                                <div style="text-align: right;">
                                    <div style="font-size: 1.2rem; font-weight: bold; color: {grade_color};">{grade}</div>
                                    <div style="font-size: 0.9rem;">Score: {score:.1f}</div>
                                </div>
                            </div>
                            <div style="margin-top: 0.5rem; font-size: 0.8rem; color: #666;">
                                <div style="display: flex; justify-content: space-between;">
                                    <span>CPU: {score_data['cpu_eff']:.1f}</span>
                                    <span>User: {score_data['user_eff']:.1f}</span>
                                </div>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

                except Exception as scoring_error:
                    st.error(f"Error creating efficiency scoring: {str(scoring_error)}")

        elif analysis_dimension == "Capacity":
            st.markdown("### üìä Resource Capacity Analysis")

            cap_col1, cap_col2 = st.columns([3, 1])

            with cap_col1:
                # Capacity utilization over time
                st.markdown("**üìà Capacity Utilization Timeline**")

                try:
                    fig_capacity = go.Figure()

                    for resource in selected_resources:
                        resource_data = df_filtered[df_filtered['resource_type'] == resource]
                        color = resource_colors.get(resource, '#3498db')

                        if not resource_data.empty:
                            # FIXED: Safe daily aggregation
                            try:
                                daily_data = resource_data.groupby('date').agg({
                                    'usage_cpu': 'max',
                                    'usage_storage': 'max',
                                    'users_active': 'max'
                                }).reset_index()

                                if not daily_data.empty:
                                    # Calculate capacity utilization percentage (assuming 100% CPU is max capacity)
                                    cpu_utilization = daily_data['usage_cpu'].clip(0, 100)

                                    fig_capacity.add_trace(go.Scatter(
                                        x=daily_data['date'],
                                        y=cpu_utilization,
                                        mode='lines+markers',
                                        name=f'{resource} Capacity',
                                        line=dict(color=color, width=3),
                                        hovertemplate=f'<b>{resource}</b><br>Date: %{{x}}<br>Capacity: %{{y:.1f}}%<extra></extra>'
                                    ))
                            except Exception as daily_error:
                                st.warning(f"Error processing daily data for {resource}: {str(daily_error)}")

                    # Add capacity thresholds
                    fig_capacity.add_hline(y=80, line_dash="dash", line_color="orange", 
                                          annotation_text="Warning Threshold (80%)")
                    fig_capacity.add_hline(y=95, line_dash="dash", line_color="red", 
                                          annotation_text="Critical Threshold (95%)")

                    fig_capacity.update_layout(
                        title="Resource Capacity Utilization Over Time",
                        xaxis_title="Date",
                        yaxis_title="Capacity Utilization (%)",
                        height=400,
                        yaxis=dict(range=[0, 110])
                    )

                    st.plotly_chart(fig_capacity, width="stretch")

                except Exception as capacity_error:
                    st.error(f"Error creating capacity chart: {str(capacity_error)}")

            with cap_col2:
                # Capacity status indicators
                st.markdown("**üö¶ Capacity Status**")

                try:
                    for resource in selected_resources:
                        resource_data = df_filtered[df_filtered['resource_type'] == resource]
                        color = resource_colors.get(resource, '#3498db')

                        if not resource_data.empty and len(resource_data) > 0:
                            # FIXED: Safe current and max calculation
                            current_cpu = resource_data['usage_cpu'].iloc[-1] if len(resource_data) > 0 else 0
                            max_cpu = resource_data['usage_cpu'].max()

                            # Capacity status
                            if max_cpu >= 95:
                                status = "üî¥ Critical"
                                status_color = "#e74c3c"
                            elif max_cpu >= 80:
                                status = "üü° Warning"
                                status_color = "#f39c12"
                            else:
                                status = "üü¢ Normal"
                                status_color = "#27ae60"

                            # FIXED: Safe trend calculation
                            capacity_projection = "Insufficient data"
                            if len(resource_data) > 14:  # Need at least 14 days for trend
                                try:
                                    recent_avg = resource_data['usage_cpu'].tail(7).mean()
                                    previous_avg = resource_data['usage_cpu'].head(7).mean()

                                    if recent_avg > previous_avg and previous_avg > 0:
                                        trend_rate = (recent_avg - previous_avg) / 7  # Daily trend
                                        if trend_rate > 0.1 and current_cpu < 100:  # Significant upward trend
                                            days_to_capacity = (100 - current_cpu) / trend_rate
                                            if days_to_capacity < 365:
                                                capacity_projection = f"{days_to_capacity:.0f} days"
                                            else:
                                                capacity_projection = "1+ year"
                                        else:
                                            capacity_projection = "Stable"
                                    else:
                                        capacity_projection = "Stable/Decreasing"
                                except:
                                    capacity_projection = "Calculation error"

                            st.markdown(f"""
                            <div style="background: white; padding: 1rem; margin: 0.5rem 0; 
                                       border-radius: 8px; border-left: 4px solid {color};
                                       box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                                    <strong style="color: {color};">{resource}</strong>
                                    <span style="color: {status_color}; font-weight: bold; font-size: 0.9rem;">{status}</span>
                                </div>
                                <div style="font-size: 0.9rem;">
                                    <div>Current: {current_cpu:.1f}%</div>
                                    <div>Peak: {max_cpu:.1f}%</div>
                                    <div style="margin-top: 0.3rem; font-size: 0.8rem; color: #666;">
                                        Time to Capacity:<br><strong>{capacity_projection}</strong>
                                    </div>
                                </div>
                                <div style="background: linear-gradient(90deg, {status_color}22 0%, transparent 100%);
                                           padding: 0.2rem; border-radius: 3px; margin-top: 0.3rem;">
                                    <div style="width: {min(100, max_cpu)}%; background: {status_color}; height: 4px; border-radius: 2px;"></div>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                except Exception as status_error:
                    st.error(f"Error creating capacity status: {str(status_error)}")

        elif analysis_dimension == "Cost-Benefit":
            st.markdown("### üí∞ Resource Cost-Benefit Analysis")

            cb_col1, cb_col2 = st.columns([2, 1])

            with cb_col1:
                # Cost-benefit matrix
                st.markdown("**üí∞ Resource Value Analysis**")

                try:
                    # FIXED: Safer cost-benefit calculations
                    cost_benefit_data = []
                    base_costs = {'VM': 1.0, 'Storage': 0.3, 'Container': 0.8}  # Relative cost per unit

                    for resource in selected_resources:
                        resource_data = df_filtered[df_filtered['resource_type'] == resource]
                        color = resource_colors.get(resource, '#3498db')

                        if not resource_data.empty:
                            # Calculate benefit metrics safely
                            avg_users_served = resource_data['users_active'].mean()
                            avg_cpu = resource_data['usage_cpu'].mean()

                            # Avoid division by zero in efficiency calculation
                            if avg_cpu > 0:
                                resource_efficiency = avg_users_served / avg_cpu
                            else:
                                resource_efficiency = avg_users_served  # Fallback

                            # Calculate cost metrics
                            estimated_cost = avg_cpu * base_costs.get(resource, 1.0)

                            # Safe cost per user calculation
                            if avg_users_served > 0:
                                cost_per_user = estimated_cost / avg_users_served
                            else:
                                cost_per_user = estimated_cost  # Fallback

                            # ROI calculation with safety checks
                            if estimated_cost > 0:
                                roi = (resource_efficiency * 100) / estimated_cost
                            else:
                                roi = resource_efficiency * 100  # Fallback

                            cost_benefit_data.append({
                                'resource': resource,
                                'cost': max(0.1, estimated_cost),  # Minimum cost to avoid zero
                                'benefit': max(0.1, resource_efficiency * 10),  # Scale and minimum
                                'roi': max(0, roi),
                                'cost_per_user': cost_per_user,
                                'users_served': avg_users_served,
                                'color': color
                            })

                    if cost_benefit_data:
                        cb_df = pd.DataFrame(cost_benefit_data)

                        # Cost-benefit scatter plot
                        fig_cb = go.Figure()

                        for _, row in cb_df.iterrows():
                            # FIXED: Safe bubble size calculation
                            bubble_size = max(20, min(60, row['users_served'] / 5 if row['users_served'] > 0 else 20))

                            fig_cb.add_trace(go.Scatter(
                                x=[row['cost']],
                                y=[row['benefit']],
                                mode='markers+text',
                                marker=dict(
                                    size=bubble_size,
                                    color=row['color'],
                                    opacity=0.7,
                                    line=dict(width=2, color='white')
                                ),
                                name=row['resource'],
                                text=row['resource'],
                                textposition='middle center',
                                textfont=dict(color='white', size=12, family='Arial Black'),
                                hovertemplate=f"<b>{row['resource']}</b><br>" +
                                             f"Cost: {row['cost']:.1f}<br>" +
                                             f"Benefit: {row['benefit']:.1f}<br>" +
                                             f"ROI: {row['roi']:.1f}%<br>" +
                                             f"Users: {row['users_served']:.0f}<extra></extra>"
                            ))

                        # Safe quadrant calculation
                        max_cost = cb_df['cost'].max() * 1.1 if cb_df['cost'].max() > 0 else 1
                        max_benefit = cb_df['benefit'].max() * 1.1 if cb_df['benefit'].max() > 0 else 1

                        fig_cb.add_shape(type="rect", x0=0, y0=max_benefit*0.7, x1=max_cost*0.5, y1=max_benefit,
                                        fillcolor="rgba(39, 174, 96, 0.1)", line=dict(color="rgba(39, 174, 96, 0.3)"))
                        fig_cb.add_annotation(x=max_cost*0.25, y=max_benefit*0.85, text="High Value<br>(Low Cost, High Benefit)",
                                            showarrow=False, font=dict(size=10, color="#27ae60"))

                        fig_cb.update_layout(
                            title="Cost-Benefit Analysis: Resource Value Matrix",
                            xaxis_title="Relative Cost",
                            yaxis_title="Relative Benefit",
                            height=400,
                            showlegend=False
                        )

                        st.plotly_chart(fig_cb, width="stretch")
                    else:
                        st.warning("No cost-benefit data available")

                except Exception as cb_error:
                    st.error(f"Error creating cost-benefit analysis: {str(cb_error)}")

            with cb_col2:
                # ROI ranking
                st.markdown("**üìà ROI Rankings**")

                try:
                    if 'cb_df' in locals() and not cb_df.empty:
                        cb_df_sorted = cb_df.sort_values('roi', ascending=False)

                        for idx, (_, row) in enumerate(cb_df_sorted.iterrows()):
                            resource = row['resource']
                            roi = row['roi']
                            color = row['color']

                            # ROI status
                            if roi >= 20:
                                roi_status = "üöÄ Excellent"
                                roi_color = "#27ae60"
                            elif roi >= 15:
                                roi_status = "‚úÖ Good"
                                roi_color = "#2ecc71"
                            elif roi >= 10:
                                roi_status = "‚ö†Ô∏è Average"
                                roi_color = "#f39c12"
                            else:
                                roi_status = "‚ùå Poor"
                                roi_color = "#e74c3c"

                            rank_emoji = ['ü•á', 'ü•à', 'ü•â'][min(idx, 2)] if idx < 3 else f"#{idx+1}"

                            st.markdown(f"""
                            <div style="background: linear-gradient(135deg, {color}15, {color}25);
                                       padding: 1rem; margin: 0.5rem 0; border-radius: 8px;
                                       border-left: 4px solid {color};">
                                <div style="display: flex; justify-content: space-between; align-items: center;">
                                    <div style="display: flex; align-items: center;">
                                        <span style="font-size: 1.2rem; margin-right: 0.5rem;">{rank_emoji}</span>
                                        <strong style="color: {color};">{resource}</strong>
                                    </div>
                                    <span style="color: {roi_color}; font-weight: bold; font-size: 0.9rem;">{roi_status}</span>
                                </div>
                                <hr style="margin: 0.5rem 0; border-color: {color}44;">
                                <div style="font-size: 0.9rem;">
                                    <div><strong>ROI: {roi:.1f}%</strong></div>
                                    <div>Cost/User: {row['cost_per_user']:.2f}</div>
                                    <div>Users Served: {row['users_served']:.0f}</div>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.info("No ROI data available")

                except Exception as roi_error:
                    st.error(f"Error creating ROI rankings: {str(roi_error)}")

        # === OPTIMIZATION RECOMMENDATIONS (ALWAYS SHOWN IF ENABLED) ===
        if show_optimization:
            st.divider()
            st.markdown("### üéØ Resource Optimization Recommendations")

            try:
                opt_col1, opt_col2, opt_col3 = st.columns(3)

                # Generate recommendations based on analysis
                recommendations = []

                for resource in selected_resources:
                    resource_data = df_filtered[df_filtered['resource_type'] == resource]

                    if not resource_data.empty:
                        # FIXED: Safe recommendation calculations
                        avg_cpu = resource_data['usage_cpu'].mean()
                        max_cpu = resource_data['usage_cpu'].max()

                        # Safe volatility calculation
                        if len(resource_data) > 1:
                            volatility = resource_data['usage_cpu'].std()
                        else:
                            volatility = 0

                        if max_cpu > 90:
                            recommendations.append({
                                'type': 'üö® Critical',
                                'resource': resource,
                                'message': f"{resource} approaching capacity limits",
                                'action': "Consider scaling up or load balancing",
                                'priority': 'high'
                            })
                        elif avg_cpu < 30 and volatility < 10:
                            recommendations.append({
                                'type': 'üí° Efficiency',
                                'resource': resource,
                                'message': f"{resource} is underutilized",
                                'action': "Consider consolidation or downsizing",
                                'priority': 'medium'
                            })
                        elif volatility > 25:
                            recommendations.append({
                                'type': 'üìä Stability',
                                'resource': resource,
                                'message': f"{resource} shows high variability",
                                'action': "Implement auto-scaling or load smoothing",
                                'priority': 'medium'
                            })

                if not recommendations:
                    recommendations.append({
                        'type': '‚úÖ Optimal',
                        'resource': 'All Resources',
                        'message': 'Resources are operating within optimal ranges',
                        'action': 'Continue monitoring for trends',
                        'priority': 'low'
                    })

                # Display recommendations in columns
                rec_cols = [opt_col1, opt_col2, opt_col3]
                priority_colors = {'high': '#e74c3c', 'medium': '#f39c12', 'low': '#27ae60'}

                for idx, rec in enumerate(recommendations[:3]):  # Show top 3 recommendations
                    with rec_cols[idx % 3]:
                        priority_color = priority_colors.get(rec['priority'], '#3498db')

                        st.markdown(f"""
                        <div style="background: white; padding: 1rem; border-radius: 8px;
                                   border-left: 4px solid {priority_color}; box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                                   margin-bottom: 1rem;">
                            <div style="color: {priority_color}; font-weight: bold; margin-bottom: 0.5rem;">
                                {rec['type']}
                            </div>
                            <div style="font-weight: bold; margin-bottom: 0.3rem;">
                                {rec['resource']}
                            </div>
                            <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.5rem;">
                                {rec['message']}
                            </div>
                            <div style="background: {priority_color}22; padding: 0.5rem; border-radius: 4px;">
                                <strong>Action:</strong> {rec['action']}
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

                # Additional recommendations if more than 3
                if len(recommendations) > 3:
                    with st.expander(f"üìã View All {len(recommendations)} Recommendations"):
                        for rec in recommendations[3:]:
                            priority_color = priority_colors.get(rec['priority'], '#3498db')
                            st.markdown(f"**{rec['type']}** - {rec['resource']}: {rec['message']} ‚Üí *{rec['action']}*")

            except Exception as opt_error:
                st.error(f"Error generating recommendations: {str(opt_error)}")

    except Exception as main_error:
        st.error(f"‚ùå Main analysis error: {str(main_error)}")
        st.info("Please check your data and try again")





# ===== TAB 5: CORRECTED CORRELATION & STATISTICAL ANALYSIS =====
with tab5:
    st.subheader("üîó Correlation Analysis & Statistical Insights")

    try:
        # Load raw data for comprehensive correlation analysis
        raw_data = fetch_api("data/raw")

        if not raw_data:
            st.error("‚ùå Unable to load correlation data")
            st.stop()

        df_raw = pd.DataFrame(raw_data)
        df_raw['date'] = pd.to_datetime(df_raw['date'])

        # Data validation for correlation analysis
        numeric_columns = ['usage_cpu', 'usage_storage', 'users_active', 'economic_index', 'cloud_market_demand']
        available_columns = [col for col in numeric_columns if col in df_raw.columns]

        if len(available_columns) < 2:
            st.error("‚ùå Insufficient numeric columns for correlation analysis")
            st.stop()

        # Clean data for correlation analysis
        df_clean = df_raw[available_columns + ['region', 'resource_type', 'date']].dropna()

        # === CORRELATION ANALYSIS CONTROL PANEL (UNIQUE GRID LAYOUT) ===
        st.markdown("**üî¨ Statistical Analysis Configuration:**")

        # Grid layout (different from other tabs' layouts)
        config_container = st.container()

        with config_container:
            # Top row - main controls
            main_col1, main_col2, main_col3, main_col4 = st.columns(4)

            with main_col1:
                correlation_method = st.selectbox(
                    "üìä Correlation Method",
                    options=['pearson', 'spearman', 'kendall'],
                    format_func=lambda x: {
                        'pearson': 'üìà Pearson (Linear)',
                        'spearman': 'üìâ Spearman (Rank)',
                        'kendall': 'üîÑ Kendall (Tau)'
                    }[x],
                    help="Choose correlation calculation method"
                )

            with main_col2:
                analysis_scope = st.selectbox(
                    "üéØ Analysis Scope",
                    options=['Overall', 'By Region', 'By Resource', 'Time Series'],
                    help="Define the scope of correlation analysis"
                )

            with main_col3:
                significance_level = st.selectbox(
                    "üìè Significance Level",
                    options=[0.05, 0.01, 0.001],
                    format_func=lambda x: f"Œ± = {x}",
                    help="Statistical significance threshold"
                )

            with main_col4:
                min_correlation = st.slider(
                    "üéöÔ∏è Min Correlation",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.1,
                    step=0.05,
                    help="Minimum correlation magnitude to display"
                )

            # Bottom row - visualization controls
            viz_col1, viz_col2, viz_col3, viz_col4 = st.columns(4)

            with viz_col1:
                show_p_values = st.checkbox("üìä Show P-Values", value=True)

            with viz_col2:
                advanced_stats = st.checkbox("üßÆ Advanced Statistics", value=True)

            with viz_col3:
                interactive_mode = st.checkbox("üéÆ Interactive Mode", value=True)

            with viz_col4:
                export_results = st.checkbox("üíæ Export Results", value=False)

        st.divider()

        # Calculate correlations based on scope
        if analysis_scope == 'Overall':
            correlation_data = df_clean[available_columns].corr(method=correlation_method)
            analysis_groups = {'Overall': df_clean}
        elif analysis_scope == 'By Region':
            analysis_groups = {region: group for region, group in df_clean.groupby('region')}
        elif analysis_scope == 'By Resource':
            analysis_groups = {resource: group for resource, group in df_clean.groupby('resource_type')}
        elif analysis_scope == 'Time Series':
            # Monthly aggregation for time series analysis
            df_clean['month'] = df_clean['date'].dt.to_period('M')
            analysis_groups = {str(month): group for month, group in df_clean.groupby('month')}

        # === MAIN CORRELATION VISUALIZATION ===
        if analysis_scope == 'Overall':
            st.markdown("### üå°Ô∏è Overall Correlation Heatmap")

            # Enhanced correlation heatmap
            correlation_matrix = df_clean[available_columns].corr(method=correlation_method)

            # Calculate p-values if requested
            if show_p_values:
                import scipy.stats as stats
                p_values = pd.DataFrame(index=correlation_matrix.index, columns=correlation_matrix.columns)

                for i in correlation_matrix.index:
                    for j in correlation_matrix.columns:
                        if i != j:
                            try:
                                corr, p_val = stats.pearsonr(df_clean[i].dropna(), df_clean[j].dropna())
                                p_values.loc[i, j] = p_val
                            except:
                                p_values.loc[i, j] = 1.0  # No significance if calculation fails
                        else:
                            p_values.loc[i, j] = 0.0

                # Create significance mask
                significance_mask = p_values < significance_level

            # FIXED: Create enhanced heatmap with corrected colorbar properties
            fig_heatmap = go.Figure()

            # Add correlation heatmap with FIXED colorbar configuration
            heatmap_trace = go.Heatmap(
                z=correlation_matrix.values,
                x=correlation_matrix.columns,
                y=correlation_matrix.index,
                colorscale='RdBu',
                zmid=0,
                zmin=-1,
                zmax=1,
                text=correlation_matrix.values.round(3),
                texttemplate='%{text}',
                textfont={"size": 12, "color": "white"},
                hoverongaps=False,
                colorbar=dict(
                    title="Correlation Coefficient",
                    # REMOVED: titleside (not supported in this Plotly version)
                    # REPLACED WITH: Standard colorbar properties
                    x=1.02,  # Position colorbar to the right
                    xanchor='left',
                    tickmode="linear",
                    tick0=-1,
                    dtick=0.5,
                    len=0.9  # Length of colorbar
                )
            )

            fig_heatmap.add_trace(heatmap_trace)

            # Add significance markers if p-values are shown
            if show_p_values and 'significance_mask' in locals():
                for i, row in enumerate(correlation_matrix.index):
                    for j, col in enumerate(correlation_matrix.columns):
                        try:
                            if significance_mask.iloc[i, j] and abs(correlation_matrix.iloc[i, j]) >= min_correlation:
                                fig_heatmap.add_shape(
                                    type="rect",
                                    x0=j-0.4, y0=i-0.4, x1=j+0.4, y1=i+0.4,
                                    line=dict(color="yellow", width=3),
                                    fillcolor="rgba(0,0,0,0)"
                                )
                        except:
                            continue  # Skip if significance calculation failed

            fig_heatmap.update_layout(
                title=f"Correlation Matrix ({correlation_method.title()} Method)",
                xaxis_title="Variables",
                yaxis_title="Variables",
                height=500,
                font=dict(size=12)
            )

            st.plotly_chart(fig_heatmap, width="stretch")

            # Correlation insights
            if advanced_stats:
                with st.expander("üîç Correlation Insights"):
                    insights_col1, insights_col2 = st.columns(2)

                    with insights_col1:
                        st.markdown("**üìà Strongest Correlations:**")

                        # Find strongest correlations
                        correlations_list = []
                        for i in range(len(correlation_matrix.columns)):
                            for j in range(i+1, len(correlation_matrix.columns)):
                                var1 = correlation_matrix.columns[i]
                                var2 = correlation_matrix.columns[j]
                                corr_val = correlation_matrix.iloc[i, j]
                                if abs(corr_val) >= min_correlation and not np.isnan(corr_val):
                                    correlations_list.append({
                                        'pair': f"{var1} ‚Üî {var2}",
                                        'correlation': corr_val,
                                        'strength': 'Strong' if abs(corr_val) >= 0.7 else 'Moderate' if abs(corr_val) >= 0.3 else 'Weak'
                                    })

                        # Sort by absolute correlation
                        correlations_list.sort(key=lambda x: abs(x['correlation']), reverse=True)

                        if correlations_list:
                            for corr_data in correlations_list[:5]:  # Show top 5
                                strength_color = {
                                    'Strong': '#27ae60',
                                    'Moderate': '#f39c12', 
                                    'Weak': '#95a5a6'
                                }[corr_data['strength']]

                                st.markdown(f"""
                                <div style="background: {strength_color}22; padding: 0.5rem; margin: 0.3rem 0; border-radius: 6px;
                                           border-left: 3px solid {strength_color};">
                                    <strong>{corr_data['pair']}</strong><br>
                                    <span style="color: {strength_color};">
                                        r = {corr_data['correlation']:.3f} ({corr_data['strength']})
                                    </span>
                                </div>
                                """, unsafe_allow_html=True)
                        else:
                            st.info("No significant correlations found above the minimum threshold")

                    with insights_col2:
                        st.markdown("**üìä Statistical Summary:**")

                        # Calculate summary statistics
                        abs_correlations = np.abs(correlation_matrix.values)
                        # Remove diagonal (self-correlations) and get upper triangle
                        mask = np.triu(np.ones_like(abs_correlations, dtype=bool), k=1)
                        abs_correlations = abs_correlations[mask]

                        # Remove NaN values
                        abs_correlations = abs_correlations[~np.isnan(abs_correlations)]

                        if len(abs_correlations) > 0:
                            st.metric("üéØ Average Correlation", f"{np.mean(abs_correlations):.3f}")
                            st.metric("üìè Max Correlation", f"{np.max(abs_correlations):.3f}")
                            st.metric("üìê Std Deviation", f"{np.std(abs_correlations):.3f}")

                            # Correlation strength distribution
                            strong_count = sum(1 for c in abs_correlations if c >= 0.7)
                            moderate_count = sum(1 for c in abs_correlations if 0.3 <= c < 0.7)
                            weak_count = sum(1 for c in abs_correlations if c < 0.3)

                            st.markdown(f"""
                            **üîç Correlation Distribution:**
                            - üü¢ Strong (‚â•0.7): {strong_count}
                            - üü° Moderate (0.3-0.7): {moderate_count}  
                            - ‚ö™ Weak (<0.3): {weak_count}
                            """)
                        else:
                            st.warning("No valid correlations calculated")

        else:
            # Multi-group correlation analysis
            st.markdown(f"### üìä Correlation Analysis: {analysis_scope}")

            # Create comparison visualization
            group_correlations = {}

            # Calculate correlations for each group
            for group_name, group_data in list(analysis_groups.items())[:6]:  # Limit to 6 groups for performance
                if len(group_data) > 3:  # Need minimum data for correlation
                    try:
                        group_corr = group_data[available_columns].corr(method=correlation_method)
                        # Check if correlation matrix has valid values
                        if not group_corr.isnull().all().all():
                            group_correlations[group_name] = group_corr
                    except:
                        continue  # Skip groups with calculation issues

            if group_correlations:
                # Multi-group heatmap comparison
                n_groups = len(group_correlations)
                cols_per_row = 2
                n_rows = (n_groups + cols_per_row - 1) // cols_per_row

                from plotly.subplots import make_subplots

                fig_multi = make_subplots(
                    rows=n_rows,
                    cols=cols_per_row,
                    subplot_titles=list(group_correlations.keys()),
                    vertical_spacing=0.08,
                    horizontal_spacing=0.05
                )

                for idx, (group_name, corr_matrix) in enumerate(group_correlations.items()):
                    row = (idx // cols_per_row) + 1
                    col = (idx % cols_per_row) + 1

                    # FIXED: Simplified colorbar configuration for subplots
                    fig_multi.add_trace(
                        go.Heatmap(
                            z=corr_matrix.values,
                            x=corr_matrix.columns,
                            y=corr_matrix.index,
                            colorscale='RdBu',
                            zmid=0,
                            zmin=-1,
                            zmax=1,
                            showscale=(idx == 0),  # Show colorbar only for first plot
                            text=corr_matrix.values.round(2),
                            texttemplate='%{text}',
                            textfont={"size": 8},
                            hoverongaps=False
                        ),
                        row=row, col=col
                    )

                fig_multi.update_layout(
                    title=f"Correlation Comparison: {analysis_scope}",
                    height=300 * n_rows,
                    showlegend=False
                )

                st.plotly_chart(fig_multi, width="stretch")
            else:
                st.warning("‚ö†Ô∏è No valid correlation data for selected groups")

        # === INTERACTIVE CORRELATION EXPLORER ===
        if interactive_mode:
            st.divider()
            st.markdown("### üéÆ Interactive Correlation Explorer")

            explorer_col1, explorer_col2 = st.columns([1, 2])

            with explorer_col1:
                st.markdown("**üéõÔ∏è Variable Selection:**")

                var_x = st.selectbox(
                    "X-Axis Variable",
                    options=available_columns,
                    index=0 if available_columns else None
                )

                var_y = st.selectbox(
                    "Y-Axis Variable", 
                    options=available_columns,
                    index=1 if len(available_columns) > 1 else 0
                )

                color_by = st.selectbox(
                    "Color By",
                    options=['None', 'region', 'resource_type'],
                    index=1
                )

                size_by = st.selectbox(
                    "Size By",
                    options=['None'] + available_columns,
                    index=0
                )

                # Correlation calculation for selected pair
                if var_x and var_y and var_x != var_y:
                    try:
                        correlation_value = df_clean[var_x].corr(df_clean[var_y], method=correlation_method)

                        if not np.isnan(correlation_value):
                            # Determine correlation strength and color
                            if abs(correlation_value) >= 0.7:
                                strength = "Strong"
                                strength_color = "#27ae60"
                            elif abs(correlation_value) >= 0.3:
                                strength = "Moderate"
                                strength_color = "#f39c12"
                            else:
                                strength = "Weak"
                                strength_color = "#95a5a6"

                            st.markdown(f"""
                            <div style="background: {strength_color}22; padding: 1rem; border-radius: 8px;
                                       border-left: 4px solid {strength_color}; text-align: center;">
                                <h3 style="color: {strength_color}; margin: 0;">{correlation_value:.3f}</h3>
                                <p style="margin: 0.5rem 0 0 0;">{strength} Correlation</p>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.warning("‚ö†Ô∏è Cannot calculate correlation for selected variables")
                    except Exception as corr_error:
                        st.error(f"Error calculating correlation: {str(corr_error)}")

            with explorer_col2:
                if var_x and var_y and var_x != var_y:
                    try:
                        # Create interactive scatter plot
                        scatter_fig = go.Figure()

                        if color_by != 'None' and color_by in df_clean.columns:
                            # Group by color variable
                            color_map = {
                                'region': {'East US': '#0078d4', 'West US': '#ff6b6b', 'North Europe': '#4ecdc4', 'Southeast Asia': '#95e1d3'},
                                'resource_type': {'VM': '#8e44ad', 'Storage': '#e67e22', 'Container': '#27ae60'}
                            }

                            for group_value in df_clean[color_by].unique():
                                group_data = df_clean[df_clean[color_by] == group_value]

                                # Calculate size values if specified
                                if size_by != 'None' and size_by in available_columns:
                                    sizes = group_data[size_by]
                                    # Normalize sizes to reasonable range
                                    size_range = sizes.max() - sizes.min()
                                    if size_range > 0:
                                        normalized_sizes = ((sizes - sizes.min()) / size_range * 30) + 10
                                    else:
                                        normalized_sizes = [15] * len(sizes)
                                else:
                                    normalized_sizes = 8

                                color = color_map.get(color_by, {}).get(group_value, '#3498db')

                                scatter_fig.add_trace(go.Scatter(
                                    x=group_data[var_x],
                                    y=group_data[var_y],
                                    mode='markers',
                                    name=str(group_value),
                                    marker=dict(
                                        color=color,
                                        size=normalized_sizes,
                                        opacity=0.7,
                                        line=dict(width=1, color='white')
                                    ),
                                    hovertemplate=f'<b>{group_value}</b><br>' +
                                                 f'{var_x}: %{{x:.2f}}<br>' +
                                                 f'{var_y}: %{{y:.2f}}<br>' +
                                                 (f'{size_by}: %{{marker.size:.1f}}<br>' if size_by != 'None' else '') +
                                                 '<extra></extra>'
                                ))
                        else:
                            # Single series scatter plot
                            if size_by != 'None' and size_by in available_columns:
                                sizes = df_clean[size_by]
                                size_range = sizes.max() - sizes.min()
                                if size_range > 0:
                                    normalized_sizes = ((sizes - sizes.min()) / size_range * 30) + 10
                                else:
                                    normalized_sizes = [15] * len(sizes)
                            else:
                                normalized_sizes = 8

                            scatter_fig.add_trace(go.Scatter(
                                x=df_clean[var_x],
                                y=df_clean[var_y],
                                mode='markers',
                                name='Data Points',
                                marker=dict(
                                    color='#3498db',
                                    size=normalized_sizes,
                                    opacity=0.7
                                ),
                                hovertemplate=f'{var_x}: %{{x:.2f}}<br>' +
                                             f'{var_y}: %{{y:.2f}}<br>' +
                                             '<extra></extra>'
                            ))

                        # Add trend line
                        try:
                            x_clean = df_clean[var_x].dropna()
                            y_clean = df_clean[var_y].dropna()

                            # Align the data
                            common_idx = x_clean.index.intersection(y_clean.index)
                            x_aligned = x_clean.loc[common_idx]
                            y_aligned = y_clean.loc[common_idx]

                            if len(x_aligned) > 1:
                                z = np.polyfit(x_aligned, y_aligned, 1)
                                p = np.poly1d(z)
                                x_trend = np.linspace(x_aligned.min(), x_aligned.max(), 100)

                                scatter_fig.add_trace(go.Scatter(
                                    x=x_trend,
                                    y=p(x_trend),
                                    mode='lines',
                                    name='Trend Line',
                                    line=dict(color='red', width=2, dash='dash'),
                                    hovertemplate='Trend Line<extra></extra>'
                                ))
                        except:
                            pass  # Skip trend line if calculation fails

                        scatter_fig.update_layout(
                            title=f"Interactive Correlation: {var_x} vs {var_y}",
                            xaxis_title=var_x.replace('_', ' ').title(),
                            yaxis_title=var_y.replace('_', ' ').title(),
                            height=400,
                            showlegend=True,
                            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                        )

                        st.plotly_chart(scatter_fig, width="stretch")

                    except Exception as scatter_error:
                        st.error(f"Error creating scatter plot: {str(scatter_error)}")

        # === ADVANCED STATISTICAL ANALYSIS ===
        if advanced_stats:
            st.divider()
            st.markdown("### üìà Advanced Statistical Analysis")

            # Simplified version to avoid complexity
            st.markdown("**üß™ Correlation Summary**")

            # Create a simple summary table
            if 'correlation_matrix' in locals():
                summary_data = []
                for i in range(len(correlation_matrix.columns)):
                    for j in range(i+1, len(correlation_matrix.columns)):
                        var1 = correlation_matrix.columns[i]
                        var2 = correlation_matrix.columns[j]
                        corr_val = correlation_matrix.iloc[i, j]

                        if not np.isnan(corr_val) and abs(corr_val) >= min_correlation:
                            summary_data.append({
                                'Variable 1': var1,
                                'Variable 2': var2,
                                'Correlation': f"{corr_val:.3f}",
                                'Strength': 'Strong' if abs(corr_val) >= 0.7 else 'Moderate' if abs(corr_val) >= 0.3 else 'Weak'
                            })

                if summary_data:
                    summary_df = pd.DataFrame(summary_data)
                    st.dataframe(summary_df, width="stretch")
                else:
                    st.info("No correlations above the minimum threshold found")

        # === EXPORT RESULTS ===
        if export_results:
            st.divider()
            st.markdown("### üíæ Export Analysis Results")

            if 'correlation_matrix' in locals():
                csv_data = correlation_matrix.to_csv()
                st.download_button(
                    label="üìä Download Correlation Matrix",
                    data=csv_data,
                    file_name=f"correlation_matrix_{correlation_method}.csv",
                    mime="text/csv"
                )
            else:
                st.warning("‚ö†Ô∏è No correlation matrix available for export")

    except Exception as main_error:
        st.error(f"‚ùå Main correlation analysis error: {str(main_error)}")
        st.info("Please check your data and try again")


# ===== TAB 6: HOLIDAY EFFECTS =====

# ===== CORRECTED MERGED TAB 6: SEASONAL BEHAVIOR & USER ENGAGEMENT ANALYSIS =====
with tab6:
    st.subheader("üéÑ Seasonal Behavior & User Engagement Intelligence")

    try:
        # Load raw data for comprehensive seasonal and engagement analysis
        raw_data = fetch_api("data/raw")

        if not raw_data:
            st.error("‚ùå Unable to load seasonal behavior data")
            st.stop()

        df_raw = pd.DataFrame(raw_data)
        df_raw['date'] = pd.to_datetime(df_raw['date'])

        # Enhanced date features for seasonal analysis
        df_raw['day_of_week'] = df_raw['date'].dt.day_name()
        df_raw['month'] = df_raw['date'].dt.month
        df_raw['month_name'] = df_raw['date'].dt.month_name()
        df_raw['day_of_month'] = df_raw['date'].dt.day
        df_raw['quarter'] = df_raw['date'].dt.quarter
        df_raw['week_of_year'] = df_raw['date'].dt.isocalendar().week

        # Create holiday indicator (simulated based on weekends and common dates)
        weekend_mask = df_raw['date'].dt.weekday >= 5  # Saturday=5, Sunday=6
        month_day_holidays = [
            (1, 1),   # New Year
            (7, 4),   # July 4th
            (12, 25), # Christmas
            (12, 31)  # New Year's Eve
        ]
        holiday_mask = df_raw[['month', 'day_of_month']].apply(
            lambda x: (x['month'], x['day_of_month']) in month_day_holidays, axis=1
        )
        df_raw['is_holiday'] = (weekend_mask | holiday_mask).astype(int)

        # Calculate user engagement metrics
        df_raw['cpu_per_user'] = df_raw['usage_cpu'] / (df_raw['users_active'] + 1)  # Avoid division by zero
        df_raw['storage_per_user'] = df_raw['usage_storage'] / (df_raw['users_active'] + 1)
        df_raw['user_efficiency'] = df_raw['users_active'] / (df_raw['usage_cpu'] + 1) * 100  # Users per CPU unit

        # Clean data
        df_clean = df_raw.dropna()

        # === BEHAVIORAL ANALYSIS CONTROL CENTER (UNIQUE DASHBOARD DESIGN) ===
        st.markdown("**üéØ Behavioral Analysis Control Center:**")

        # Three-tier control layout (different from all other tabs)
        tier1_container = st.container()
        tier2_container = st.container()
        tier3_container = st.container()

        with tier1_container:
            # Tier 1: Primary Analysis Selection
            primary_col1, primary_col2, primary_col3 = st.columns(3)

            with primary_col1:
                analysis_focus = st.selectbox(
                    "üéØ Analysis Focus",
                    options=['Seasonal Patterns', 'Holiday Effects', 'User Behavior', 'Engagement Efficiency'],
                    help="Choose the primary behavioral analysis focus"
                )

            with primary_col2:
                time_granularity = st.selectbox(
                    "‚è∞ Time Granularity",
                    options=['Daily', 'Weekly', 'Monthly', 'Quarterly'],
                    index=2,  # Default to Monthly
                    help="Select temporal analysis granularity"
                )

            with primary_col3:
                behavioral_metric = st.selectbox(
                    "üìä Key Metric",
                    options=['usage_cpu', 'usage_storage', 'users_active', 'cpu_per_user', 'user_efficiency'],
                    format_func=lambda x: {
                        'usage_cpu': 'üî• CPU Usage',
                        'usage_storage': 'üíæ Storage Usage',
                        'users_active': 'üë• Active Users',
                        'cpu_per_user': '‚ö° CPU Efficiency',
                        'user_efficiency': 'üéØ User Efficiency'
                    }[x],
                    help="Primary metric for behavioral analysis"
                )

        with tier2_container:
            # Tier 2: Behavioral Filters
            filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)

            with filter_col1:
                include_holidays = st.checkbox("üéâ Include Holidays", value=True)

            with filter_col2:
                include_weekends = st.checkbox("üõå Include Weekends", value=True)

            with filter_col3:
                behavior_comparison = st.checkbox("‚öñÔ∏è Behavior Comparison", value=True)

            with filter_col4:
                advanced_insights = st.checkbox("üß† Advanced Insights", value=True)

        with tier3_container:
            # Tier 3: Visualization Options
            viz_col1, viz_col2, viz_col3 = st.columns(3)

            with viz_col1:
                show_annotations = st.toggle("üìù Show Annotations", value=True)

            with viz_col2:
                interactive_features = st.toggle("üéÆ Interactive Features", value=True)

            with viz_col3:
                export_insights = st.toggle("üíæ Export Insights", value=False)

        # Apply filters
        df_filtered = df_clean.copy()

        if not include_holidays:
            df_filtered = df_filtered[df_filtered['is_holiday'] == 0]

        if not include_weekends:
            df_filtered = df_filtered[df_filtered['date'].dt.weekday < 5]  # Monday=0 to Friday=4

        st.divider()

        # === MAIN BEHAVIORAL ANALYSIS SECTIONS ===

        if analysis_focus == 'Seasonal Patterns':
            st.markdown("### üåÖ Seasonal Pattern Analysis")

            pattern_col1, pattern_col2 = st.columns([2, 1])

            with pattern_col1:
                # Seasonal trend visualization
                st.markdown("**üìà Seasonal Trends Dashboard**")

                # Aggregate data based on time granularity
                if time_granularity == 'Daily':
                    time_group = df_filtered.groupby(df_filtered['date'].dt.date)[behavioral_metric].mean().reset_index()
                    time_group.columns = ['period', 'value']
                elif time_granularity == 'Weekly':
                    time_group = df_filtered.groupby('week_of_year')[behavioral_metric].mean().reset_index()
                    time_group.columns = ['period', 'value']
                elif time_granularity == 'Monthly':
                    time_group = df_filtered.groupby('month')[behavioral_metric].mean().reset_index()
                    time_group.columns = ['period', 'value']
                else:  # Quarterly
                    time_group = df_filtered.groupby('quarter')[behavioral_metric].mean().reset_index()
                    time_group.columns = ['period', 'value']

                # Create seasonal pattern chart
                fig_seasonal = go.Figure()

                # Main trend line
                fig_seasonal.add_trace(go.Scatter(
                    x=time_group['period'],
                    y=time_group['value'],
                    mode='lines+markers',
                    name=f'{behavioral_metric.replace("_", " ").title()}',
                    line=dict(color='#2E86AB', width=4),
                    marker=dict(size=8, color='#2E86AB'),
                    fill='tonexty' if time_granularity != 'Daily' else None,
                    fillcolor='rgba(46, 134, 171, 0.1)'
                ))

                # Add seasonal average line
                seasonal_avg = time_group['value'].mean()
                fig_seasonal.add_hline(
                    y=seasonal_avg, 
                    line_dash="dash", 
                    line_color="orange",
                    annotation_text=f"Average: {seasonal_avg:.1f}"
                )

                # Add peak and trough annotations if enabled
                if show_annotations and len(time_group) > 0:
                    peak_idx = time_group['value'].idxmax()
                    trough_idx = time_group['value'].idxmin()

                    fig_seasonal.add_annotation(
                        x=time_group.iloc[peak_idx]['period'],
                        y=time_group.iloc[peak_idx]['value'],
                        text=f"Peak: {time_group.iloc[peak_idx]['value']:.1f}",
                        showarrow=True,
                        arrowhead=2,
                        arrowcolor="green",
                        bgcolor="lightgreen",
                        bordercolor="green"
                    )

                    fig_seasonal.add_annotation(
                        x=time_group.iloc[trough_idx]['period'],
                        y=time_group.iloc[trough_idx]['value'],
                        text=f"Low: {time_group.iloc[trough_idx]['value']:.1f}",
                        showarrow=True,
                        arrowhead=2,
                        arrowcolor="red",
                        bgcolor="lightcoral",
                        bordercolor="red"
                    )

                fig_seasonal.update_layout(
                    title=f"{time_granularity} {behavioral_metric.replace('_', ' ').title()} Patterns",
                    xaxis_title=time_granularity,
                    yaxis_title=behavioral_metric.replace('_', ' ').title(),
                    height=400,
                    hovermode='x unified'
                )

                st.plotly_chart(fig_seasonal, width="stretch")

            with pattern_col2:
                # Seasonal insights panel
                st.markdown("**üîç Seasonal Insights**")

                if len(time_group) > 1:
                    # Calculate seasonal statistics
                    seasonal_variance = time_group['value'].var()
                    seasonal_range = time_group['value'].max() - time_group['value'].min()
                    seasonal_cv = (time_group['value'].std() / time_group['value'].mean()) * 100 if time_group['value'].mean() > 0 else 0

                    # Pattern classification
                    if seasonal_cv < 10:
                        pattern_type = "üü¢ Stable"
                        pattern_color = "#27ae60"
                    elif seasonal_cv < 25:
                        pattern_type = "üü° Moderate Variation"
                        pattern_color = "#f39c12"
                    else:
                        pattern_type = "üî¥ High Volatility"
                        pattern_color = "#e74c3c"

                    st.markdown(f"""
                    <div style="background: {pattern_color}22; padding: 1rem; border-radius: 8px;
                               border-left: 4px solid {pattern_color};">
                        <h4 style="color: {pattern_color}; margin: 0;">Pattern Type</h4>
                        <h3 style="margin: 0.5rem 0;">{pattern_type}</h3>
                        <small>Coefficient of Variation: {seasonal_cv:.1f}%</small>
                    </div>
                    """, unsafe_allow_html=True)

                    st.metric("üìä Seasonal Range", f"{seasonal_range:.1f}")
                    st.metric("üìà Peak Value", f"{time_group['value'].max():.1f}")
                    st.metric("üìâ Trough Value", f"{time_group['value'].min():.1f}")

                    # Seasonal recommendations
                    if advanced_insights:
                        st.markdown("**üí° Recommendations:**")

                        if seasonal_cv > 25:
                            st.markdown("- Consider implementing adaptive scaling during high volatility periods")
                            st.markdown("- Monitor resource allocation during peak seasons")

                        peak_period = time_group.iloc[time_group['value'].idxmax()]['period']
                        st.markdown(f"- Peak demand occurs in period {peak_period}")

                        if seasonal_range > seasonal_avg * 0.5:
                            st.markdown("- Significant seasonal variation detected - plan capacity accordingly")
                else:
                    st.info("Insufficient data for seasonal analysis")

            # Seasonal heatmap
            if len(df_filtered) > 0:
                st.markdown("**üóìÔ∏è Seasonal Calendar Heatmap**")

                # Create month-day heatmap
                calendar_pivot = df_filtered.groupby(['month', 'day_of_month'])[behavioral_metric].mean().reset_index()

                if not calendar_pivot.empty:
                    calendar_matrix = calendar_pivot.pivot(index='day_of_month', columns='month', values=behavioral_metric)

                    fig_calendar = go.Figure(data=go.Heatmap(
                        z=calendar_matrix.values,
                        x=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],
                        y=calendar_matrix.index,
                        colorscale='RdYlBu_r',
                        text=calendar_matrix.values.round(1),
                        texttemplate='%{text}',
                        textfont={"size": 8},
                        hoverongaps=False,
                        colorbar=dict(
                            title=behavioral_metric.replace('_', ' ').title(),
                            x=1.02,
                            xanchor='left'
                        )
                    ))

                    fig_calendar.update_layout(
                        title=f"Seasonal Calendar - {behavioral_metric.replace('_', ' ').title()} Patterns",
                        xaxis_title="Month",
                        yaxis_title="Day of Month",
                        height=400
                    )

                    st.plotly_chart(fig_calendar, width="stretch")

        elif analysis_focus == 'Holiday Effects':
            st.markdown("### üéâ Holiday Effects Analysis")

            holiday_col1, holiday_col2 = st.columns(2)

            with holiday_col1:
                # Holiday vs Non-Holiday comparison
                st.markdown("**üìä Holiday vs Regular Day Comparison**")

                holiday_data = df_filtered[df_filtered['is_holiday'] == 1]
                regular_data = df_filtered[df_filtered['is_holiday'] == 0]

                if not holiday_data.empty and not regular_data.empty:
                    # Comparative box plots
                    fig_comparison = go.Figure()

                    fig_comparison.add_trace(go.Box(
                        y=regular_data[behavioral_metric],
                        name='Regular Days',
                        marker_color='#4ecdc4',
                        boxmean=True
                    ))

                    fig_comparison.add_trace(go.Box(
                        y=holiday_data[behavioral_metric],
                        name='Holidays',
                        marker_color='#ff6b6b',
                        boxmean=True
                    ))

                    fig_comparison.update_layout(
                        title=f"Holiday Impact on {behavioral_metric.replace('_', ' ').title()}",
                        yaxis_title=behavioral_metric.replace('_', ' ').title(),
                        height=400,
                        showlegend=True
                    )

                    st.plotly_chart(fig_comparison, width="stretch")

                    # Holiday impact metrics
                    holiday_avg = holiday_data[behavioral_metric].mean()
                    regular_avg = regular_data[behavioral_metric].mean()
                    impact_pct = ((holiday_avg - regular_avg) / regular_avg) * 100 if regular_avg > 0 else 0

                    impact_color = "#27ae60" if impact_pct > 0 else "#e74c3c"
                    impact_direction = "üìà Increase" if impact_pct > 0 else "üìâ Decrease"

                    st.markdown(f"""
                    <div style="background: {impact_color}22; padding: 1rem; border-radius: 8px;
                               border-left: 4px solid {impact_color}; text-align: center;">
                        <h4 style="color: {impact_color}; margin: 0;">Holiday Impact</h4>
                        <h2 style="margin: 0.5rem 0;">{impact_pct:+.1f}%</h2>
                        <p style="margin: 0;">{impact_direction} vs Regular Days</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.info("Insufficient holiday or regular day data for comparison")

            with holiday_col2:
                # Day of week analysis
                st.markdown("**üìÖ Day of Week Behavioral Patterns**")

                dow_analysis = df_filtered.groupby('day_of_week')[behavioral_metric].agg(['mean', 'std']).reset_index()

                if not dow_analysis.empty:
                    # Reorder days of week
                    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                    dow_analysis['day_of_week'] = pd.Categorical(dow_analysis['day_of_week'], categories=day_order, ordered=True)
                    dow_analysis = dow_analysis.sort_values('day_of_week')

                    fig_dow = go.Figure()

                    # Add bar chart with error bars
                    fig_dow.add_trace(go.Bar(
                        x=dow_analysis['day_of_week'],
                        y=dow_analysis['mean'],
                        error_y=dict(type='data', array=dow_analysis['std']),
                        marker_color=['#3498db' if day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'] 
                                     else '#e74c3c' for day in dow_analysis['day_of_week']],
                        hovertemplate='%{x}<br>Mean: %{y:.1f}<br>Std: %{error_y.array:.1f}<extra></extra>'
                    ))

                    # Add weekend highlighting
                    fig_dow.add_vrect(
                        x0=4.5, x1=6.5,
                        fillcolor="rgba(231, 76, 60, 0.1)",
                        layer="below",
                        line_width=0,
                        annotation_text="Weekend",
                        annotation_position="top left"
                    )

                    fig_dow.update_layout(
                        title=f"Weekly Pattern - {behavioral_metric.replace('_', ' ').title()}",
                        xaxis_title="Day of Week",
                        yaxis_title=behavioral_metric.replace('_', ' ').title(),
                        height=400,
                        showlegend=False
                    )

                    st.plotly_chart(fig_dow, width="stretch")

        elif analysis_focus == 'User Behavior':
            st.markdown("### üë• User Behavior Intelligence")

            behavior_col1, behavior_col2 = st.columns([3, 1])

            with behavior_col1:
                # User behavior scatter analysis
                st.markdown("**üéà User Behavior Bubble Analysis**")

                # Create behavioral scatter plot
                fig_behavior = go.Figure()

                # Group by region for different colors
                region_colors = {'East US': '#0078d4', 'West US': '#ff6b6b', 'North Europe': '#4ecdc4', 'Southeast Asia': '#95e1d3'}

                for region in df_filtered['region'].unique():
                    region_data = df_filtered[df_filtered['region'] == region]

                    fig_behavior.add_trace(go.Scatter(
                        x=region_data['users_active'],
                        y=region_data['usage_cpu'],
                        mode='markers',
                        name=region,
                        marker=dict(
                            color=region_colors.get(region, '#3498db'),
                            size=region_data['usage_storage'] / 50,  # Scale bubble size
                            sizemin=5,
                            sizemax=30,
                            opacity=0.7,
                            line=dict(width=1, color='white')
                        ),
                        hovertemplate=f'<b>{region}</b><br>' +
                                     'Active Users: %{x}<br>' +
                                     'CPU Usage: %{y:.1f}%<br>' +
                                     'Storage: %{marker.size*50:.0f}GB<extra></extra>'
                    ))

                # Add efficiency trend line
                if len(df_filtered) > 10:
                    try:
                        z = np.polyfit(df_filtered['users_active'], df_filtered['usage_cpu'], 1)
                        p = np.poly1d(z)
                        x_trend = np.linspace(df_filtered['users_active'].min(), df_filtered['users_active'].max(), 100)

                        fig_behavior.add_trace(go.Scatter(
                            x=x_trend,
                            y=p(x_trend),
                            mode='lines',
                            name='Efficiency Trend',
                            line=dict(color='red', width=2, dash='dash'),
                            hovertemplate='Trend Line<extra></extra>'
                        ))
                    except:
                        pass  # Skip trend line if calculation fails

                fig_behavior.update_layout(
                    title="User Behavior Analysis (Bubble size = Storage Usage)",
                    xaxis_title="Active Users",
                    yaxis_title="CPU Usage (%)",
                    height=450,
                    showlegend=True,
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )

                st.plotly_chart(fig_behavior, width="stretch")

            with behavior_col2:
                # User behavior insights
                st.markdown("**üß† Behavior Insights**")

                # Calculate user behavior metrics
                avg_users = df_filtered['users_active'].mean()
                avg_cpu_per_user = df_filtered['cpu_per_user'].mean()
                avg_efficiency = df_filtered['user_efficiency'].mean()

                # User classification
                if avg_cpu_per_user < 2:
                    user_class = "üü¢ Efficient"
                    class_color = "#27ae60"
                elif avg_cpu_per_user < 5:
                    user_class = "üü° Moderate"
                    class_color = "#f39c12"
                else:
                    user_class = "üî¥ Resource Intensive"
                    class_color = "#e74c3c"

                st.markdown(f"""
                <div style="background: {class_color}22; padding: 1rem; border-radius: 8px;
                           border-left: 4px solid {class_color};">
                    <h4 style="color: {class_color}; margin: 0;">User Classification</h4>
                    <h3 style="margin: 0.5rem 0;">{user_class}</h3>
                    <small>Based on CPU usage per user</small>
                </div>
                """, unsafe_allow_html=True)

                st.metric("üë• Avg Active Users", f"{avg_users:.0f}")
                st.metric("‚ö° CPU per User", f"{avg_cpu_per_user:.1f}%")
                st.metric("üéØ User Efficiency", f"{avg_efficiency:.1f}")

                # Behavior recommendations
                if advanced_insights:
                    st.markdown("**üí° Behavior Insights:**")

                    if not df_filtered.empty:
                        # Peak usage analysis
                        peak_usage = df_filtered.loc[df_filtered['usage_cpu'].idxmax()]
                        st.markdown(f"- Peak usage: {peak_usage['users_active']:.0f} users on {peak_usage['date'].strftime('%Y-%m-%d')}")

                        # Efficiency trends
                        correlation = df_filtered['users_active'].corr(df_filtered['usage_cpu'])
                        if correlation > 0.7:
                            st.markdown("- Strong positive correlation: More users = Higher CPU usage")
                        elif correlation < -0.3:
                            st.markdown("- Negative correlation: System becomes more efficient with more users")
                        else:
                            st.markdown("- Moderate correlation: User count has mixed impact on resources")

        elif analysis_focus == 'Engagement Efficiency':
            st.markdown("### üéØ Engagement Efficiency Analysis")

            efficiency_col1, efficiency_col2 = st.columns(2)

            with efficiency_col1:
                # Efficiency heatmap by region and resource
                st.markdown("**üî• Regional Efficiency Heatmap**")

                efficiency_pivot = df_filtered.groupby(['region', 'resource_type'])['user_efficiency'].mean().reset_index()

                if not efficiency_pivot.empty:
                    efficiency_matrix = efficiency_pivot.pivot(index='region', columns='resource_type', values='user_efficiency')

                    fig_efficiency_heatmap = go.Figure(data=go.Heatmap(
                        z=efficiency_matrix.values,
                        x=efficiency_matrix.columns,
                        y=efficiency_matrix.index,
                        colorscale='RdYlGn',
                        text=efficiency_matrix.values.round(1),
                        texttemplate='%{text}',
                        textfont={"size": 12},
                        hoverongaps=False,
                        colorbar=dict(
                            title="Efficiency Score",
                            x=1.02,
                            xanchor='left'
                        )
                    ))

                    fig_efficiency_heatmap.update_layout(
                        title="User Engagement Efficiency by Region & Resource",
                        xaxis_title="Resource Type",
                        yaxis_title="Region",
                        height=400
                    )

                    st.plotly_chart(fig_efficiency_heatmap, width="stretch")
                else:
                    st.info("Insufficient data for efficiency heatmap")

            with efficiency_col2:
                # Efficiency distribution analysis
                st.markdown("**üìä Efficiency Distribution**")

                fig_efficiency_dist = go.Figure()

                # Create violin plot for efficiency distribution
                for resource in df_filtered['resource_type'].unique():
                    resource_data = df_filtered[df_filtered['resource_type'] == resource]

                    fig_efficiency_dist.add_trace(go.Violin(
                        y=resource_data['user_efficiency'],
                        name=resource,
                        box_visible=True,
                        meanline_visible=True
                    ))

                fig_efficiency_dist.update_layout(
                    title="Efficiency Distribution by Resource Type",
                    yaxis_title="User Efficiency Score",
                    height=400,
                    showlegend=True
                )

                st.plotly_chart(fig_efficiency_dist, width="stretch")

        # === BEHAVIORAL INTELLIGENCE SUMMARY ===
        if advanced_insights:
            st.divider()
            st.markdown("### üß† Behavioral Intelligence Summary")

            intel_col1, intel_col2, intel_col3 = st.columns(3)

            with intel_col1:
                st.markdown("**üîç Key Findings**")

                # Generate key insights
                insights = []

                # Seasonal insight
                if len(df_filtered) > 12:  # Need sufficient data for seasonal analysis
                    seasonal_var = df_filtered.groupby('month')[behavioral_metric].mean().var()
                    if seasonal_var > df_filtered[behavioral_metric].var() * 0.5:
                        insights.append("üìÖ Strong seasonal patterns detected")

                # Holiday insight
                holiday_data = df_filtered[df_filtered['is_holiday'] == 1]
                regular_data = df_filtered[df_filtered['is_holiday'] == 0]

                if not holiday_data.empty and not regular_data.empty:
                    holiday_avg = holiday_data[behavioral_metric].mean()
                    regular_avg = regular_data[behavioral_metric].mean()
                    holiday_impact = abs((holiday_avg - regular_avg) / regular_avg * 100) if regular_avg > 0 else 0
                    if holiday_impact > 15:
                        insights.append("üéâ Significant holiday effects observed")

                # User behavior insight
                user_cpu_corr = df_filtered['users_active'].corr(df_filtered['usage_cpu'])
                if user_cpu_corr > 0.7:
                    insights.append("üë• Strong user-resource correlation")

                for insight in insights[:5]:  # Show top 5 insights
                    st.markdown(f"- {insight}")

                if not insights:
                    st.info("No significant behavioral patterns detected")

            with intel_col2:
                st.markdown("**üìä Behavioral Metrics**")

                # Key behavioral metrics
                behavioral_consistency = 100 - (df_filtered[behavioral_metric].std() / df_filtered[behavioral_metric].mean() * 100) if df_filtered[behavioral_metric].mean() > 0 else 0
                user_predictability = 100 - (df_filtered['users_active'].std() / df_filtered['users_active'].mean() * 100) if df_filtered['users_active'].mean() > 0 else 0
                peak_to_trough = df_filtered[behavioral_metric].max() / df_filtered[behavioral_metric].min() if df_filtered[behavioral_metric].min() > 0 else 0

                st.metric("üéØ Behavioral Consistency", f"{behavioral_consistency:.1f}%")
                st.metric("üë• User Predictability", f"{user_predictability:.1f}%")
                st.metric("üìà Peak-to-Trough Ratio", f"{peak_to_trough:.1f}x")

            with intel_col3:
                st.markdown("**üéØ Action Items**")

                # Generate action items based on analysis
                actions = []

                if behavioral_consistency < 70:
                    actions.append("üìä Implement behavioral monitoring")

                if user_predictability < 60:
                    actions.append("üë• Analyze user engagement patterns")

                if peak_to_trough > 3:
                    actions.append("‚öñÔ∏è Consider load balancing strategies")

                # Always include these general actions
                actions.extend([
                    "üìà Continue monitoring seasonal trends",
                    "üéâ Plan for holiday capacity changes"
                ])

                for action in actions[:5]:  # Show top 5 actions
                    st.markdown(f"- {action}")

        # === EXPORT FUNCTIONALITY ===
        if export_insights:
            st.divider()
            st.markdown("### üíæ Export Behavioral Analysis")

            export_col1, export_col2 = st.columns(2)

            with export_col1:
                # Export seasonal data
                if st.button("üìÖ Export Seasonal Analysis"):
                    seasonal_export = df_filtered.groupby(['month', 'day_of_week']).agg({
                        behavioral_metric: ['mean', 'std', 'min', 'max'],
                        'users_active': 'mean',
                        'is_holiday': 'sum'
                    }).round(2)

                    seasonal_export.columns = ['_'.join(col).strip() for col in seasonal_export.columns]
                    csv_data = seasonal_export.to_csv()

                    st.download_button(
                        label="‚¨áÔ∏è Download Seasonal Data",
                        data=csv_data,
                        file_name=f"seasonal_analysis_{analysis_focus.lower().replace(' ', '_')}.csv",
                        mime="text/csv"
                    )

            with export_col2:
                # Export behavioral insights
                if st.button("üß† Export Behavioral Insights"):
                    insights_export = {
                        'analysis_focus': analysis_focus,
                        'time_granularity': time_granularity,
                        'behavioral_metric': behavioral_metric,
                        'total_records': len(df_filtered),
                        'date_range': f"{df_filtered['date'].min()} to {df_filtered['date'].max()}",
                        'avg_metric_value': df_filtered[behavioral_metric].mean(),
                        'metric_volatility': df_filtered[behavioral_metric].std(),
                        'user_efficiency': df_filtered['user_efficiency'].mean(),
                        'holiday_impact': 'N/A'  # Would be calculated based on analysis
                    }

                    insights_json = pd.DataFrame([insights_export]).to_json(orient='records', indent=2)

                    st.download_button(
                        label="‚¨áÔ∏è Download Insights Summary",
                        data=insights_json,
                        file_name=f"behavioral_insights_{analysis_focus.lower().replace(' ', '_')}.json",
                        mime="application/json"
                    )

    except Exception as main_error:
        st.error(f"‚ùå Behavioral analysis error: {str(main_error)}")
        st.info("Please check your data and try again")


#-------------------------------------------i have edited down code -------------------------------------------------

# ===== TAB 7: ML FORECASTING (ENHANCED IMPLEMENTATION) =====
# ===== TAB 7: ENHANCED ML FORECASTING (DUAL-METRIC IMPLEMENTATION) =====
with tab7:
    st.markdown("# üîÆ Machine Learning Forecasting Dashboard")
    
    cpu_tab, users_tab, storage_tab = st.tabs([
        "üñ•Ô∏è CPU Usage Forecasting", 
        "üë• Active Users Forecasting", 
        "üíæ Storage Usage Forecasting"  # NEW
    ])    
    # ------------------------------------------------------------------
    # Enhanced Helper Function for Forecasting UI
    # ------------------------------------------------------------------
    def enhanced_forecast_ui(metric_name: str,
                           model_ep: str,
                           predict_ep: str,
                           pred_key: str,
                           yaxis_title: str,
                           unit_symbol: str = ""):
        
        # --- LOAD MODEL STATUS ----------------------------------------
        model_info = fetch_api(model_ep)
        if not model_info:
            st.error("‚ö†Ô∏è Unable to load model information.")
            return
        
        # --- COMPACT HORIZONTAL MODEL STATUS ----------------------
        st.markdown("### üéØ Model Status & Settings")
        
        # Create horizontal model status display
        status_cols = st.columns(4)
        regions = list(model_info['models'].keys())
        
        for i, (region, info) in enumerate(model_info['models'].items()):
            with status_cols[i]:
                status = "‚úÖ" if info['loaded'] else "‚ùå"
                color = "#d4edda" if info['loaded'] else "#f8d7da"
                st.markdown(f"""
                    <div style="background-color:{color}; padding:10px; border-radius:8px; 
                                text-align:center; border:1px solid #{'c3e6cb' if info['loaded'] else '#f5c6cb'}">
                        <strong>{region}</strong><br>
                        {info['model_type']} {status}
                    </div>
                """, unsafe_allow_html=True)
        
        # --- FORECAST SETTINGS IN HORIZONTAL LAYOUT ---------------
        st.markdown("---")
        settings_cols = st.columns([2, 2, 1])
        
        with settings_cols[0]:
            days = st.slider("üìÖ Forecast Horizon (days)", 7, 90, 30, 
                           key=f"{metric_name}_days")
        
        with settings_cols[1]:
            region_filter = st.selectbox("üåç Focus Region",
                                       ["All Regions"] + regions,
                                       key=f"{metric_name}_region")
        
        with settings_cols[2]:
            st.markdown("<br>", unsafe_allow_html=True)  # Add spacing
            generate_btn = st.button("üöÄ Generate", key=f"{metric_name}_btn", 
                                    type="primary", use_container_width=True)
        
        if generate_btn:
            st.session_state[f"gen_{metric_name}"] = True
        
        # --- MAIN FORECASTING RESULTS ---------------------------------
        if st.session_state.get(f"gen_{metric_name}", False):
            with st.spinner("üîÑ Generating forecasts..."):
                params = {'days': days}
                if region_filter != "All Regions":
                    params['region'] = region_filter
                data = fetch_api(predict_ep, params=params)
            
            if not data:
                st.error("‚ùå Forecast generation failed.")
                st.session_state[f"gen_{metric_name}"] = False
                return
            
            # --- CREATE INDIVIDUAL REGION CHARTS -------------------
            st.markdown("### üìä Individual Region Forecasts")
            
            # Create 2x2 grid for individual region charts
            row1_cols = st.columns(2)
            row2_cols = st.columns(2)
            chart_cols = [row1_cols[0], row1_cols[1], row2_cols[0], row2_cols[1]]
            
            valid_regions = []
            all_forecast_data = {}
            
            for idx, (reg, d) in enumerate(data.items()):
                if 'error' in d:
                    st.error(f"‚ùå {reg}: {d['error']}")
                    continue
                
                valid_regions.append(reg)
                all_forecast_data[reg] = d
                
                if idx < 4:  # Only show first 4 regions in grid
                    with chart_cols[idx]:
                        # Individual region chart with min/max shading
                        fig_individual = go.Figure()
                        
                        # Historical data
                        if 'historical' in d:
                            h = d['historical']
                            hist_y = h.get('actual_cpu') or h.get('actual_users') or h.get('actual_storage')
                            fig_individual.add_trace(go.Scatter(
                                x=h['dates'], y=hist_y,
                                mode='lines',
                                name="Historical",
                                line=dict(color='#2E86C1', width=2),
                                fill=None
                            ))
                        
                        # Forecast data
                        forecast_values = np.array(d[pred_key])
                        forecast_dates = d['dates']
                        
                        # Calculate confidence intervals (using ¬±10% as example)
                        forecast_upper = forecast_values * 1.1
                        forecast_lower = forecast_values * 0.9
                        
                        # Add shaded area for forecast range
                        fig_individual.add_trace(go.Scatter(
                            x=forecast_dates + forecast_dates[::-1],
                            y=list(forecast_upper) + list(forecast_lower[::-1]),
                            fill='toself',
                            fillcolor='rgba(255, 182, 193, 0.3)',
                            line=dict(color='rgba(255,255,255,0)'),
                            name='Forecast Range',
                            showlegend=False
                        ))
                        
                        # Main forecast line
                        fig_individual.add_trace(go.Scatter(
                            x=forecast_dates,
                            y=forecast_values,
                            mode='lines+markers',
                            name=f"Forecast ({d['model_info']['type']})",
                            line=dict(color='#E74C3C', width=2, dash='dash'),
                            marker=dict(size=4)
                        ))
                        
                        fig_individual.update_layout(
                            title=f"üìà {reg}",
                            xaxis_title="Date",
                            yaxis_title=yaxis_title,
                            height=300,
                            showlegend=False,
                            margin=dict(l=40, r=40, t=50, b=40)
                        )
                        
                        st.plotly_chart(fig_individual, use_container_width=True)
            
            # --- COMBINED VIEW CHART ----------------------------------
            st.markdown("### üåç Combined Regional Forecast View")
            
            fig_combined = go.Figure()
            colors = ['#3498DB', '#E74C3C', '#2ECC71', '#F39C12', '#9B59B6', '#1ABC9C']
            
            for idx, (reg, d) in enumerate(all_forecast_data.items()):
                color = colors[idx % len(colors)]
                
                # Historical data
                if 'historical' in d:
                    h = d['historical']
                    hist_y = h.get('actual_cpu') or h.get('actual_users') or h.get('actual_storage')
                    fig_combined.add_trace(go.Scatter(
                        x=h['dates'], y=hist_y,
                        mode='lines',
                        name=f"{reg} - Historical",
                        line=dict(color=color, width=2),
                        opacity=0.7
                    ))
                
                # Forecast data
                fig_combined.add_trace(go.Scatter(
                    x=d['dates'],
                    y=d[pred_key],
                    mode='lines+markers',
                    name=f"{reg} - Forecast ({d['model_info']['type']})",
                    line=dict(color=color, width=3, dash='dash'),
                    marker=dict(size=5, symbol='diamond')
                ))
            
            fig_combined.update_layout(
                title=f"üåê All Regions - {metric_name} Forecast Comparison",
                xaxis_title="üìÖ Date",
                yaxis_title=yaxis_title,
                height=500,
                hovermode='x unified',
                legend=dict(
                    orientation="v",
                    yanchor="top",
                    y=1,
                    xanchor="left",
                    x=1.05
                )
            )
            
            st.plotly_chart(fig_combined, use_container_width=True)
            
            # --- MODEL PERFORMANCE BAR CHART -------------------------
            st.markdown("### üìä Model Performance Analysis")
            
            perf_col1, perf_col2 = st.columns([2, 1])
            
            with perf_col1:
                # Fetch model comparison data
                if metric_name == "CPU Usage":
                    comparison_ep = "forecast/comparison"
                elif metric_name == "Active Users":
                    comparison_ep = "forecast/users/comparison"
                else:  # Storage Usage  
                    comparison_ep = "forecast/storage/comparison"
                    
                perf_data = fetch_api(comparison_ep)
                
                if perf_data:
                    # Create performance bar chart
                    regions_perf = list(perf_data['regional_performance'].keys())
                    rmse_values = [perf_data['regional_performance'][r]['rmse'] for r in regions_perf]
                    mae_values = [perf_data['regional_performance'][r]['mae'] for r in regions_perf]
                    models_used = [perf_data['regional_performance'][r]['model'] for r in regions_perf]
                    
                    fig_perf = go.Figure()
                    
                    fig_perf.add_trace(go.Bar(
                        name='RMSE',
                        x=regions_perf,
                        y=rmse_values,
                        yaxis='y',
                        offsetgroup=1,
                        marker_color='#E74C3C',
                        text=[f"{v:.1f}" for v in rmse_values],
                        textposition='auto'
                    ))
                    
                    fig_perf.add_trace(go.Bar(
                        name='MAE',
                        x=regions_perf,
                        y=mae_values,
                        yaxis='y2',
                        offsetgroup=2,
                        marker_color='#3498DB',
                        text=[f"{v:.1f}" for v in mae_values],
                        textposition='auto'
                    ))
                    
                    fig_perf.update_layout(
                        title='üéØ Model Accuracy by Region',
                        xaxis=dict(title='Regions'),
                        yaxis=dict(title='RMSE', side='left', color='#E74C3C'),
                        yaxis2=dict(title='MAE', side='right', overlaying='y', color='#3498DB'),
                        height=400,
                        barmode='group'
                    )
                    
                    st.plotly_chart(fig_perf, use_container_width=True)
            
            with perf_col2:
                # Model distribution pie chart
                if perf_data:
                    model_counts = {}
                    for model in models_used:
                        model_counts[model] = model_counts.get(model, 0) + 1
                    
                    fig_pie = go.Figure(data=[go.Pie(
                        labels=list(model_counts.keys()),
                        values=list(model_counts.values()),
                        hole=0.4,
                        marker_colors=['#FF6B6B', '#4ECDC4', '#45B7D1']
                    )])
                    
                    fig_pie.update_layout(
                        title="üß† Model Distribution",
                        height=400,
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_pie, use_container_width=True)
            
            # --- FORECAST SUMMARY TABLE -------------------------------
            st.markdown("### üìã Detailed Forecast Summary")
            
            summary_rows = []
            for reg, d in all_forecast_data.items():
                if pred_key in d:
                    vals = np.array(d[pred_key])
                    model_type = d['model_info']['type']
                    forecast_range = d['model_info'].get('range', [0, 0])
                    
                    summary_rows.append({
                        'üåç Region': reg,
                        'üß† Model': model_type,
                        f'üìä Avg {metric_name}': f"{vals.mean():.1f}{unit_symbol}",
                        f'üìà Max {metric_name}': f"{vals.max():.1f}{unit_symbol}",
                        f'üìâ Min {metric_name}': f"{vals.min():.1f}{unit_symbol}",
                        'üìÖ Forecast Days': days,
                        'üéØ Confidence Range': f"{forecast_range[0]:.1f} - {forecast_range[1]:.1f}{unit_symbol}"
                    })
            
            if summary_rows:
                df_summary = pd.DataFrame(summary_rows)
                st.dataframe(df_summary, use_container_width=True)
                
                # Download button for summary
                csv = df_summary.to_csv(index=False)
                st.download_button(
                    label="üíæ Download Forecast Summary",
                    data=csv,
                    file_name=f"{metric_name.lower()}_forecast_summary.csv",
                    mime="text/csv"
                )
            
            # --- KEY INSIGHTS SECTION ----------------------------------
            st.markdown("### üí° Key Insights")
            
            insights_cols = st.columns(3)
            
            with insights_cols[0]:
                if summary_rows:
                    avg_values = [float(row[f'üìä Avg {metric_name}'].replace(unit_symbol, '')) for row in summary_rows]
                    best_region = summary_rows[np.argmin(avg_values)]['üåç Region']
                    worst_region = summary_rows[np.argmax(avg_values)]['üåç Region']
                    
                    st.info(f"""
                    **üèÜ Best Performing Region:**  
                    {best_region}
                    
                    **‚ö†Ô∏è Highest Load Region:**  
                    {worst_region}
                    """)
            
            with insights_cols[1]:
                if perf_data:
                    best_model = min(perf_data['regional_performance'].items(), 
                                   key=lambda x: x[1]['rmse'])
                    st.success(f"""
                    **üéØ Most Accurate Model:**  
                    {best_model[1]['model']} in {best_model[0]}
                    
                    **üìä RMSE:** {best_model[1]['rmse']:.2f}
                    """)
            
            with insights_cols[2]:
                if summary_rows:
                    total_forecast = sum(float(row[f'üìä Avg {metric_name}'].replace(unit_symbol, '')) 
                                       for row in summary_rows)
                    st.warning(f"""
                    **üìà Total Forecast Average:**  
                    {total_forecast:.1f}{unit_symbol}
                    
                    **üïí Forecast Period:**  
                    {days} days
                    """)
            
            st.session_state[f"gen_{metric_name}"] = False
    
    # ------------------------------------------------------------------
    # CPU FORECAST TAB
    # ------------------------------------------------------------------
    with cpu_tab:
        enhanced_forecast_ui(
            metric_name="CPU Usage",
            model_ep="forecast/models",
            predict_ep="forecast/predict",
            pred_key="predicted_cpu",
            yaxis_title="CPU Usage (%)",
            unit_symbol="%"
        )
    
    # ------------------------------------------------------------------
    # ACTIVE USERS FORECAST TAB
    # ------------------------------------------------------------------
    with users_tab:
        enhanced_forecast_ui(
            metric_name="Active Users",
            model_ep="forecast/users/models",
            predict_ep="forecast/users/predict",
            pred_key="predicted_users",
            yaxis_title="Active Users (count)",
            unit_symbol=" users"
        )
    
    # ------------------------------------------------------------------
    # Storage usage FORECAST TAB
    # ------------------------------------------------------------------
    with storage_tab:
        enhanced_forecast_ui(
            metric_name="Storage Usage",
            model_ep="forecast/storage/models",
            predict_ep="forecast/storage/predict",
            pred_key="predicted_storage",
            yaxis_title="Storage usage (count)",
            unit_symbol="GB"
        )

# Add this as Tab 8 in your dashboard
# Enhanced Tab 8: Intelligent Model Training Pipeline Dashboard

# FIXED Tab 8: Intelligent Model Training Pipeline Dashboard - CORRECTED API ENDPOINTS
# ===== TAB 8: INTELLIGENT MODEL HEALTH MONITORING & PERFORMANCE ANALYTICS =====
with tab8:
    st.markdown("# üîç Model Health Monitoring & Performance Analytics")
    st.markdown("**Enterprise-grade intelligent model training pipeline with real-time health monitoring**")
    
    # === SECTION 1: PIPELINE STATUS OVERVIEW ===
    st.markdown("---")
    st.markdown("## üìä Pipeline Status Overview")

    
    # Fetch all required data with better error handling
    status_data = None
    config_data = None  
    history_data = None
    comparison_data = None

    with st.spinner("üîÑ Loading intelligent training pipeline data..."):
       try:
           status_data = fetch_api("training/intelligent/status")
           if status_data and 'error' in status_data:
               st.error(f"Status API Error: {status_data['error']}")
               status_data = None
       except Exception as e:
          st.error(f"Status API Connection Error: {str(e)}")
    
       try:
           config_data = fetch_api("training/intelligent/config")
           if config_data and 'error' in config_data:
               st.warning(f"Config API Error: {config_data['error']}")
               config_data = None
       except Exception as e:
             st.warning(f"Config API Connection Error: {str(e)}")
    
       try:
            history_data = fetch_api("training/intelligent/history")
            if history_data and 'error' in history_data:
                st.warning(f"History API Error: {history_data['error']}")
                history_data = None
       except Exception as e:
           st.warning(f"History API Connection Error: {str(e)}")
    
       try:
            comparison_data = fetch_api("training/intelligent/model-comparison")
            if comparison_data and 'error' in comparison_data:
                 st.warning(f"Comparison API Error: {comparison_data['error']}")
                 comparison_data = None
       except Exception as e:
            st.warning(f"Comparison API Connection Error: {str(e)}")



    # Pipeline Status Metrics
    if status_data and status_data.get('pipeline_active'):
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("ü§ñ Pipeline Status", "Active", delta="Operational")
        
        with col2:
            pipeline_type = status_data.get('pipeline_type', 'unknown')
            st.metric("üß† Selection Method", "Intelligent" if pipeline_type == 'intelligent_auto_selection' else "Manual")
        
        with col3:
            if status_data.get('recent_monitoring'):
                last_check = pd.to_datetime(status_data['recent_monitoring'][0]['check_date'])
                st.metric("‚è∞ Last Check", last_check.strftime("%m-%d %H:%M"))
            else:
                st.metric("‚è∞ Last Check", "N/A")
        
        with col4:
            model_configs = status_data.get('model_configurations', {})
            total_models = sum(len(models) for models in model_configs.values())
            st.metric("üìà Active Models", f"{total_models}/12", delta="4 Regions √ó 3 Metrics")
        
        with col5:
            model_types = status_data.get('all_model_types_tested', [])
            st.metric("üî¨ Model Types Tested", len(model_types), delta=", ".join(model_types))
        
        # Pipeline Health Banner
        if status_data.get('pipeline_type') == 'intelligent_auto_selection':
            st.success("‚úÖ **Intelligent Pipeline Active** - All model types (ARIMA, XGBoost, LSTM) are automatically trained and the best performing model is selected based on RMSE performance.")
        else:
            st.warning("‚ö†Ô∏è **Fallback Mode** - Unable to connect to intelligent training pipeline. Using static configuration.")
    
    else:
        st.error("‚ùå **Pipeline Connection Failed** - Unable to retrieve intelligent training status.")
        st.info("üí° **Troubleshooting:** Check if the model training pipeline is running and the performance database is accessible.")
    
    # === SECTION 2: INTELLIGENT TRAINING CONTROLS ===
    st.markdown("---")
    st.markdown("## üéÆ Intelligent Training Controls")
    
    control_col1, control_col2, control_col3, control_col4 = st.columns([2, 1, 1, 1])
    
    with control_col1:
        if st.button("üöÄ Trigger Intelligent Training", type="primary", use_container_width=True):
            with st.spinner("üîÑ Starting intelligent training pipeline..."):
                try:
                    response = requests.post(f"{BASE_URL}training/intelligent/trigger")
                    if response.status_code == 200:
                        result = response.json()
                        st.success(f"‚úÖ {result.get('status', 'Training started')}")
                        st.info(f"üî¨ **Training Models:** {', '.join(result.get('models_to_test', []))}")
                        st.info(f"üìä **Metrics:** {', '.join(result.get('metrics_to_train', []))}")
                        time.sleep(2)
                        st.rerun()
                    else:
                        st.error(f"‚ùå Failed to start training (Status: {response.status_code})")
                except Exception as e:
                    st.error(f"üîå Connection error: {str(e)}")
    
    with control_col2:
        if st.button("üîÑ Refresh Status", use_container_width=True):
            st.rerun()
    
    with control_col3:
        if st.button("üìä View Logs", use_container_width=True):
            st.info("üìù Check terminal/console for detailed training progress")
    
    with control_col4:
        if st.button("‚öôÔ∏è Configuration", use_container_width=True):
            if config_data:
                st.json(config_data)
            else:
                st.error("Config data unavailable")
    
    # === SECTION 3: CURRENT BEST MODELS (AUTO-SELECTED) ===
    st.markdown("---")
    st.markdown("## üèÜ Current Best Models (Auto-Selected)")
    
    if status_data and status_data.get('model_configurations'):
        model_configs = status_data['model_configurations']
        
        # Create tabs for different metrics
        cpu_tab, users_tab, storage_tab = st.tabs(["üñ•Ô∏è CPU Models", "üë• Users Models", "üíæ Storage Models"])
        
        with cpu_tab:
            if 'cpu' in model_configs and model_configs['cpu']:
                cpu_models = model_configs['cpu']
                cpu_df = pd.DataFrame([
                    {"Region": region, "Best Model": model, "Status": "‚úÖ Active", "Selection": "Auto"} 
                    for region, model in cpu_models.items()
                ])
                st.dataframe(cpu_df, use_container_width=True, hide_index=True)
            else:
                st.info("üîÑ CPU model configuration not available. Pipeline may be initializing.")
        
        with users_tab:
            if 'users' in model_configs and model_configs['users']:
                users_models = model_configs['users']
                users_df = pd.DataFrame([
                    {"Region": region, "Best Model": model, "Status": "‚úÖ Active", "Selection": "Auto"} 
                    for region, model in users_models.items()
                ])
                st.dataframe(users_df, use_container_width=True, hide_index=True)
            else:
                st.info("üîÑ Users model configuration not available. Pipeline may be initializing.")
        
        with storage_tab:
            if 'storage' in model_configs and model_configs['storage']:
                storage_models = model_configs['storage']
                storage_df = pd.DataFrame([
                    {"Region": region, "Best Model": model, "Status": "‚úÖ Active", "Selection": "Auto"} 
                    for region, model in storage_models.items()
                ])
                st.dataframe(storage_df, use_container_width=True, hide_index=True)
            else:
                st.info("üîÑ Storage model configuration not available. Pipeline may be initializing.")
    
    else:
        st.warning("‚ö†Ô∏è Model configurations not available. Please check pipeline connection.")
    
    # === SECTION 4: MODEL PERFORMANCE ANALYTICS ===
    st.markdown("---")
    st.markdown("## üìà Model Performance Analytics")
    
    if status_data and status_data.get('current_models'):
        models_df = pd.DataFrame(status_data['current_models'])
        
        if not models_df.empty and 'rmse' in models_df.columns:
            perf_tab1, perf_tab2, perf_tab3 = st.tabs(["üìä RMSE Performance", "üìâ MAE Analysis", "üìã Detailed Metrics"])
            
            with perf_tab1:
                # RMSE Performance Chart
                fig_rmse = go.Figure()
                
                # Separate by metric type
                cpu_models = models_df[models_df['metric_type'] == 'cpu'] if 'metric_type' in models_df.columns else pd.DataFrame()
                users_models = models_df[models_df['metric_type'] == 'users'] if 'metric_type' in models_df.columns else pd.DataFrame()
                storage_models = models_df[models_df['metric_type'] == 'storage'] if 'metric_type' in models_df.columns else pd.DataFrame()
                
                if not cpu_models.empty:
                    fig_rmse.add_trace(go.Bar(
                        name="üñ•Ô∏è CPU Models",
                        x=cpu_models['region'],
                        y=cpu_models['rmse'],
                        marker_color='#3498DB',
                        text=[f"{v:.2f}" for v in cpu_models['rmse']],
                        textposition='auto',
                        customdata=cpu_models['model_type'] if 'model_type' in cpu_models.columns else ['N/A'] * len(cpu_models),
                        hovertemplate="<b>%{x} - CPU</b><br>Model: %{customdata}<br>RMSE: %{y:.2f}<extra></extra>"
                    ))
                
                if not users_models.empty:
                    fig_rmse.add_trace(go.Bar(
                        name="üë• Users Models",
                        x=users_models['region'],
                        y=users_models['rmse'],
                        marker_color='#E74C3C',
                        text=[f"{v:.2f}" for v in users_models['rmse']],
                        textposition='auto',
                        customdata=users_models['model_type'] if 'model_type' in users_models.columns else ['N/A'] * len(users_models),
                        hovertemplate="<b>%{x} - Users</b><br>Model: %{customdata}<br>RMSE: %{y:.2f}<extra></extra>"
                    ))
                
                if not storage_models.empty:
                    fig_rmse.add_trace(go.Bar(
                        name="üíæ Storage Models",
                        x=storage_models['region'],
                        y=storage_models['rmse'],
                        marker_color='#2ECC71',
                        text=[f"{v:.2f}" for v in storage_models['rmse']],
                        textposition='auto',
                        customdata=storage_models['model_type'] if 'model_type' in storage_models.columns else ['N/A'] * len(storage_models),
                        hovertemplate="<b>%{x} - Storage</b><br>Model: %{customdata}<br>RMSE: %{y:.2f}<extra></extra>"
                    ))
                
                fig_rmse.update_layout(
                    title="üéØ Best Model RMSE Performance by Region & Metric",
                    xaxis_title="Region",
                    yaxis_title="RMSE (Lower is Better)",
                    barmode='group',
                    height=450,
                    showlegend=True
                )
                
                st.plotly_chart(fig_rmse, use_container_width=True)
            
            with perf_tab2:
                # MAE Analysis Chart
                if 'mae' in models_df.columns and not models_df['mae'].isna().all():
                    fig_mae = go.Figure()
                    
                    cpu_mae = cpu_models[cpu_models['mae'].notna()] if not cpu_models.empty else pd.DataFrame()
                    users_mae = users_models[users_models['mae'].notna()] if not users_models.empty else pd.DataFrame()
                    storage_mae = storage_models[storage_models['mae'].notna()] if not storage_models.empty else pd.DataFrame()
                    
                    if not cpu_mae.empty:
                        fig_mae.add_trace(go.Bar(
                            name="üñ•Ô∏è CPU Models",
                            x=cpu_mae['region'],
                            y=cpu_mae['mae'],
                            marker_color='#3498DB',
                            text=[f"{v:.1f}" for v in cpu_mae['mae']],
                            textposition='auto'
                        ))
                    
                    if not users_mae.empty:
                        fig_mae.add_trace(go.Bar(
                            name="üë• Users Models",
                            x=users_mae['region'],
                            y=users_mae['mae'],
                            marker_color='#E74C3C',
                            text=[f"{v:.1f}" for v in users_mae['mae']],
                            textposition='auto'
                        ))
                    
                    if not storage_mae.empty:
                        fig_mae.add_trace(go.Bar(
                            name="üíæ Storage Models",
                            x=storage_mae['region'],
                            y=storage_mae['mae'],
                            marker_color='#2ECC71',
                            text=[f"{v:.1f}" for v in storage_mae['mae']],
                            textposition='auto'
                        ))
                    
                    fig_mae.update_layout(
                        title="üìâ Mean Absolute Error (MAE) by Region & Metric",
                        xaxis_title="Region",
                        yaxis_title="MAE (Lower is Better)",
                        barmode='group',
                        height=450,
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_mae, use_container_width=True)
                else:
                    st.info("üìä MAE data not available for current models")
            
            with perf_tab3:
                # Detailed Metrics Table
                if not models_df.empty:
                    # Format the dataframe for better display
                    display_df = models_df.copy()
                    
                    # Round numeric columns
                    numeric_cols = ['rmse', 'mae', 'mape']
                    for col in numeric_cols:
                        if col in display_df.columns:
                            display_df[col] = display_df[col].round(3)
                    
                    # Format training date if available
                    if 'training_date' in display_df.columns:
                        display_df['training_date'] = pd.to_datetime(display_df['training_date']).dt.strftime('%Y-%m-%d %H:%M')
                    
                    st.dataframe(display_df, use_container_width=True, hide_index=True)
                    
                    # Download button for detailed metrics
                    csv = display_df.to_csv(index=False)
                    st.download_button(
                        label="üíæ Download Model Performance Data",
                        data=csv,
                        file_name=f"model_performance_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                        mime="text/csv"
                    )
                else:
                    st.info("üìã No detailed metrics available")
        else:
            st.info("üìä Performance data not available. Trigger training to generate performance metrics.")
    
    # === SECTION 5: TRAINING HISTORY & TRENDS ===
    st.markdown("---")
    st.markdown("## üìú Training History & Trends")
    
    if history_data:
        history_tab1, history_tab2, history_tab3 = st.tabs(["üìà Performance History", "üîÑ Training Activity", "üìä Model Comparison"])
        
        with history_tab1:
            if history_data.get('performance_history'):
                perf_history = pd.DataFrame(history_data['performance_history'])
                
                if not perf_history.empty:
                    # Training date trend chart
                    perf_history['training_date'] = pd.to_datetime(perf_history['training_date'])
                    perf_history = perf_history.sort_values('training_date')
                    
                    fig_trend = go.Figure()
                    
                    # Group by metric type and create trend lines
                    for metric_type in perf_history['metric_type'].unique():
                        metric_data = perf_history[perf_history['metric_type'] == metric_type]
                        
                        colors = {'cpu': '#3498DB', 'users': '#E74C3C', 'storage': '#2ECC71'}
                        color = colors.get(metric_type, '#95A5A6')
                        
                        fig_trend.add_trace(go.Scatter(
                            x=metric_data['training_date'],
                            y=metric_data['rmse'],
                            mode='lines+markers',
                            name=f"{metric_type.upper()} RMSE",
                            line=dict(color=color, width=2),
                            marker=dict(size=6),
                            hovertemplate=f"<b>{metric_type.upper()}</b><br>" + 
                                        "Date: %{x}<br>" +
                                        "RMSE: %{y:.2f}<br>" +
                                        "<extra></extra>"
                        ))
                    
                    fig_trend.update_layout(
                        title="üìà Model Performance Trends Over Time",
                        xaxis_title="Training Date",
                        yaxis_title="RMSE (Lower is Better)",
                        height=400,
                        showlegend=True,
                        hovermode='x unified'
                    )
                    
                    st.plotly_chart(fig_trend, use_container_width=True)
                    
                    # Recent performance summary
                    recent_perf = perf_history.nlargest(10, 'training_date')
                    st.markdown("### üïí Recent Training Sessions")
                    st.dataframe(recent_perf[['training_date', 'region', 'metric_type', 'model_type', 'rmse', 'mae']], 
                               use_container_width=True, hide_index=True)
                else:
                    st.info("üìà No performance history available yet")
            else:
                st.info("üìà Performance history not available")
        
        with history_tab2:
            if history_data.get('monitoring_history'):
                monitor_history = pd.DataFrame(history_data['monitoring_history'])
                
                if not monitor_history.empty:
                    monitor_history['check_date'] = pd.to_datetime(monitor_history['check_date'])
                    monitor_history = monitor_history.sort_values('check_date')
                    
                    # Training activity chart
                    fig_activity = go.Figure()
                    
                    fig_activity.add_trace(go.Scatter(
                        x=monitor_history['check_date'],
                        y=monitor_history['new_records'],
                        mode='lines+markers',
                        name='New Records',
                        line=dict(color='#3498DB', width=2),
                        marker=dict(size=6),
                        yaxis='y'
                    ))
                    
                    fig_activity.add_trace(go.Scatter(
                        x=monitor_history['check_date'],
                        y=monitor_history['training_triggered'].astype(int),
                        mode='markers',
                        name='Training Triggered',
                        marker=dict(color='#E74C3C', size=10, symbol='diamond'),
                        yaxis='y2'
                    ))
                    
                    fig_activity.update_layout(
                        title="üîÑ Data Monitoring & Training Activity",
                        xaxis_title="Date",
                        yaxis=dict(title="New Records", side='left'),
                        yaxis2=dict(title="Training Triggered", side='right', overlaying='y', range=[-0.1, 1.1]),
                        height=400,
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_activity, use_container_width=True)
                    
                    # Activity summary
                    total_checks = len(monitor_history)
                    training_sessions = monitor_history['training_triggered'].sum()
                    avg_new_records = monitor_history['new_records'].mean()
                    
                    activity_col1, activity_col2, activity_col3 = st.columns(3)
                    with activity_col1:
                        st.metric("üìä Total Checks", total_checks)
                    with activity_col2:
                        st.metric("üöÄ Training Sessions", int(training_sessions))
                    with activity_col3:
                        st.metric("üìà Avg New Records", f"{avg_new_records:.1f}")
                else:
                    st.info("üîÑ No monitoring history available yet")
            else:
                st.info("üîÑ Monitoring history not available")
        
        with history_tab3:
            if comparison_data:
                if comparison_data.get('all_model_comparison'):
                    all_models = pd.DataFrame(comparison_data['all_model_comparison'])
                    
                    if not all_models.empty:
                        # Model comparison heatmap
                        pivot_rmse = all_models.pivot_table(values='rmse', index='region', columns=['metric_type', 'model_type'])
                        
                        fig_heatmap = go.Figure(data=go.Heatmap(
                            z=pivot_rmse.values,
                            x=[f"{col[0]}_{col[1]}" for col in pivot_rmse.columns],
                            y=pivot_rmse.index,
                            colorscale='RdYlGn_r',  # Red (high RMSE) to Green (low RMSE)
                            text=np.round(pivot_rmse.values, 2),
                            texttemplate="%{text}",
                            textfont={"size": 10},
                            hovertemplate="<b>%{y}</b><br>%{x}<br>RMSE: %{z:.2f}<extra></extra>"
                        ))
                        
                        fig_heatmap.update_layout(
                            title="üî• Model Performance Heatmap (RMSE)",
                            xaxis_title="Metric_ModelType",
                            yaxis_title="Region",
                            height=400
                        )
                        
                        st.plotly_chart(fig_heatmap, use_container_width=True)
                        
                        # Best models summary
                        st.markdown("### üèÜ Best Performing Models by Category")
                        best_models = all_models.loc[all_models.groupby(['region', 'metric_type'])['rmse'].idxmin()]
                        st.dataframe(best_models[['region', 'metric_type', 'model_type', 'rmse', 'mae']], 
                                   use_container_width=True, hide_index=True)
                    else:
                        st.info("üìä No model comparison data available")
                else:
                    st.info("üìä Model comparison data not available")
            else:
                st.info("üìä No comparison data available")
    
    # === SECTION 6: SYSTEM HEALTH & MONITORING ===
    st.markdown("---")
    st.markdown("## üè• System Health & Monitoring")
    
    health_col1, health_col2, health_col3, health_col4 = st.columns(4)
    
    with health_col1:
        if status_data and status_data.get('pipeline_active'):
            st.metric("üü¢ Pipeline Health", "Healthy", delta="All systems operational")
        else:
            st.metric("üî¥ Pipeline Health", "Offline", delta="Connection issues")
    
    with health_col2:
        if status_data and status_data.get('database_path'):
            st.metric("üóÑÔ∏è Database", "Connected", delta=f"Path: {status_data['database_path']}")
        else:
            st.metric("üóÑÔ∏è Database", "Unavailable", delta="Check database connection")
    
    with health_col3:
        if config_data and config_data.get('supported_metrics'):
            metrics_count = len(config_data['supported_metrics'])
            st.metric("üìä Supported Metrics", metrics_count, delta=", ".join(config_data['supported_metrics']))
        else:
            st.metric("üìä Supported Metrics", "Unknown", delta="Config unavailable")
    
    with health_col4:
        if status_data and status_data.get('model_directories'):
            directories = status_data['model_directories']
            available_dirs = sum(1 for path in directories.values() if os.path.exists(path)) if directories else 0
            total_dirs = len(directories) if directories else 0
            st.metric("üìÇ Model Directories", f"{available_dirs}/{total_dirs}", delta="Available/Total")
        else:
            st.metric("üìÇ Model Directories", "Unknown", delta="Status unavailable")
    
    # === SECTION 7: QUICK ACTIONS & UTILITIES ===
    st.markdown("---")
    st.markdown("## ‚ö° Quick Actions & Utilities")
    
    action_col1, action_col2, action_col3, action_col4 = st.columns(4)
    
    with action_col1:
        if st.button("üìä View Raw Status", use_container_width=True):
            if status_data:
                st.json(status_data)
            else:
                st.error("No status data available")
    
    with action_col2:
        if st.button("üîç Model Comparison", use_container_width=True):
            if comparison_data:
                st.json(comparison_data)
            else:
                st.error("No comparison data available")
    
    with action_col3:
        if st.button("üìú Latest History", use_container_width=True):
            if history_data:
                # Show recent performance
                recent_performance = history_data.get('performance_history', [])[:5]
                recent_monitoring = history_data.get('monitoring_history', [])[:5]
                st.json({"recent_performance": recent_performance, "recent_monitoring": recent_monitoring})
            else:
                st.error("No history data available")
    
    with action_col4:
        if st.button("‚öôÔ∏è System Config", use_container_width=True):
            if config_data:
                st.json(config_data)
            else:
                st.error("No config data available")
    
    # === SECTION 8: CONNECTION STATUS ===
    st.markdown("---")
    st.markdown("## üîå API Connection Status")
    
    status_col1, status_col2, status_col3, status_col4 = st.columns(4)
    
    with status_col1:
        if status_data:
            st.success("‚úÖ Status API")
        else:
            st.error("‚ùå Status API")
    
    with status_col2:
        if comparison_data:
            st.success("‚úÖ Comparison API")
        else:
            st.error("‚ùå Comparison API")
    
    with status_col3:
        if history_data:
            st.success("‚úÖ History API")
        else:
            st.error("‚ùå History API")
    
    with status_col4:
        if config_data:
            st.success("‚úÖ Config API")
        else:
            st.error("‚ùå Config API")
   
#-------------------------------------------i have edited up code-------------------------------------------------
# TAB 9  CODE - ADD TO YOUR DASHBOARD_APP.PY

# TAB 9: CAPACITY PLANNING - ADD TO YOUR DASHBOARD_APP.PY


# STEP 2: ADD TAB 9 CODE AFTER YOUR EXISTING TAB 8 CODE

# ===== TAB 9: INTELLIGENT CAPACITY PLANNING & RESOURCE OPTIMIZATION =====
with tab9:
    st.markdown("# üèóÔ∏è Intelligent Capacity Planning & Resource Optimization")
    st.markdown("*Enterprise-grade capacity planning using AI-powered forecasting models*")
    
    # Show dynamic integration status with current models
    try:
        cpu_models_info = fetch_api('forecast/models')
        users_models_info = fetch_api('forecast/users/models')
        storage_models_info = fetch_api('forecast/storage/models')
        
        # Extract current model info dynamically
        cpu_models = {}
        users_models = {}
        storage_models = {}
        
        if cpu_models_info and cpu_models_info.get('models'):
            cpu_models = {region: info.get('model_type', 'Unknown') for region, info in cpu_models_info['models'].items()}
        
        if users_models_info and users_models_info.get('models'):
            users_models = {region: info.get('model_type', 'Unknown') for region, info in users_models_info['models'].items()}
            
        if storage_models_info and storage_models_info.get('models'):
            storage_models = {region: info.get('model_type', 'Unknown') for region, info in storage_models_info['models'].items()}
        
        # Dynamic integration status
        total_models = len(cpu_models) + len(users_models) + len(storage_models)
        st.success(f"""
        üîó **Live Integration Status**: Connected to {total_models} active forecasting models
        
        **üñ•Ô∏è CPU Models**: {', '.join([f"{r} ({m})" for r, m in cpu_models.items()]) if cpu_models else 'Loading...'}
        
        **üë• Users Models**: {', '.join([f"{r} ({m})" for r, m in users_models.items()]) if users_models else 'Loading...'}
        
        **üíæ Storage Models**: {', '.join([f"{r} ({m})" for r, m in storage_models.items()]) if storage_models else 'Loading...'}
        
        **‚ö° Smart Caching**: Optimized forecasts for 1-day, 7-day, and 30-day planning
        """)
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Model status retrieval issue: {str(e)}")
        st.info("""
        üîó **Integration Status**: Connecting to forecasting models...
        ‚Ä¢ **CPU Models**: East US, North Europe, Southeast Asia, West US  
        ‚Ä¢ **Users Models**: East US, North Europe, Southeast Asia, West US
        ‚Ä¢ **Storage Models**: East US, North Europe, Southeast Asia, West US
        """)
    
    # ===== CAPACITY PLANNING CONTROLS =====
    st.markdown("---")
    st.markdown("### üéõÔ∏è Capacity Planning Configuration")
    
    config_col1, config_col2, config_col3, config_col4 = st.columns(4)
    
    with config_col1:
        selected_service = st.selectbox(
            "üîß Service Type",
            options=['Compute', 'Storage', 'Users'],
            index=0,
            help="Select the service type for capacity analysis"
        )
    
    with config_col2:
        forecast_option = st.selectbox(
            "üìÖ Forecast Period",
            options=['Next Day (1 day)', 'Next Week (7 days)', 'Next Month (30 days)', 'Custom Range'],
            index=2,
            help="Select forecast period - default periods use cached results"
        )
        
        # Extract horizon from selection
        if 'Next Day' in forecast_option:
            planning_horizon = 1
        elif 'Next Week' in forecast_option:
            planning_horizon = 7
        elif 'Next Month' in forecast_option:
            planning_horizon = 30
        else:  # Custom Range
            planning_horizon = st.slider("Custom Days", min_value=1, max_value=90, value=30)
    
    with config_col3:
        selected_region_capacity = st.selectbox(
            "üåç Region Focus",
            options=['All Regions', 'East US', 'West US', 'North Europe', 'Southeast Asia'],
            index=0,
            help="Focus on specific region or analyze all regions"
        )
    
    with config_col4:
        show_details = st.toggle(
            "üîç Show Details",
            value=True,
            help="Show detailed analysis and charts"
        )
    
    # ===== CAPACITY ANALYSIS DASHBOARD =====
    st.markdown("---")
    st.markdown("### üìä Real-Time Capacity Analysis")
    
    # Add cache status indicator
    cache_status = "üü¢ Using cached data" if planning_horizon in [1, 7, 30] else "üü° Generating fresh data"
    st.markdown(f"*{cache_status} ‚Ä¢ Analyzing {selected_service} over {planning_horizon} days*")
    
    # Fetch capacity planning data with better error handling
    capacity_data = None
    with st.spinner(f"üîÑ Analyzing capacity for {selected_region_capacity}..."):
        capacity_params = {
            'region': selected_region_capacity,
            'service': selected_service,
            'horizon': planning_horizon
        }
        
        try:
            capacity_data = fetch_api('capacity-planning', capacity_params)
        except Exception as e:
            st.error(f"‚ùå API Connection Error: {str(e)}")
            capacity_data = None
    
    # ===== SUCCESS STATE: FULL CAPACITY ANALYSIS =====
    if capacity_data and capacity_data.get('capacity_analysis') and not capacity_data.get('error'):
        
        # ===== SUMMARY METRICS =====
        summary = capacity_data.get('summary', {})
        capacity_analysis = capacity_data['capacity_analysis']
        
        # Filter out error regions
        successful_analysis = {k: v for k, v in capacity_analysis.items() if not v.get('error')}
        error_regions = {k: v for k, v in capacity_analysis.items() if v.get('error')}
        
        if not successful_analysis:
            st.error("‚ùå No regions could be analyzed. Check model availability.")
        else:
            # Summary metrics row
            summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
            
            with summary_col1:
                st.metric(
                    "üåç Regions Analyzed",
                    len(successful_analysis),
                    delta=f"{len(error_regions)} errors" if error_regions else "All successful",
                    delta_color="inverse" if error_regions else "normal",
                    help="Successfully analyzed regions"
                )
            
            with summary_col2:
                risk_dist = summary.get('risk_distribution', {})
                high_risk = risk_dist.get('high_risk', 0)
                medium_risk = risk_dist.get('medium_risk', 0)
                total_risk = high_risk + medium_risk
                st.metric(
                    "‚ö†Ô∏è At-Risk Regions",
                    f"{high_risk} High" if high_risk > 0 else "None",
                    delta=f"{medium_risk} Medium" if medium_risk > 0 else "All healthy",
                    delta_color="inverse" if total_risk > 0 else "normal",
                    help="Regions with capacity risks"
                )
            
            with summary_col3:
                overall_status = summary.get('overall_status', 'UNKNOWN')
                status_colors = {'HEALTHY': 'üü¢', 'WARNING': 'üü°', 'CRITICAL': 'üî¥', 'UNKNOWN': '‚ö™'}
                status_emoji = status_colors.get(overall_status, '‚ö™')
                st.metric(
                    "üéØ Overall Status",
                    f"{status_emoji} {overall_status}",
                    help="Overall capacity health across all regions"
                )
            
            with summary_col4:
                data_source = capacity_data.get('data_source', 'live_models')
                cache_indicator = "üìÅ Cached" if "cached" in data_source.lower() else "üîÑ Live"
                source_display = data_source.replace('_', ' ').title()
                st.metric(
                    "ü§ñ Data Source",
                    cache_indicator,
                    delta=source_display,
                    help="Using cached or live forecasting models"
                )
            
            # ===== MODEL SOURCES TABLE =====
            if show_details:
                st.markdown("#### üéØ Forecast Model Sources")
                model_source_data = []
                for region, analysis in successful_analysis.items():
                    forecast_source = analysis.get('forecast_source', {})
                    model_source_data.append({
                        'Region': region,
                        'Service Analyzed': analysis.get('service', selected_service),
                        'CPU Model': forecast_source.get('cpu_model', 'Not used'),
                        'Users Model': forecast_source.get('users_model', 'Not used'),
                        'Storage Model': forecast_source.get('storage_model', 'Not used'),
                        'Forecast Days': analysis.get('forecast_horizon_days', planning_horizon),
                        'Status': '‚úÖ Success'
                    })
                
                if model_source_data:
                    df_sources = pd.DataFrame(model_source_data)
                    st.dataframe(df_sources, use_container_width=True, hide_index=True)
            
            # ===== CAPACITY UTILIZATION OVERVIEW =====
            st.markdown("#### üå°Ô∏è Capacity Utilization Overview")
            
            # Display up to 4 regions in cards
            util_regions = list(successful_analysis.items())[:4]
            util_cols = st.columns(len(util_regions))
            
            for idx, (region, analysis) in enumerate(util_regions):
                with util_cols[idx]:
                    utilization = analysis.get('capacity_utilization', {})
                    peak_pct = float(utilization.get('peak_pct', 0))  # Convert to number
                    current_pct = float(utilization.get('current_pct', 0))  # Convert to number
                    
                    # Color-coded metric display based on utilization
                    if peak_pct >= 95:
                        st.error(f"üî¥ **{region}**  \n{peak_pct:.1f}% Peak  \n{current_pct:.1f}% Avg")
                    elif peak_pct >= 85:
                        st.warning(f"üü° **{region}**  \n{peak_pct:.1f}% Peak  \n{current_pct:.1f}% Avg")
                    else:
                        st.success(f"üü¢ **{region}**  \n{peak_pct:.1f}% Peak  \n{current_pct:.1f}% Avg")
                    
                    # Additional capacity info
                    capacity = float(analysis.get('current_capacity', 0))
                    if capacity > 0:
                        st.caption(f"Capacity: {capacity:,} units")
                    else:
                        st.caption("Capacity: Unknown")
            
            # ===== DEMAND VS CAPACITY VISUALIZATION =====
            if show_details and successful_analysis:
                st.markdown("#### üìà Demand vs Capacity Trends")
                
                fig_capacity = go.Figure()
                colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
                
                for idx, (region, analysis) in enumerate(list(successful_analysis.items())[:4]):
                    predicted_demand = analysis.get('predicted_demand', {})
                    timeline_data = predicted_demand.get('timeline', [])
                    current_capacity = float(analysis.get('current_capacity', 1000))

                    
                    if not timeline_data:
                        continue
                    
                    # Generate date range for x-axis (limit to reasonable number for display)
                    display_days = min(len(timeline_data), 30)
                    dates = [(datetime.now() + timedelta(days=i+1)).strftime('%m-%d') 
                            for i in range(display_days)]
                    display_timeline = timeline_data[:display_days]
                    
                    color = colors[idx % len(colors)]
                    
                    # Add demand line
                    fig_capacity.add_trace(
                        go.Scatter(
                            x=dates,
                            y=display_timeline,
                            mode='lines+markers',
                            name=f'{region} Demand',
                            line=dict(width=3, color=color),
                            marker=dict(size=4),
                            hovertemplate=f"<b>{region} Demand</b><br>" + 
                                        "Date: %{x}<br>" +
                                        "Demand: %{y:,.1f}<br>" +
                                        "<extra></extra>"
                        )
                    )
                    
                    # Add capacity line (horizontal)
                    fig_capacity.add_trace(
                        go.Scatter(
                            x=dates,
                            y=[current_capacity] * len(dates),
                            mode='lines',
                            name=f'{region} Capacity',
                            line=dict(dash='dash', width=2, color=color),
                            opacity=0.7,
                            hovertemplate=f"<b>{region} Capacity</b><br>" + 
                                        "Capacity: %{y:,.0f}<br>" +
                                        "<extra></extra>"
                        )
                    )
                
                fig_capacity.update_layout(
                    title=f"{selected_service} Demand vs Capacity - {selected_region_capacity}",
                    height=400,
                    hovermode='x unified',
                    showlegend=True,
                    xaxis_title="Date",
                    yaxis_title=f"{selected_service} Units",
                    legend=dict(
                        orientation="h",
                        yanchor="bottom",
                        y=1.02,
                        xanchor="right",
                        x=1
                    )
                )
                
                st.plotly_chart(fig_capacity, use_container_width=True)
            
            # ===== RISK ASSESSMENT MATRIX =====
            st.markdown("#### ‚ö†Ô∏è Risk Assessment Matrix")
            
            risk_data = []
            for region, analysis in successful_analysis.items():
                risk_assessment = analysis.get('risk_assessment', {})
                utilization = analysis.get('capacity_utilization', {})
                predicted_demand = analysis.get('predicted_demand', {})
                
                risk_data.append({
                   'Region': region,
                   'Risk Level': risk_assessment.get('overall_risk', 'UNKNOWN'),
                   'Current Capacity': f"{float(analysis.get('current_capacity', 0)):,.0f}",  # ‚úÖ Fixed
                   'Peak Demand': f"{float(predicted_demand.get('max', 0)):,.1f}",  # ‚úÖ Fixed
                   'Avg Demand': f"{float(predicted_demand.get('avg', 0)):,.1f}",  # ‚úÖ Fixed
                   'Peak Utilization': f"{float(utilization.get('peak_pct', 0)):.1f}%",  # ‚úÖ Fixed
                   'Avg Utilization': f"{float(utilization.get('current_pct', 0)):.1f}%",  # ‚úÖ Fixed
                   'Status': risk_assessment.get('utilization_risk', {}).get('message', 'No assessment available')   
              })
            
            if risk_data:
                risk_df = pd.DataFrame(risk_data)
                
                # Enhanced styling for risk levels
                def highlight_risk(row):
                    risk_level = row['Risk Level']
                    if risk_level == 'HIGH':
                        return ['background-color: #ffebee; color: #c62828'] * len(row)
                    elif risk_level == 'MEDIUM':
                        return ['background-color: #fff3e0; color: #ef6c00'] * len(row)
                    elif risk_level == 'LOW':
                        return ['background-color: #e8f5e8; color: #2e7d32'] * len(row)
                    else:
                        return ['background-color: #f5f5f5; color: #424242'] * len(row)
                
                try:
                    styled_risk_df = risk_df.style.apply(highlight_risk, axis=1)
                    st.dataframe(styled_risk_df, use_container_width=True, hide_index=True)
                except Exception:
                    # Fallback to regular dataframe if styling fails
                    st.dataframe(risk_df, use_container_width=True, hide_index=True)
            
            # ===== INTELLIGENT RECOMMENDATIONS =====
            st.markdown("#### üí° Intelligent Scaling Recommendations")
            
            # Collect and sort all recommendations
            all_recommendations = []
            for region, analysis in successful_analysis.items():
                for rec in analysis.get('recommendations', []):
                    rec_copy = rec.copy()
                    rec_copy['region'] = region
                    all_recommendations.append(rec_copy)
            
            # Sort recommendations by priority
            priority_order = {'HIGH': 0, 'MEDIUM': 1, 'LOW': 2}
            all_recommendations.sort(key=lambda x: priority_order.get(x.get('priority', 'LOW'), 3))
            
            # Display recommendations by priority
            if all_recommendations:
                high_priority = [r for r in all_recommendations if r.get('priority') == 'HIGH']
                medium_priority = [r for r in all_recommendations if r.get('priority') == 'MEDIUM'] 
                low_priority = [r for r in all_recommendations if r.get('priority') == 'LOW']
                
                if high_priority:
                    st.markdown("**üö® HIGH PRIORITY ACTIONS**")
                    for idx, rec in enumerate(high_priority[:3]):  # Show top 3 high priority
                        with st.container():
                            st.error(f"""
                            **üèóÔ∏è {rec.get('type', 'ACTION')} - {rec['region']}**  
                            **Action**: {rec.get('action', 'No action specified')}  
                            **Reason**: {rec.get('reason', 'No reason provided')}  
                            **Timeline**: {rec.get('timeline', 'Immediate')}  
                            **Impact**: {rec.get('impact', 'Not specified')}
                            """)
                
                if medium_priority and show_details:
                    st.markdown("**‚ö†Ô∏è MEDIUM PRIORITY ACTIONS**")
                    for rec in medium_priority[:2]:  # Show top 2 medium priority
                        with st.container():
                            st.warning(f"""
                            **üèóÔ∏è {rec.get('type', 'ACTION')} - {rec['region']}**  
                            **Action**: {rec.get('action', 'No action specified')}  
                            **Timeline**: {rec.get('timeline', 'Within 1 month')}  
                            **Impact**: {rec.get('impact', 'Moderate')}
                            """)
                
                if low_priority and show_details:
                    with st.expander(f"‚ÑπÔ∏è Low Priority Recommendations ({len(low_priority)})"):
                        for rec in low_priority:
                            st.info(f"**{rec['region']}**: {rec.get('action', 'Monitor and maintain')}")
                
            else:
                st.success("‚úÖ **All regions are optimally provisioned!** No immediate actions required.")
            
            # ===== CAPACITY OPTIMIZATION INSIGHTS =====
            if show_details:
                st.markdown("#### üìà Capacity Optimization Insights")
                
                insight_col1, insight_col2, insight_col3 = st.columns(3)
                
                with insight_col1:
                    # Calculate optimization opportunities (under-utilized regions)
                    over_provisioned = sum(1 for analysis in successful_analysis.values() 
                                          if float(analysis.get('capacity_utilization', {}).get('current_pct', 100)) < 40)
                    st.metric(
                        "üéØ Optimization Opportunities",
                        over_provisioned,
                        delta=f"{over_provisioned}/{len(successful_analysis)} regions",
                        delta_color="normal",
                        help="Regions with potential cost savings (< 40% utilization)"
                    )
                
                with insight_col2:
                    # Calculate scaling needs
                    scale_up_needed = sum(1 for rec in all_recommendations if rec.get('type') == 'SCALE_UP')
                    high_priority_scale = sum(1 for rec in all_recommendations 
                                            if rec.get('type') == 'SCALE_UP' and rec.get('priority') == 'HIGH')
                    
                    st.metric(
                        "üöÄ Scaling Actions Needed",
                        scale_up_needed,
                        delta=f"High Priority: {high_priority_scale}" if high_priority_scale > 0 else "None urgent",
                        delta_color="inverse" if high_priority_scale > 0 else "normal",
                        help="Regions requiring capacity increases"
                    )
                
                with insight_col3:
                    # Calculate average utilization across all regions
                    if successful_analysis:
                        # ‚úÖ FIXED CODE:
                        utilization_values = [float(analysis.get('capacity_utilization', {}).get('current_pct', 0)) 
                                            for analysis in successful_analysis.values()]
                        avg_utilization = sum(utilization_values) / len(utilization_values)
                        # Determine if utilization is in optimal range (60-80%)
                        optimal_range = "Optimal" if 60 <= avg_utilization <= 80 else "Sub-optimal"
                        
                        st.metric(
                            "üìä Average Utilization",
                            f"{avg_utilization:.1f}%",
                            delta=f"Target: 60-80% ({optimal_range})",
                            delta_color="normal" if optimal_range == "Optimal" else "inverse",
                            help="Current average capacity utilization across all regions"
                        )
        
        # ===== ERROR REGIONS SUMMARY =====
        if error_regions:
            with st.expander(f"‚ö†Ô∏è Processing Errors ({len(error_regions)} regions)"):
                st.warning("The following regions could not be processed:")
                for region, error_info in error_regions.items():
                    st.write(f"**{region}**: {error_info.get('error', 'Unknown error occurred')}")
                st.info("üí° Check if forecasting models are loaded for these regions")
    
    # ===== ERROR STATE: API ISSUES OR NO DATA =====
    else:
        if capacity_data and capacity_data.get('error'):
            error_message = capacity_data.get('error', 'Unknown error')
            st.error(f"‚ùå **Capacity Planning API Error**: {error_message}")
            
            # Provide specific troubleshooting based on error type
            error_lower = error_message.lower()
            if 'model' in error_lower:
                st.info("ü§ñ **Model Issue**: Check if forecasting models are loaded and running properly.")
            elif 'data' in error_lower or 'not found' in error_lower:
                st.info("üìä **Data Issue**: Ensure historical data is available for analysis.")
            elif 'connection' in error_lower or 'timeout' in error_lower:
                st.info("üîó **Connection Issue**: Check API connectivity and server status.")
                
            # Show available regions if provided
            available_regions = capacity_data.get('available_regions', [])
            if available_regions:
                st.info(f"üåç **Available Regions**: {', '.join(available_regions)}")
        
        elif capacity_data is None:
            st.error("‚ùå **API Connection Failed**: Unable to reach capacity planning service.")
            st.info("üîó Check if the backend server is running and accessible.")
        
        else:
            st.warning("‚ö†Ô∏è **No Capacity Data**: Service returned empty response.")
        
        # ===== ENHANCED DEMO MODE =====
        st.markdown("---")
        st.markdown("### üìä Demo Mode: Capacity Planning Interface")
        st.info("üí° **Demo Mode Active**: Showing sample capacity planning interface with your model configuration")
        
        # Demo metrics based on actual model info
        demo_col1, demo_col2, demo_col3, demo_col4 = st.columns(4)
        
        with demo_col1:
            total_regions = len(cpu_models) if cpu_models else 4
            st.metric("üåç Regions", total_regions, help="Total regions configured")
            
        with demo_col2:
            st.metric("‚ö†Ô∏è At-Risk", "1 High", delta="2 Medium", help="Sample risk distribution")
            
        with demo_col3:
            st.metric("üéØ Status", "üü° WARNING", help="Sample overall status")
            
        with demo_col4:
            demo_models = total_models if 'total_models' in locals() else 12
            st.metric("ü§ñ Active Models", demo_models, help="Your forecasting models")
        
        # Demo recommendations
        st.markdown("#### üìã Sample Recommendations")
        st.error("üö® **SCALE_UP - East US**: Increase compute capacity by 20% within 1 week due to predicted demand surge")
        st.warning("‚ö†Ô∏è **MONITOR - West US**: Watch utilization trends closely - approaching 85% threshold")
        st.success("‚úÖ **OPTIMIZE - North Europe**: Consider downsizing by 10% to reduce costs while maintaining performance")
        st.info("‚ÑπÔ∏è **MAINTAIN - Southeast Asia**: Continue current capacity levels - optimal utilization detected")
    
    # ===== ENHANCED DOWNLOAD REPORTS SECTION =====
    st.markdown("---")
    st.markdown("### üìä Capacity Planning Reports & Utilities")
    
    report_col1, report_col2, report_col3 = st.columns(3)
    
    with report_col1:
        if st.button("üìä Generate Capacity Report", use_container_width=True):
            if capacity_data and capacity_data.get('capacity_analysis'):
                try:
                    # Create comprehensive capacity report
                    report_data = []
                    for region, analysis in capacity_data['capacity_analysis'].items():
                        if not analysis.get('error'):
                            utilization = analysis.get('capacity_utilization', {})
                            predicted_demand = analysis.get('predicted_demand', {})
                            risk_assessment = analysis.get('risk_assessment', {})
                            forecast_source = analysis.get('forecast_source', {})
                            
                            # ‚úÖ FIXED CODE:
                            report_data.append({
                                'Region': region,
                                'Service_Type': analysis.get('service', selected_service),
                                'Analysis_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                'Forecast_Horizon_Days': int(analysis.get('forecast_horizon_days', planning_horizon)),  # ‚úÖ Fixed
                                'Current_Capacity': float(analysis.get('current_capacity', 0)),  # ‚úÖ Fixed
                                'Peak_Demand': float(predicted_demand.get('max', 0)),  # ‚úÖ Fixed
                                'Average_Demand': float(predicted_demand.get('avg', 0)),  # ‚úÖ Fixed
                                'Min_Demand': float(predicted_demand.get('min', 0)),  # ‚úÖ Fixed
                                'Peak_Utilization_%': float(utilization.get('peak_pct', 0)),  # ‚úÖ Fixed
                                'Average_Utilization_%': float(utilization.get('current_pct', 0)),  # ‚úÖ Fixed
                                'Risk_Level': risk_assessment.get('overall_risk', 'UNKNOWN'),
                                'Risk_Message': risk_assessment.get('utilization_risk', {}).get('message', 'No assessment'),
                                'CPU_Model_Used': forecast_source.get('cpu_model', 'Not used'),
                                'Users_Model_Used': forecast_source.get('users_model', 'Not used'),
                                'Storage_Model_Used': forecast_source.get('storage_model', 'Not used'),
                                'Data_Source': capacity_data.get('data_source', 'Unknown')
                            })
                    
                    if report_data:
                        report_df = pd.DataFrame(report_data)
                        csv_data = report_df.to_csv(index=False)
                        
                        st.success(f"‚úÖ Capacity report generated for {len(report_data)} regions!")
                        st.download_button(
                            label="‚¨áÔ∏è Download Capacity Report (CSV)",
                            data=csv_data,
                            file_name=f"capacity_report_{selected_service.lower()}_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                        
                        # Show preview
                        with st.expander("üìã Report Preview"):
                            st.dataframe(report_df.head(), use_container_width=True)
                    else:
                        st.warning("üìä No valid data available for report generation")
                        
                except Exception as e:
                    st.error(f"‚ùå Error generating capacity report: {str(e)}")
            else:
                st.info("üìä No capacity data available. Run analysis first to generate reports.")
    
    with report_col2:
        if st.button("üìà Export Recommendations", use_container_width=True):
            if capacity_data and capacity_data.get('capacity_analysis'):
                try:
                    # Export all recommendations
                    all_recs = []
                    for region, analysis in capacity_data['capacity_analysis'].items():
                        if analysis.get('recommendations') and not analysis.get('error'):
                            for rec in analysis['recommendations']:
                                all_recs.append({
                                    'Region': region,
                                    'Service_Type': analysis.get('service', selected_service),
                                    'Recommendation_Type': rec.get('type', 'UNKNOWN'),
                                    'Priority': rec.get('priority', 'LOW'),
                                    'Action_Required': rec.get('action', ''),
                                    'Reason': rec.get('reason', ''),
                                    'Timeline': rec.get('timeline', ''),
                                    'Expected_Impact': rec.get('impact', ''),
                                    'Current_Capacity': analysis.get('current_capacity', 0),
                                    'Risk_Level': analysis.get('risk_assessment', {}).get('overall_risk', 'UNKNOWN'),
                                    'Generated_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                    'Forecast_Horizon': analysis.get('forecast_horizon_days', planning_horizon)
                                })
                    
                    if all_recs:
                        rec_df = pd.DataFrame(all_recs)
                        csv_data = rec_df.to_csv(index=False)
                        
                        # Count by priority
                        priority_counts = rec_df['Priority'].value_counts().to_dict()
                        priority_summary = ", ".join([f"{count} {priority}" for priority, count in priority_counts.items()])
                        
                        st.success(f"‚úÖ Exported {len(all_recs)} recommendations: {priority_summary}")
                        st.download_button(
                            label="‚¨áÔ∏è Download Recommendations (CSV)",
                            data=csv_data,
                            file_name=f"capacity_recommendations_{selected_service.lower()}_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                        
                        # Show preview
                        with st.expander("üìã Recommendations Preview"):
                            st.dataframe(rec_df.head(), use_container_width=True)
                    else:
                        st.info("üìà No recommendations available. All regions appear to be optimally configured!")
                        
                except Exception as e:
                    st.error(f"‚ùå Error exporting recommendations: {str(e)}")
            else:
                st.info("üìà No recommendation data available. Run analysis first to export recommendations.")
    
    with report_col3:
        if st.button("üéØ Check Model Status", use_container_width=True):
            try:
                # Fetch comprehensive model debug info
                debug_info = fetch_api('forecast/debug')
                users_debug_info = fetch_api('forecast/users/debug')
                storage_debug_info = fetch_api('forecast/storage/debug')
                
                st.success("‚úÖ **Model Status Retrieved**")
                
                # Create tabs for different model types
                model_tab1, model_tab2, model_tab3 = st.tabs(["üñ•Ô∏è CPU Models", "üë• Users Models", "üíæ Storage Models"])
                
                with model_tab1:
                    if debug_info and debug_info.get('loaded_models'):
                        loaded_models = debug_info.get('loaded_models', [])
                        model_types = debug_info.get('model_types_loaded', {})
                        
                        st.markdown("**Loaded CPU Models:**")
                        for model in loaded_models:
                            model_type = model_types.get(model, 'Unknown')
                            st.success(f"‚úÖ {model} ({model_type})")
                        
                        # Show additional CPU model info
                        if debug_info.get('ml_available'):
                            st.info("ü§ñ ML libraries available and loaded")
                        if debug_info.get('scalers_loaded'):
                            st.info(f"üîß Scalers loaded: {', '.join(debug_info.get('scalers_loaded', []))}")
                    else:
                        st.error("‚ùå No CPU model information available")
                
                with model_tab2:
                    if users_debug_info and users_debug_info.get('loaded_user_models'):
                        loaded_user_models = users_debug_info.get('loaded_user_models', [])
                        user_model_types = users_debug_info.get('user_model_types_loaded', {})
                        
                        st.markdown("**Loaded Users Models:**")
                        for model in loaded_user_models:
                            model_type = user_model_types.get(model, 'Unknown')
                            st.success(f"‚úÖ {model} ({model_type})")
                        
                        # Show additional Users model info
                        if users_debug_info.get('user_scalers_loaded'):
                            st.info(f"üîß User Scalers: {', '.join(users_debug_info.get('user_scalers_loaded', []))}")
                    else:
                        st.error("‚ùå No Users model information available")
                
                with model_tab3:
                    if storage_debug_info and storage_debug_info.get('loaded_storage_models'):
                        loaded_storage_models = storage_debug_info.get('loaded_storage_models', [])
                        storage_model_types = storage_debug_info.get('storage_model_types_loaded', {})
                        
                        st.markdown("**Loaded Storage Models:**")
                        for model in loaded_storage_models:
                            model_type = storage_model_types.get(model, 'Unknown')
                            st.success(f"‚úÖ {model} ({model_type})")
                        
                        # Show additional Storage model info
                        if storage_debug_info.get('storage_scalers_loaded'):
                            st.info(f"üîß Storage Scalers: {', '.join(storage_debug_info.get('storage_scalers_loaded', []))}")
                    else:
                        st.error("‚ùå No Storage model information available")
                    
            except Exception as e:
                st.error(f"‚ùå Error checking model status: {str(e)}")
                st.info("üîó Ensure the backend API is running and accessible")
    
   
# STEP 3: ADD TAB 10 CODE AFTER TAB 9

with tab10:
    st.markdown("# üîç Model Health Monitoring & Performance Analytics")
    st.markdown("*Real-time model performance tracking, health assessment, and automated reporting system*")
    
    # ===== MONITORING CONTROLS =====
    st.markdown("---")
    st.markdown("### üéõÔ∏è Monitoring Dashboard Controls")
    
    monitor_col1, monitor_col2, monitor_col3, monitor_col4 = st.columns(4)
    
    with monitor_col1:
        refresh_interval = st.selectbox(
            "üîÑ Refresh Interval",
            options=[5, 15, 30, 60],
            index=2,
            format_func=lambda x: f"{x} seconds",
            help="Auto-refresh interval for monitoring data"
        )
    
    with monitor_col2:
        alert_threshold = st.slider(
            "‚ö†Ô∏è Alert Threshold (%)",
            min_value=60,
            max_value=95,
            value=75,
            help="Accuracy threshold below which alerts are triggered"
        )
    
    with monitor_col3:
        show_historical = st.toggle(
            "üìà Show Historical",
            value=True,
            help="Include historical performance trends"
        )
    
    with monitor_col4:
        auto_monitoring = st.toggle(
            "ü§ñ Auto Monitoring",
            value=False,
            help="Enable automatic monitoring and alerts"
        )
    
    # Auto refresh functionality
    if auto_monitoring:
        time.sleep(refresh_interval)
        st.rerun()
    
    # ===== MODEL HEALTH OVERVIEW =====
    st.markdown("---")
    st.markdown("### üè• Real-Time Model Health Dashboard")
    
    # Get monitoring data from API
    monitoring_data = fetch_api('monitoring/accuracy')
    
    if monitoring_data:
        model_health = monitoring_data.get('model_health', {})
        accuracy_metrics = monitoring_data.get('accuracy_metrics', {})
        retraining_status = monitoring_data.get('retraining_status', {})
        
        # ===== HEALTH STATUS OVERVIEW =====
        health_col1, health_col2, health_col3, health_col4 = st.columns(4)
        
        with health_col1:
            overall_status = model_health.get('overall_status', 'UNKNOWN')
            status_colors = {'HEALTHY': 'üü¢', 'WARNING': 'üü°', 'CRITICAL': 'üî¥'}
            status_color = status_colors.get(overall_status, '‚ö™')
            avg_accuracy = model_health.get('average_accuracy', 0)
            
            st.metric(
                "üéØ Overall Health",
                f"{status_color} {overall_status}",
                delta=f"{avg_accuracy:.1f}% avg accuracy",
                help="Overall model health status across all regions"
            )
        
        with health_col2:
            healthy_models = model_health.get('healthy_models', 0)
            total_models = model_health.get('total_models', 0)
            warning_models = model_health.get('warning_models', 0)
            
            st.metric(
                "‚úÖ Healthy Models",
                f"{healthy_models}/{total_models}",
                delta=f"{warning_models} need attention",
                help="Number of models with good performance"
            )
        
        with health_col3:
            retrain_needed = len(retraining_status.get('regions_needing_retrain', []))
            
            st.metric(
                "üîÑ Retraining Queue",
                retrain_needed,
                delta="models flagged for retraining",
                delta_color="inverse",
                help="Number of models that need retraining"
            )
        
        with health_col4:
            next_retrain = retraining_status.get('next_scheduled_retrain', 'Not scheduled')
            if next_retrain != 'Not scheduled':
                next_date = pd.to_datetime(next_retrain).strftime('%m/%d %H:%M')
                st.metric(
                    "‚è∞ Next Auto-Retrain",
                    next_date,
                    delta="scheduled",
                    help="Next automatic retraining scheduled time"
                )
            else:
                st.metric(
                    "‚è∞ Next Auto-Retrain", 
                    "Not scheduled",
                    help="No automatic retraining currently scheduled"
                )
        
        # ===== MODEL ACCURACY TRENDS =====
        st.markdown("#### üìà Model Accuracy Performance by Region")
        
        # Create accuracy comparison chart
        fig_accuracy = go.Figure()
        
        regions = list(accuracy_metrics.keys())
        accuracies = [accuracy_metrics[region]['accuracy'] for region in regions]
        trends = [accuracy_metrics[region]['trend'] for region in regions]
        
        # Color code based on accuracy level
        colors = []
        for accuracy in accuracies:
            if accuracy >= 85:
                colors.append('#27ae60')  # Green
            elif accuracy >= alert_threshold:
                colors.append('#f39c12')  # Orange  
            else:
                colors.append('#e74c3c')  # Red
        
        # Add trend indicators
        trend_symbols = {'improving': '‚ÜóÔ∏è', 'stable': '‚û°Ô∏è', 'declining': '‚ÜòÔ∏è'}
        hover_text = [
            f"{region}<br>Accuracy: {accuracies[i]:.1f}%<br>Trend: {trend_symbols.get(trends[i], '‚û°Ô∏è')} {trends[i].title()}<br>MAE: {accuracy_metrics[region]['mae']}<br>RMSE: {accuracy_metrics[region]['rmse']}"
            for i, region in enumerate(regions)
        ]
        
        
        fig_accuracy.add_trace(go.Bar(
        x=regions,
        y=accuracies,
        marker_color=colors,
        text=[f"{acc:.1f}%" for acc in accuracies],
        textposition='auto',
        customdata=hover_text,
        hovertemplate='%{customdata}<extra></extra>'  # <-- ONLY ONE hovertemplate
     ))
        
        # Add threshold lines
        fig_accuracy.add_hline(
            y=85, 
            line_dash="dash", 
            line_color="green",
            annotation_text="Healthy Threshold (85%)",
            annotation_position="bottom right"
        )
        
        fig_accuracy.add_hline(
            y=alert_threshold,
            line_dash="dash", 
            line_color="orange",
            annotation_text=f"Alert Threshold ({alert_threshold}%)",
            annotation_position="top right"
        )
        
        fig_accuracy.update_layout(
            title="Current Model Accuracy by Region",
            xaxis_title="Region",
            yaxis_title="Accuracy (%)",
            showlegend=False,
            height=400,
            yaxis=dict(range=[0, 100])
        )
        
        st.plotly_chart(fig_accuracy, use_container_width=True)
        
        # ===== DETAILED PERFORMANCE METRICS =====
        st.markdown("#### üìã Detailed Performance Metrics")
        
        metrics_data = []
        for region, metrics in accuracy_metrics.items():
            trend_emoji = {'improving': 'üìà', 'stable': '‚û°Ô∏è', 'declining': 'üìâ'}.get(metrics['trend'], '‚û°Ô∏è')
            
            # Determine status based on accuracy
            if metrics['accuracy'] >= 85:
                status = '‚úÖ Excellent'
                status_color = 'green'
            elif metrics['accuracy'] >= alert_threshold:
                status = '‚ö†Ô∏è Warning'  
                status_color = 'orange'
            else:
                status = '‚ùå Critical'
                status_color = 'red'
            
            metrics_data.append({
                'üåç Region': region,
                'üéØ Accuracy (%)': f"{metrics['accuracy']:.1f}%",
                'üìä MAE': f"{metrics['mae']:.2f}",
                'üìà RMSE': f"{metrics['rmse']:.2f}",
                'üìä Trend': f"{trend_emoji} {metrics['trend'].title()}",
                'üîÑ Health Status': status
            })
        
        metrics_df = pd.DataFrame(metrics_data)
        
        # Style the dataframe based on health status
        def color_status(val):
            if '‚úÖ' in val:
                return 'background-color: #d4edda; color: #155724'
            elif '‚ö†Ô∏è' in val:
                return 'background-color: #fff3cd; color: #856404'  
            elif '‚ùå' in val:
                return 'background-color: #f8d7da; color: #721c24'
            return ''
        
        styled_metrics = metrics_df.style.applymap(color_status, subset=['üîÑ Health Status'])
        st.dataframe(styled_metrics, use_container_width=True, hide_index=True)
        
        # ===== RETRAINING RECOMMENDATIONS =====
        if retraining_status.get('retraining_required', False):
            st.markdown("#### üîÑ Intelligent Retraining Recommendations")
            
            for retrain_info in retraining_status['regions_needing_retrain']:
                priority_colors = {
                    'HIGH': '#e74c3c', 
                    'MEDIUM': '#f39c12', 
                    'LOW': '#27ae60'
                }
                priority_color = priority_colors.get(retrain_info['priority'], '#95a5a6')
                
                st.markdown(f"""
                <div style="background: {priority_color}22; padding: 1rem; border-radius: 8px; border-left: 4px solid {priority_color}; margin-bottom: 1rem;">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <strong style="color: {priority_color};">üîÑ {retrain_info['region']}</strong>
                        <span style="background: {priority_color}; color: white; padding: 0.2rem 0.5rem; border-radius: 12px; font-size: 0.8rem;">{retrain_info['priority']} PRIORITY</span>
                    </div>
                    <div style="margin-top: 0.5rem; font-size: 0.9rem;">{retrain_info['reason']}</div>
                    <div style="margin-top: 0.5rem; font-size: 0.8rem; color: #666;">
                        üí° <strong>Action:</strong> Schedule model retraining for improved accuracy
                    </div>
                </div>
                """, unsafe_allow_html=True)
            
            # Manual retraining trigger
            st.markdown("---")
            manual_col1, manual_col2 = st.columns([1, 2])
            
            with manual_col1:
                if st.button("üöÄ Trigger Manual Retraining", type="primary", use_container_width=True):
                    with st.spinner("Initiating intelligent model retraining..."):
                        try:
                            response = requests.post(f"{BASE_URL}/training/intelligent/trigger")
                            if response.status_code == 200:
                                result = response.json()
                                st.success("‚úÖ Intelligent retraining initiated successfully!")
                                st.info(f"ü§ñ Training pipeline started: {result.get('status', 'Started')}")
                                time.sleep(2)
                                st.rerun()
                            else:
                                st.error("‚ùå Failed to trigger retraining")
                        except Exception as e:
                            st.error(f"‚ùå Connection error: {str(e)}")
            
            with manual_col2:
                st.info("ü§ñ **Intelligent Retraining**: The system will automatically test ARIMA, XGBoost, and LSTM models for each flagged region and deploy the best performing model.")
        
        else:
            st.success("‚úÖ **All models are performing well!** No retraining required at this time.")
            
            # Show last successful training info
            st.markdown("#### üéØ Model Performance Summary")
            
            perf_col1, perf_col2, perf_col3 = st.columns(3)
            
            with perf_col1:
                excellent_count = sum(1 for metrics in accuracy_metrics.values() if metrics['accuracy'] >= 85)
                st.metric("üåü Excellent Models", excellent_count, help="Models with >85% accuracy")
            
            with perf_col2:
                stable_count = sum(1 for metrics in accuracy_metrics.values() if metrics['trend'] == 'stable')
                st.metric("üìä Stable Models", stable_count, help="Models with stable performance")
            
            with perf_col3:
                improving_count = sum(1 for metrics in accuracy_metrics.values() if metrics['trend'] == 'improving')
                st.metric("üìà Improving Models", improving_count, help="Models with improving accuracy")
        
    else:
        st.warning("‚ö†Ô∏è Model monitoring data not available. Please ensure the backend API is running with Milestone 4 enhancements.")
        
        # Show demo monitoring interface
        st.info("üí° **Demo Mode**: Model monitoring requires the enhanced backend API with `/api/monitoring/accuracy` endpoint.")
        
        # Demo monitoring dashboard
        st.markdown("#### üè• Demo: Model Health Dashboard")
        
        demo_health_data = []
        demo_regions = ['East US', 'West US', 'North Europe', 'Southeast Asia']
        
        for region in demo_regions:
            accuracy = np.random.uniform(75, 95)
            trend = np.random.choice(['improving', 'stable', 'declining'], p=[0.3, 0.5, 0.2])
            
            demo_health_data.append({
                'Region': region,
                'Accuracy (%)': f"{accuracy:.1f}%",
                'MAE': f"{np.random.uniform(10, 20):.2f}",
                'RMSE': f"{np.random.uniform(12, 25):.2f}",
                'Trend': trend.title(),
                'Status': 'Healthy' if accuracy >= 85 else 'Warning' if accuracy >= 75 else 'Critical'
            })
        
        demo_health_df = pd.DataFrame(demo_health_data)
        st.dataframe(demo_health_df, use_container_width=True, hide_index=True)
    
    # ===== AUTOMATED REPORTING SECTION =====
    st.markdown("---")
    st.markdown("### üìä Automated Model Reporting System")
    
    report_tab1, report_tab2, report_tab3 = st.tabs(["üìà Performance Reports", "üìã Health Reports", "üîÑ Training Reports"])
    
    with report_tab1:
        st.markdown("#### üìà Model Performance Reports")
        
        perf_col1, perf_col2 = st.columns([2, 1])
        
        with perf_col1:
            st.markdown("**üìä Available Performance Reports:**")
            
            performance_reports = [
                {
                    "name": "Daily Accuracy Summary",
                    "description": "Daily model accuracy trends and alerts",
                    "format": "CSV",
                    "icon": "üìä"
                },
                {
                    "name": "Weekly Performance Analysis",
                    "description": "Comprehensive weekly model analysis",
                    "format": "Excel",
                    "icon": "üìà"
                },
                {
                    "name": "Monthly Health Assessment",
                    "description": "Monthly model health and trend analysis",
                    "format": "PDF",
                    "icon": "üìã"
                },
                {
                    "name": "Accuracy vs Forecast Comparison",
                    "description": "Detailed accuracy vs actual predictions",
                    "format": "CSV",
                    "icon": "üéØ"
                }
            ]
            
            for i, report in enumerate(performance_reports):
                if st.button(f"{report['icon']} Generate {report['name']} ({report['format']})", key=f"perf_report_{i}"):
                    with st.spinner(f"Generating {report['name']}..."):
                        # Simulate report generation
                        progress = st.progress(0)
                        for j in range(100):
                            time.sleep(0.01)
                            progress.progress(j + 1)
                        
                        st.success(f"‚úÖ {report['name']} generated successfully!")
                        st.info(f"üìÑ **Description:** {report['description']}")
                        
                        # Show download button for demo
                        if report['format'] == 'CSV':
                            sample_data = "Region,Accuracy,MAE,RMSE,Status\nEast US,87.3,12.5,15.2,Healthy\n"
                            st.download_button(
                                label=f"‚¨áÔ∏è Download {report['format']}",
                                data=sample_data,
                                file_name=f"{report['name'].lower().replace(' ', '_')}.csv",
                                mime="text/csv"
                            )
        
        with perf_col2:
            st.markdown("**üìÖ Report Schedule:**")
            st.info("""
            **ü§ñ Automated Schedule:**
            - üïê **Daily:** 6:00 AM UTC
            - üìÖ **Weekly:** Monday 8:00 AM UTC  
            - üóìÔ∏è **Monthly:** 1st of month 9:00 AM UTC
            
            **üìä Last Generated:**
            - Daily: 2 hours ago ‚úÖ
            - Weekly: 3 days ago ‚úÖ
            - Monthly: 12 days ago ‚úÖ
            
            **‚ö° Status:** All automations active
            """)
    
    with report_tab2:
        st.markdown("#### üìã Model Health Reports")
        
        health_col1, health_col2 = st.columns(2)
        
        with health_col1:
            health_report_type = st.selectbox(
                "üìã Select Health Report Type", 
                [
                    "Overall Health Summary",
                    "Risk Assessment Report", 
                    "Retraining Recommendations",
                    "Performance Degradation Analysis"
                ]
            )
        
        with health_col2:
            health_time_range = st.selectbox(
                "üìÖ Select Time Range",
                ["Last 7 days", "Last 30 days", "Last 90 days", "Custom range"]
            )
        
        if st.button("üìä Generate Health Report", use_container_width=True):
            with st.spinner("Generating comprehensive health report..."):
                # Simulate report generation
                progress_bar = st.progress(0)
                for i in range(100):
                    time.sleep(0.02)
                    progress_bar.progress(i + 1)
                
                st.success("‚úÖ Health report generated successfully!")
                
                # Show sample health report preview
                st.markdown("**üìä Report Preview:**")
                
                if monitoring_data:
                    # Use real data if available
                    health_preview_data = {
                        'Metric': ['Overall Health Status', 'Healthy Models', 'Models Needing Attention', 'Average Accuracy', 'Retraining Required'],
                        'Value': [
                            model_health.get('overall_status', 'Unknown'),
                            f"{model_health.get('healthy_models', 0)}/{model_health.get('total_models', 0)}",
                            model_health.get('warning_models', 0) + model_health.get('critical_models', 0),
                            f"{model_health.get('average_accuracy', 0):.1f}%",
                            'Yes' if retraining_status.get('retraining_required', False) else 'No'
                        ],
                        'Status': ['üü¢ Good', '‚úÖ Healthy', '‚ö†Ô∏è Monitor', 'üìà Good', 'üîÑ Active']
                    }
                else:
                    # Use demo data
                    health_preview_data = {
                        'Metric': ['Overall Health Status', 'Healthy Models', 'Models Needing Attention', 'Average Accuracy', 'Retraining Required'],
                        'Value': ['HEALTHY', '3/4', '1', '84.2%', 'No'],
                        'Status': ['üü¢ Good', '‚úÖ Healthy', '‚ö†Ô∏è Monitor', 'üìà Good', '‚úÖ None']
                    }
                
                st.dataframe(pd.DataFrame(health_preview_data), use_container_width=True, hide_index=True)
    
    with report_tab3:
        st.markdown("#### üîÑ Model Training Reports")
        
        # Get training history if available
        training_history = fetch_api('training/intelligent/history')
        
        if training_history:
            st.markdown("**üìö Recent Training Sessions:**")
            
            training_sessions = [
                {"name": "Latest Intelligent Training", "date": "2025-10-05", "status": "‚úÖ Completed", "models_updated": 3, "duration": "45 min"},
                {"name": "Weekly Auto-Training", "date": "2025-10-01", "status": "‚úÖ Completed", "models_updated": 8, "duration": "78 min"},
                {"name": "Performance Optimization", "date": "2025-09-30", "status": "‚úÖ Completed", "models_updated": 6, "duration": "52 min"}
            ]
        else:
            st.markdown("**üìö Training Sessions (Demo):**")
            
            training_sessions = [
                {"name": "Manual Training Trigger", "date": "2025-10-05", "status": "‚úÖ Completed", "models_updated": 4, "duration": "62 min"},
                {"name": "Scheduled Auto-Training", "date": "2025-10-02", "status": "‚úÖ Completed", "models_updated": 8, "duration": "84 min"},
                {"name": "Performance Retraining", "date": "2025-09-28", "status": "‚úÖ Completed", "models_updated": 5, "duration": "71 min"}
            ]
        
        for session in training_sessions:
            train_col1, train_col2, train_col3, train_col4, train_col5 = st.columns([3, 2, 2, 2, 1])
            
            with train_col1:
                st.write(f"ü§ñ {session['name']}")
            with train_col2:
                st.write(f"üìÖ {session['date']}")
            with train_col3:
                st.write(session['status'])
            with train_col4:
                st.write(f"üîÑ {session['models_updated']} models updated")
            with train_col5:
                if st.button("üìÑ", key=f"download_training_{session['name']}"):
                    st.info("üìä Training report download initiated!")
    
    # ===== EXPORT AND ANALYTICS SECTION =====
    st.markdown("---")
    st.markdown("### üíæ Advanced Analytics & Export Center")
    
    export_col1, export_col2, export_col3, export_col4 = st.columns(4)
    
    with export_col1:
        if st.button("üìä Export All Metrics", use_container_width=True):
            if monitoring_data:
                # Generate comprehensive metrics export
                all_metrics_data = []
                
                for region, metrics in accuracy_metrics.items():
                    all_metrics_data.append({
                        'Region': region,
                        'Accuracy_%': metrics['accuracy'],
                        'MAE': metrics['mae'],
                        'RMSE': metrics['rmse'],
                        'Trend': metrics['trend'],
                        'Health_Status': 'Healthy' if metrics['accuracy'] >= 85 else 'Warning' if metrics['accuracy'] >= alert_threshold else 'Critical',
                        'Last_Updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    })
                
                metrics_df_export = pd.DataFrame(all_metrics_data)
                csv_data = metrics_df_export.to_csv(index=False)
                
                st.download_button(
                    label="‚¨áÔ∏è Download Comprehensive Metrics (CSV)",
                    data=csv_data,
                    file_name=f"model_metrics_comprehensive_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.info("üìä Metrics export requires monitoring data")
    
    with export_col2:
        if st.button("üìà Export Performance Charts", use_container_width=True):
            st.info("üìä Chart export functionality ready! Charts can be downloaded as PNG/SVG from the chart menu.")
    
    with export_col3:
        if st.button("üîÑ Export Training History", use_container_width=True):
            if training_history:
                st.success("üìã Training history export ready!")
                st.info("üîÑ Training history includes performance evolution and model comparisons")
            else:
                st.info("üìã Training history export requires training data")
    
    with export_col4:
        if st.button("üìã Generate Full Report", use_container_width=True):
            with st.spinner("Generating comprehensive monitoring report..."):
                time.sleep(2)
                st.success("üìÑ Full monitoring report generated!")
                st.info("üéØ Includes: Model health, performance trends, recommendations, and training history")

# END OF TAB 9 & 10 CODE





# ===== FOOTER =====
    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; color: #666; background: #f8f9fa; padding: 1rem; border-radius: 8px;">
        <strong>üß† Intelligent Capacity Planning</strong><br>
        Analyzing {selected_service} capacity over {planning_horizon} days ‚Ä¢ 
        {cache_status} ‚Ä¢ Powered by your 8 forecasting models
    </div>
    """, unsafe_allow_html=True)   
